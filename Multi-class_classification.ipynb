{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main reference:\n",
    "\n",
    "https://medium.com/swlh/natural-language-processing-nlp-analysis-with-amazon-review-data-part-i-data-engineering-6573b782e4dc\n",
    "https://melaniesoek0120.medium.com/natural-language-processing-nlp-amazon-review-data-part-ii-eda-data-preprocessing-and-model-3866dcbdbb77 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and DropNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93907\n",
      "   overall                                         reviewText\n",
      "0        5  This is awesome to listen to, A must-have for ...\n",
      "1        5                                               bien\n",
      "2        5  It was great to hear the old stuff again and I...\n",
      "3        4  well best of's are a bit poison normally but t...\n",
      "4        5  What can I say? This is Casting Crowns!!!This ...\n",
      "[2165, 54714]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer as ps\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Lim Jia Hui\\Desktop\\songsdata.csv\")\n",
    "print(len(df.reviewText))\n",
    "print(df.head())\n",
    "nanlist = []\n",
    "for text in range(len(df.reviewText)):\n",
    "    if type(df.reviewText[text])!= str:\n",
    "        nanlist.append(int(text))\n",
    "print(nanlist)\n",
    "df.drop(index=nanlist, axis=0,inplace=True)\n",
    "df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_list = stopwords.words('english')\n",
    "sw_list += list(string.punctuation)\n",
    "sw_list += [\"''\", '\"\"', '...', '``', '’', '“', '’', '”', '‘', '‘',\"'\", '©','said',\"'s\", \"also\",'one',\"n't\",'com', '-', '–', '—', '_',\"/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer, Stemmer, and Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['awesom', 'listen', 'must-hav', 'slayer', 'fan', '..', 'sadli', 'need', 'tripl', 'disc', 'set', '..', 'mani', 'hit'], ['bien'], ['great', 'hear', 'old', 'stuff', 'like', 'new', 'stuff', 'recommend', 'slayer', 'fan'], ['well', 'best', 'bite', 'poison', 'normal', 'bad', 'pretti', 'good', \"'d\", 'put', '90', 'hell', 'await', 'reign', 'blood', 'south', 'season', 'divin', 'coupl', 'musica', 'track', 'everyth', 'god', 'hate', '-at', 'point', 'best', 'mean', 'everi', 'cd', 'mainli', 'bad', 'dose', 'put', 'great', 'track', 'live', 'show', 'play', 'much', 'like,213', 'skeleton', 'societi', 'sex', 'murder', 'art', 'gemini', 'rare', 'track', 'final', 'six', 'bonu', 'track', 'christ', 'illus', 'mysteri', 'cover', 'song', 'unditstput', 'attitud', 'cd', 'would', 'greatest', 'hit', 'collect', 'know', 'put', 'coupl', 'live', 'track', 'too.al', 'could', 'much', 'wors', 'great', 'car'], ['say', 'cast', 'crown', 'good', 'bless', 'fill', 'cd']]\n"
     ]
    }
   ],
   "source": [
    "def Tokenizer(data):\n",
    "    tokens = nltk.word_tokenize(data)\n",
    "    tokenized_data= []\n",
    "    for i in tokens:\n",
    "        if i.lower() not in sw_list:\n",
    "            tokenized_data.append(i.lower())\n",
    "    return tokenized_data\n",
    "\n",
    "def Stemmer(data2):\n",
    "    stemmed_data =[]\n",
    "    for j in data2:\n",
    "        stemmed_data.append(ps().stem(j))\n",
    "    return stemmed_data\n",
    "\n",
    "def Lemmatizer(data3):\n",
    "    lemmatized_data = []\n",
    "    for k in data3:\n",
    "        lemmatized_data.append(WordNetLemmatizer().lemmatize(k, pos='v'))\n",
    "    return lemmatized_data\n",
    "\n",
    "\n",
    "\n",
    "lemmatized_reviews = list(map(Lemmatizer,(map(Stemmer, (map(Tokenizer, df['reviewText']))))))\n",
    "\n",
    "print(lemmatized_reviews[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Lemmatized Nan Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[293, 1792, 1942, 2652, 3560, 3857, 5025, 5122, 5568, 6552, 7846, 8136, 9464, 10069, 11448, 11803, 12422, 12825, 13354, 14932, 18283, 28588, 30450, 32356, 32601, 33455, 35223, 35698, 35703, 37831, 37910, 39228, 40752, 42037, 43383, 44559, 45716, 48627, 50097, 52295, 52380, 52690, 56502, 59520, 60623, 61150, 61165, 62528, 65639, 66416, 69224, 70043, 70892, 71015, 71677, 72711, 73298, 73509, 73897, 75327, 75406, 76099, 77468, 77836, 77867, 80751, 81848, 82071, 82843, 85562, 86105, 86398, 88067, 88161, 88665, 89174, 89212, 90531, 91580, 92817]\n",
      "80\n",
      "93905\n",
      "93825\n"
     ]
    }
   ],
   "source": [
    "nanlist2 = []\n",
    "for word in range(len(lemmatized_reviews)):\n",
    "    if len(lemmatized_reviews[word]) == 0:\n",
    "        nanlist2.append(word)\n",
    "print(nanlist2)\n",
    "print(len(nanlist2))\n",
    "print(len(lemmatized_reviews))\n",
    "for nan in nanlist2:\n",
    "    lemmatized_reviews.remove([])\n",
    "print(len(lemmatized_reviews))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal from original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=nanlist2, axis=0,inplace=True)\n",
    "df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test and Train-Val-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75060, 1)\n",
      "(18765, 1)\n",
      "(75060, 1)\n",
      "(18765, 1)\n",
      "(60048, 1)\n",
      "(15012, 1)\n",
      "(60048, 1)\n",
      "(15012, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(pd.DataFrame({'processed_reviews':lemmatized_reviews}), df['overall'].to_frame(name='overall'), test_size=0.2, random_state=0)\n",
    "\n",
    "x_train_train, x_val, y_train_train, y_val = train_test_split(x_train,y_train,test_size=0.2,stratify=y_train, random_state=0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(x_train_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train_train.shape)\n",
    "print(y_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional \"manual\" resampler with sklearn.utils.resample\n",
    "\n",
    "# from sklearn.utils import resample\n",
    "\n",
    "# xy_train = pd.concat([x_train,y_train], axis=1)\n",
    "# xy_train_train = pd.concat([x_train_train,y_train_train], axis=1)\n",
    "\n",
    "# def resampling(minority):\n",
    "#    resampled_minority = resample(minority, replace=True, n_samples= len(xy_train[xy_train.overall==5]), random_state=0)\n",
    "#    return resampled_minority\n",
    "\n",
    "# resampled_xy_train = xy_train[xy_train.overall==5]\n",
    "# resampled_xy_train_train = xy_train_train[xy_train_train.overall==5]\n",
    "\n",
    "# for i in range (1,5):\n",
    "#    resampled_xy_train = pd.concat([resampled_xy_train,resampling(xy_train[xy_train.overall==i])])\n",
    "\n",
    "# for i in range (1,5):\n",
    "#    resampled_xy_train_train = pd.concat([resampled_xy_train_train,resampling(xy_train_train[xy_train_train.overall==i])])\n",
    "\n",
    "# resampled_shuffled_xy_train = resampled_xy_train.sample(frac=1)\n",
    "# x_train = resampled_shuffled_xy_train['processed_reviews'].to_frame()\n",
    "# y_train = resampled_shuffled_xy_train['overall'].to_frame()\n",
    "\n",
    "# resampled_shuffled_xy_train_train = resampled_xy_train_train.sample(frac=1)\n",
    "# x_train_train = resampled_shuffled_xy_train_train['processed_reviews'].to_frame()\n",
    "# y_train_train = resampled_shuffled_xy_train_train['overall'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "x_train, y_train = RandomOverSampler(random_state=0).fit_resample(x_train,y_train)\n",
    "\n",
    "x_train_train, y_train_train = RandomOverSampler(random_state=0).fit_resample(x_train_train,y_train_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def dummy_token_and_pre(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy_token_and_pre, preprocessor=dummy_token_and_pre, token_pattern=None)\n",
    "\n",
    "tfidf_val = TfidfVectorizer(analyzer='word', tokenizer=dummy_token_and_pre, preprocessor=dummy_token_and_pre, token_pattern=None)\n",
    "\n",
    "x_trainvec = tfidf.fit_transform(x_train.processed_reviews).sorted_indices()\n",
    "x_testvec = tfidf.transform(x_test.processed_reviews).sorted_indices()\n",
    "\n",
    "x_train_trainvec = tfidf_val.fit_transform(x_train_train.processed_reviews).sorted_indices()\n",
    "x_valvec = tfidf_val.transform(x_val.processed_reviews).sorted_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pseudocode for mlp hyperparam tuning\n",
    "\n",
    "#obj()\n",
    "    #param = suggest()\n",
    "\n",
    "    #model = model()\n",
    "\n",
    "    #for epochs in range()\n",
    "    #            agg_f1 = []\n",
    "\n",
    "    #    for train_index, val_index in StratifiedKFold(n_splits=5).split(x_trainvec,y_train): \n",
    "\n",
    "    #        x_trainvec_resd, y_train_resd = RandomOverSampler(random_state=0).fit_resample(x_trainvec.iloc[train_index], y_train.iloc[train_index])    \n",
    "\n",
    "    #        model.fit(x=x_trainvec_resd, y=y_train_resd, epochs =(5^(rung)), verbose=0, batch_size= 100, random_state=0, callbacks=es)\n",
    "\n",
    "    #        agg_f1.append(f1_score(y_pred=model.predict(pd.DataFrame.sparse.from_spmatrix(x_trainvec).iloc[val_index]), y_true=y_train.iloc[val_index].to_numpy().ravel(), average = 'macro'))\n",
    "\n",
    "    #    intermediate_value = statistics.mean(agg_f1)\n",
    "\n",
    "\n",
    "\n",
    "#rant: The challenge in implementing cross-validation for a tf model is the use of a tf model with (a lack of)sklearn functionalities\n",
    "#      In this case, tf models have some hyperparams that need do be defined in .fit(), which clashes with sklearn functionalities \n",
    "#      as some sklearn functions have .fit() implicit in them. The important one here is cross_val_score(). Without this, one has to\n",
    "#      resort to manually implementing the (stratified)cross_val function. This is a further issue when the data is imbalanced.\n",
    "#      From googling it seems that the way to treat imbalanced data in cross-validation is to oversample the training folds\n",
    "#      for each cross-validation split. This can normally be combined into a sklearn/imblearn pipeline and then passed to the\n",
    "#      cross-validation function as seen in the random forest model. However, as mentioned this is a tf model with sklearn functionalities,\n",
    "#      hence one has to implement this part manually as well. This is a bigger conundrum that one might initially expect.\n",
    "#      As the method used is usually to slice out the training part of each cross-validation fold and then apply an oversampling function.\n",
    "#      However, slicing a sparse matrix with a 1d np array as input is something that googling doesnt show how to do.\n",
    "#      Now, you might think of transforming the sparse matrix into a pd df so that you could slice it with say iloc, but  \n",
    "#      because of an unknown reason while the oversampling function as mentioned previously is supposed to be able to take \n",
    "#      both pandas df and sparse matrix as inputs, the pandas df version of a sparse matrix is not a valid input. This is vile shenanigans \n",
    "#      and I am utterly repulsed by it. Yet, given all this there is still the option of moving the tf-idf vectorization into the \n",
    "#      cross-validation part so that the sparse matrix is only made post oversampling, or making your own cross-validation\n",
    "#      function with libraries using an updated version of pandas/scipy(both of which I will NOT do).\n",
    "#  \n",
    "\n",
    "#      Now one might be wondering why one should use a tf model anyways given its imperfect compatabiities(at least in cross-validation).  \n",
    "#      The answer is GPU. Sklearn does not offer GPU support for training its models. The increase in training speed given GPU support is  \n",
    "#      highly considerable. However, given that cross-validation is such a pain to implement, one might ask whether its still worth using even\n",
    "#      if you have to redo the tf-idf vectorization every split for every epoch for every set of hyperparameters. The answer is something I do \n",
    "#      not know and will not attempt to know. Hence, the question is then rephrased into whether the extra speed from using the GPU is worth \n",
    "#      the decrease in samples used for the training set as some samples need to be separated into a validation set. Admittedly, I personally \n",
    "#      answered this question rather arbitrarily and perhaps personally biased to the superiority of Optuna over sklearn hyperparameter tuning.\n",
    "#      Hence, I can't exactly justify my choice here, and what I do here is best treated just as a proof of concept.\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:06:54,025]\u001b[0m A new study created in memory with name: no-name-a418ea7d-74b9-47ef-bc88-9940be52076b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 19), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8447 - accuracy: 0.6544 - tf_f1: 0.5249 - val_loss: 1.1850 - val_accuracy: 0.5142 - val_tf_f1: 0.6462\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.5425 - accuracy: 0.7843 - tf_f1: 0.6830 - val_loss: 1.0550 - val_accuracy: 0.5982 - val_tf_f1: 0.7111\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4656 - accuracy: 0.8165 - tf_f1: 0.7289 - val_loss: 1.1352 - val_accuracy: 0.6232 - val_tf_f1: 0.7440\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.4180 - accuracy: 0.8364 - tf_f1: 0.7552 - val_loss: 1.3025 - val_accuracy: 0.4760 - val_tf_f1: 0.7643\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.3860 - accuracy: 0.8504 - tf_f1: 0.7718 - val_loss: 1.1065 - val_accuracy: 0.6535 - val_tf_f1: 0.7793\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.3629 - accuracy: 0.8604 - tf_f1: 0.7858 - val_loss: 1.2806 - val_accuracy: 0.5583 - val_tf_f1: 0.7912\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.3455 - accuracy: 0.8671 - tf_f1: 0.7959 - val_loss: 1.4963 - val_accuracy: 0.4647 - val_tf_f1: 0.7998\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.3330 - accuracy: 0.8722 - tf_f1: 0.8032 - val_loss: 1.3531 - val_accuracy: 0.5520 - val_tf_f1: 0.8068\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.3188 - accuracy: 0.8779 - tf_f1: 0.8101 - val_loss: 1.1880 - val_accuracy: 0.6729 - val_tf_f1: 0.8135\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.3100 - accuracy: 0.8821 - tf_f1: 0.8167 - val_loss: 1.2961 - val_accuracy: 0.6242 - val_tf_f1: 0.8194\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.3022 - accuracy: 0.8848 - tf_f1: 0.8220 - val_loss: 1.3521 - val_accuracy: 0.5828 - val_tf_f1: 0.8243\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.2943 - accuracy: 0.8880 - tf_f1: 0.8265 - val_loss: 1.4155 - val_accuracy: 0.5768 - val_tf_f1: 0.8285\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.2898 - accuracy: 0.8898 - tf_f1: 0.8303 - val_loss: 1.3247 - val_accuracy: 0.6615 - val_tf_f1: 0.8323\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.2816 - accuracy: 0.8933 - tf_f1: 0.8342 - val_loss: 1.4277 - val_accuracy: 0.5969 - val_tf_f1: 0.8358\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.2760 - accuracy: 0.8953 - tf_f1: 0.8374 - val_loss: 1.4126 - val_accuracy: 0.6127 - val_tf_f1: 0.8390\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.2709 - accuracy: 0.8978 - tf_f1: 0.8404 - val_loss: 1.6587 - val_accuracy: 0.4973 - val_tf_f1: 0.8416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:13:04,037]\u001b[0m Trial 0 finished with value: 0.8416303396224976 and parameters: {'lr': 0.07652462285473018, 'units': 19}. Best is trial 0 with value: 0.8416303396224976.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 39), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8028 - accuracy: 0.6709 - tf_f1: 0.5413 - val_loss: 0.8955 - val_accuracy: 0.6761 - val_tf_f1: 0.6674\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.4423 - accuracy: 0.8202 - tf_f1: 0.7114 - val_loss: 0.9559 - val_accuracy: 0.6649 - val_tf_f1: 0.7427\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.3436 - accuracy: 0.8607 - tf_f1: 0.7638 - val_loss: 1.0519 - val_accuracy: 0.6322 - val_tf_f1: 0.7802\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2935 - accuracy: 0.8821 - tf_f1: 0.7929 - val_loss: 1.2791 - val_accuracy: 0.5458 - val_tf_f1: 0.8030\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 23s 5ms/step - loss: 0.2579 - accuracy: 0.8970 - tf_f1: 0.8115 - val_loss: 1.3424 - val_accuracy: 0.5543 - val_tf_f1: 0.8189\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2314 - accuracy: 0.9087 - tf_f1: 0.8255 - val_loss: 1.1279 - val_accuracy: 0.6835 - val_tf_f1: 0.8319\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.2128 - accuracy: 0.9175 - tf_f1: 0.8376 - val_loss: 1.1835 - val_accuracy: 0.6684 - val_tf_f1: 0.8427\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 27s 6ms/step - loss: 0.1964 - accuracy: 0.9254 - tf_f1: 0.8474 - val_loss: 1.1911 - val_accuracy: 0.7070 - val_tf_f1: 0.8518\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1811 - accuracy: 0.9308 - tf_f1: 0.8558 - val_loss: 1.2653 - val_accuracy: 0.6904 - val_tf_f1: 0.8594\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1728 - accuracy: 0.9354 - tf_f1: 0.8628 - val_loss: 1.4943 - val_accuracy: 0.6250 - val_tf_f1: 0.8657\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1631 - accuracy: 0.9392 - tf_f1: 0.8685 - val_loss: 1.3744 - val_accuracy: 0.6997 - val_tf_f1: 0.8712\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1532 - accuracy: 0.9436 - tf_f1: 0.8738 - val_loss: 1.5536 - val_accuracy: 0.6123 - val_tf_f1: 0.8760\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1444 - accuracy: 0.9470 - tf_f1: 0.8781 - val_loss: 1.4129 - val_accuracy: 0.6763 - val_tf_f1: 0.8803\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1385 - accuracy: 0.9503 - tf_f1: 0.8824 - val_loss: 1.5069 - val_accuracy: 0.7051 - val_tf_f1: 0.8844\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1327 - accuracy: 0.9517 - tf_f1: 0.8863 - val_loss: 1.5218 - val_accuracy: 0.6951 - val_tf_f1: 0.8880\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1284 - accuracy: 0.9533 - tf_f1: 0.8897 - val_loss: 1.5007 - val_accuracy: 0.7263 - val_tf_f1: 0.8913\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1234 - accuracy: 0.9557 - tf_f1: 0.8929 - val_loss: 1.5649 - val_accuracy: 0.7124 - val_tf_f1: 0.8944\n",
      "Epoch 18/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1210 - accuracy: 0.9567 - tf_f1: 0.8958 - val_loss: 1.5580 - val_accuracy: 0.7218 - val_tf_f1: 0.8972\n",
      "Epoch 19/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1173 - accuracy: 0.9584 - tf_f1: 0.8985 - val_loss: 1.7423 - val_accuracy: 0.6279 - val_tf_f1: 0.8996\n",
      "Epoch 20/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1152 - accuracy: 0.9585 - tf_f1: 0.9007 - val_loss: 1.6261 - val_accuracy: 0.6926 - val_tf_f1: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:21:04,691]\u001b[0m Trial 1 finished with value: 0.9017766714096069 and parameters: {'lr': 0.06534719909560231, 'units': 39}. Best is trial 1 with value: 0.9017766714096069.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape:0\", shape=(None, 11), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8967 - accuracy: 0.6221 - tf_f1: 0.5019 - val_loss: 1.1075 - val_accuracy: 0.5741 - val_tf_f1: 0.6156\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.6276 - accuracy: 0.7387 - tf_f1: 0.6503 - val_loss: 1.0200 - val_accuracy: 0.5841 - val_tf_f1: 0.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:21:53,614]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape:0\", shape=(None, 27), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8040 - accuracy: 0.6686 - tf_f1: 0.5417 - val_loss: 0.9935 - val_accuracy: 0.6105 - val_tf_f1: 0.6641\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4654 - accuracy: 0.8099 - tf_f1: 0.7053 - val_loss: 0.9943 - val_accuracy: 0.6311 - val_tf_f1: 0.7349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:22:42,274]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape:0\", shape=(None, 26), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7780 - accuracy: 0.6789 - tf_f1: 0.5572 - val_loss: 1.0026 - val_accuracy: 0.6019 - val_tf_f1: 0.6745\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4593 - accuracy: 0.8117 - tf_f1: 0.7126 - val_loss: 1.1502 - val_accuracy: 0.5720 - val_tf_f1: 0.7399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:23:30,743]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Reshape:0\", shape=(None, 34), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 1.3191 - accuracy: 0.4830 - tf_f1: 0.3871 - val_loss: 1.1117 - val_accuracy: 0.5919 - val_tf_f1: 0.4737\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.9141 - accuracy: 0.6634 - tf_f1: 0.5231 - val_loss: 0.9164 - val_accuracy: 0.6589 - val_tf_f1: 0.5655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:24:19,681]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8193 - accuracy: 0.6671 - tf_f1: 0.5338 - val_loss: 0.9667 - val_accuracy: 0.6257 - val_tf_f1: 0.6620\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4484 - accuracy: 0.8188 - tf_f1: 0.7063 - val_loss: 0.9585 - val_accuracy: 0.6467 - val_tf_f1: 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:25:08,040]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape:0\", shape=(None, 19), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 26s 5ms/step - loss: 0.7950 - accuracy: 0.6710 - tf_f1: 0.5499 - val_loss: 1.1260 - val_accuracy: 0.5634 - val_tf_f1: 0.6658\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5086 - accuracy: 0.7970 - tf_f1: 0.7014 - val_loss: 1.0515 - val_accuracy: 0.6205 - val_tf_f1: 0.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:25:57,753]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape:0\", shape=(None, 41), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 26s 5ms/step - loss: 0.8475 - accuracy: 0.6600 - tf_f1: 0.5297 - val_loss: 0.9125 - val_accuracy: 0.6482 - val_tf_f1: 0.6553\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4728 - accuracy: 0.8109 - tf_f1: 0.6995 - val_loss: 0.9525 - val_accuracy: 0.6457 - val_tf_f1: 0.7315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:26:48,199]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Reshape:0\", shape=(None, 38), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8097 - accuracy: 0.6697 - tf_f1: 0.5427 - val_loss: 1.0211 - val_accuracy: 0.5638 - val_tf_f1: 0.6641\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.4538 - accuracy: 0.8156 - tf_f1: 0.7053 - val_loss: 0.9107 - val_accuracy: 0.6900 - val_tf_f1: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:27:37,907]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.9100 - accuracy: 0.6367 - tf_f1: 0.5050 - val_loss: 1.1329 - val_accuracy: 0.5019 - val_tf_f1: 0.6288\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5044 - accuracy: 0.7987 - tf_f1: 0.6743 - val_loss: 0.9271 - val_accuracy: 0.6428 - val_tf_f1: 0.7101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:28:26,175]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Reshape:0\", shape=(None, 18), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8089 - accuracy: 0.6683 - tf_f1: 0.5456 - val_loss: 0.9100 - val_accuracy: 0.6760 - val_tf_f1: 0.6658\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5100 - accuracy: 0.7936 - tf_f1: 0.7030 - val_loss: 1.1570 - val_accuracy: 0.5167 - val_tf_f1: 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:29:14,669]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Reshape:0\", shape=(None, 20), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.9806 - accuracy: 0.6072 - tf_f1: 0.4617 - val_loss: 0.9197 - val_accuracy: 0.6475 - val_tf_f1: 0.5991\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5599 - accuracy: 0.7801 - tf_f1: 0.6510 - val_loss: 1.0458 - val_accuracy: 0.5602 - val_tf_f1: 0.6876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:30:03,227]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.9669 - accuracy: 0.5867 - tf_f1: 0.4629 - val_loss: 1.1316 - val_accuracy: 0.5358 - val_tf_f1: 0.5779\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7175 - accuracy: 0.7044 - tf_f1: 0.6118 - val_loss: 1.1435 - val_accuracy: 0.5073 - val_tf_f1: 0.6354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:30:52,153]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_14/dense_28/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_14/dense_28/embedding_lookup_sparse/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_14/dense_28/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8572 - accuracy: 0.6544 - tf_f1: 0.5189 - val_loss: 1.1218 - val_accuracy: 0.5114 - val_tf_f1: 0.6470\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4776 - accuracy: 0.8071 - tf_f1: 0.6903 - val_loss: 1.0502 - val_accuracy: 0.5818 - val_tf_f1: 0.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:31:41,519]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_15/dense_30/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_15/dense_30/embedding_lookup_sparse/Reshape:0\", shape=(None, 43), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_15/dense_30/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7929 - accuracy: 0.6766 - tf_f1: 0.5503 - val_loss: 1.1301 - val_accuracy: 0.5146 - val_tf_f1: 0.6706\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4305 - accuracy: 0.8251 - tf_f1: 0.7119 - val_loss: 0.9927 - val_accuracy: 0.6485 - val_tf_f1: 0.7442\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3317 - accuracy: 0.8648 - tf_f1: 0.7652 - val_loss: 1.0528 - val_accuracy: 0.6289 - val_tf_f1: 0.7821\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2782 - accuracy: 0.8863 - tf_f1: 0.7949 - val_loss: 1.0425 - val_accuracy: 0.6876 - val_tf_f1: 0.8063\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2465 - accuracy: 0.9025 - tf_f1: 0.8157 - val_loss: 1.2005 - val_accuracy: 0.6094 - val_tf_f1: 0.8236\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2211 - accuracy: 0.9139 - tf_f1: 0.8304 - val_loss: 1.1546 - val_accuracy: 0.6790 - val_tf_f1: 0.8368\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1980 - accuracy: 0.9247 - tf_f1: 0.8426 - val_loss: 1.3670 - val_accuracy: 0.6009 - val_tf_f1: 0.8476\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1809 - accuracy: 0.9320 - tf_f1: 0.8521 - val_loss: 1.2583 - val_accuracy: 0.6836 - val_tf_f1: 0.8565\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1667 - accuracy: 0.9380 - tf_f1: 0.8605 - val_loss: 1.3234 - val_accuracy: 0.6972 - val_tf_f1: 0.8643\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1558 - accuracy: 0.9425 - tf_f1: 0.8678 - val_loss: 1.3175 - val_accuracy: 0.6888 - val_tf_f1: 0.8709\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1436 - accuracy: 0.9474 - tf_f1: 0.8739 - val_loss: 1.5320 - val_accuracy: 0.6351 - val_tf_f1: 0.8766\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.1333 - accuracy: 0.9517 - tf_f1: 0.8791 - val_loss: 1.4262 - val_accuracy: 0.7280 - val_tf_f1: 0.8817\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1262 - accuracy: 0.9551 - tf_f1: 0.8842 - val_loss: 1.4946 - val_accuracy: 0.7404 - val_tf_f1: 0.8865\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1211 - accuracy: 0.9567 - tf_f1: 0.8887 - val_loss: 1.5093 - val_accuracy: 0.6942 - val_tf_f1: 0.8906\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1154 - accuracy: 0.9591 - tf_f1: 0.8925 - val_loss: 1.5307 - val_accuracy: 0.6970 - val_tf_f1: 0.8943\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1130 - accuracy: 0.9600 - tf_f1: 0.8960 - val_loss: 1.5119 - val_accuracy: 0.7268 - val_tf_f1: 0.8976\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1080 - accuracy: 0.9618 - tf_f1: 0.8991 - val_loss: 1.6182 - val_accuracy: 0.6910 - val_tf_f1: 0.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:38:30,015]\u001b[0m Trial 15 finished with value: 0.9005640745162964 and parameters: {'lr': 0.06502275638715334, 'units': 43}. Best is trial 1 with value: 0.9017766714096069.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Reshape:0\", shape=(None, 43), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8332 - accuracy: 0.6604 - tf_f1: 0.5284 - val_loss: 1.0446 - val_accuracy: 0.6010 - val_tf_f1: 0.6551\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4694 - accuracy: 0.8098 - tf_f1: 0.6986 - val_loss: 0.9515 - val_accuracy: 0.6624 - val_tf_f1: 0.7305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:39:18,586]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Reshape:0\", shape=(None, 37), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.9047 - accuracy: 0.6387 - tf_f1: 0.5076 - val_loss: 0.9934 - val_accuracy: 0.5938 - val_tf_f1: 0.6332\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5034 - accuracy: 0.7999 - tf_f1: 0.6795 - val_loss: 0.8751 - val_accuracy: 0.6828 - val_tf_f1: 0.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:40:07,311]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 1.1399 - accuracy: 0.5563 - tf_f1: 0.4384 - val_loss: 1.0757 - val_accuracy: 0.5623 - val_tf_f1: 0.5499\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.6765 - accuracy: 0.7445 - tf_f1: 0.6032 - val_loss: 0.9275 - val_accuracy: 0.6472 - val_tf_f1: 0.6442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:40:56,254]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_19/dense_38/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_19/dense_38/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_19/dense_38/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7934 - accuracy: 0.6774 - tf_f1: 0.5526 - val_loss: 0.8496 - val_accuracy: 0.6835 - val_tf_f1: 0.6753\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4333 - accuracy: 0.8237 - tf_f1: 0.7182 - val_loss: 0.9694 - val_accuracy: 0.6575 - val_tf_f1: 0.7485\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3306 - accuracy: 0.8655 - tf_f1: 0.7690 - val_loss: 1.0530 - val_accuracy: 0.6342 - val_tf_f1: 0.7854\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2747 - accuracy: 0.8898 - tf_f1: 0.7982 - val_loss: 1.1487 - val_accuracy: 0.6174 - val_tf_f1: 0.8092\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2344 - accuracy: 0.9079 - tf_f1: 0.8185 - val_loss: 1.2027 - val_accuracy: 0.6221 - val_tf_f1: 0.8266\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2073 - accuracy: 0.9202 - tf_f1: 0.8338 - val_loss: 1.1288 - val_accuracy: 0.6765 - val_tf_f1: 0.8403\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1861 - accuracy: 0.9301 - tf_f1: 0.8462 - val_loss: 1.2299 - val_accuracy: 0.6894 - val_tf_f1: 0.8516\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1678 - accuracy: 0.9379 - tf_f1: 0.8565 - val_loss: 1.2645 - val_accuracy: 0.7036 - val_tf_f1: 0.8610\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1519 - accuracy: 0.9450 - tf_f1: 0.8653 - val_loss: 1.3904 - val_accuracy: 0.6529 - val_tf_f1: 0.8690\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1400 - accuracy: 0.9500 - tf_f1: 0.8724 - val_loss: 1.4094 - val_accuracy: 0.6770 - val_tf_f1: 0.8756\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1323 - accuracy: 0.9527 - tf_f1: 0.8787 - val_loss: 1.4059 - val_accuracy: 0.7333 - val_tf_f1: 0.8815\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1241 - accuracy: 0.9553 - tf_f1: 0.8842 - val_loss: 1.4796 - val_accuracy: 0.7242 - val_tf_f1: 0.8867\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1164 - accuracy: 0.9589 - tf_f1: 0.8891 - val_loss: 1.5829 - val_accuracy: 0.6499 - val_tf_f1: 0.8912\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1121 - accuracy: 0.9605 - tf_f1: 0.8932 - val_loss: 1.4977 - val_accuracy: 0.7174 - val_tf_f1: 0.8951\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1061 - accuracy: 0.9630 - tf_f1: 0.8970 - val_loss: 1.5587 - val_accuracy: 0.6884 - val_tf_f1: 0.8987\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1040 - accuracy: 0.9633 - tf_f1: 0.9003 - val_loss: 1.7586 - val_accuracy: 0.6397 - val_tf_f1: 0.9017\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.0996 - accuracy: 0.9652 - tf_f1: 0.9031 - val_loss: 1.6222 - val_accuracy: 0.6841 - val_tf_f1: 0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:47:43,240]\u001b[0m Trial 19 finished with value: 0.9045053124427795 and parameters: {'lr': 0.06352216829311068, 'units': 50}. Best is trial 19 with value: 0.9045053124427795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_20/dense_40/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_20/dense_40/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_20/dense_40/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8310 - accuracy: 0.6616 - tf_f1: 0.5253 - val_loss: 1.0003 - val_accuracy: 0.6242 - val_tf_f1: 0.6571\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4537 - accuracy: 0.8177 - tf_f1: 0.7023 - val_loss: 1.0149 - val_accuracy: 0.6106 - val_tf_f1: 0.7350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:48:32,082]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_21/dense_42/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_21/dense_42/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_21/dense_42/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7999 - accuracy: 0.6739 - tf_f1: 0.5400 - val_loss: 1.0175 - val_accuracy: 0.6386 - val_tf_f1: 0.6694\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4420 - accuracy: 0.8212 - tf_f1: 0.7122 - val_loss: 1.0305 - val_accuracy: 0.6302 - val_tf_f1: 0.7431\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3433 - accuracy: 0.8605 - tf_f1: 0.7636 - val_loss: 0.9435 - val_accuracy: 0.7076 - val_tf_f1: 0.7807\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2968 - accuracy: 0.8799 - tf_f1: 0.7935 - val_loss: 1.2966 - val_accuracy: 0.5368 - val_tf_f1: 0.8033\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.2664 - accuracy: 0.8940 - tf_f1: 0.8114 - val_loss: 1.2467 - val_accuracy: 0.6056 - val_tf_f1: 0.8189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:50:33,269]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_22/dense_44/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_22/dense_44/embedding_lookup_sparse/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_22/dense_44/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7785 - accuracy: 0.6793 - tf_f1: 0.5532 - val_loss: 1.1747 - val_accuracy: 0.5656 - val_tf_f1: 0.6730\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.4391 - accuracy: 0.8213 - tf_f1: 0.7136 - val_loss: 0.9489 - val_accuracy: 0.6857 - val_tf_f1: 0.7447\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3557 - accuracy: 0.8559 - tf_f1: 0.7645 - val_loss: 1.2041 - val_accuracy: 0.6112 - val_tf_f1: 0.7799\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3040 - accuracy: 0.8774 - tf_f1: 0.7918 - val_loss: 1.1340 - val_accuracy: 0.6549 - val_tf_f1: 0.8022\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2735 - accuracy: 0.8919 - tf_f1: 0.8109 - val_loss: 1.0985 - val_accuracy: 0.7075 - val_tf_f1: 0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:52:35,330]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_23/dense_46/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_23/dense_46/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_23/dense_46/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8217 - accuracy: 0.6659 - tf_f1: 0.5385 - val_loss: 0.8973 - val_accuracy: 0.6577 - val_tf_f1: 0.6635\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4497 - accuracy: 0.8176 - tf_f1: 0.7073 - val_loss: 0.9356 - val_accuracy: 0.6857 - val_tf_f1: 0.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:53:24,025]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_24/dense_48/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_24/dense_48/embedding_lookup_sparse/Reshape:0\", shape=(None, 37), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_24/dense_48/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8750 - accuracy: 0.6475 - tf_f1: 0.5141 - val_loss: 1.0897 - val_accuracy: 0.5218 - val_tf_f1: 0.6394\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4878 - accuracy: 0.8043 - tf_f1: 0.6839 - val_loss: 1.0308 - val_accuracy: 0.5926 - val_tf_f1: 0.7179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:54:12,917]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_25/dense_50/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_25/dense_50/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_25/dense_50/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8036 - accuracy: 0.6709 - tf_f1: 0.5393 - val_loss: 1.0330 - val_accuracy: 0.6025 - val_tf_f1: 0.6658\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4415 - accuracy: 0.8206 - tf_f1: 0.7092 - val_loss: 1.1547 - val_accuracy: 0.5669 - val_tf_f1: 0.7397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:55:01,641]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_26/dense_52/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_26/dense_52/embedding_lookup_sparse/Reshape:0\", shape=(None, 42), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_26/dense_52/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7954 - accuracy: 0.6728 - tf_f1: 0.5385 - val_loss: 1.0112 - val_accuracy: 0.6037 - val_tf_f1: 0.6683\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4395 - accuracy: 0.8210 - tf_f1: 0.7112 - val_loss: 1.0787 - val_accuracy: 0.5815 - val_tf_f1: 0.7418\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3525 - accuracy: 0.8558 - tf_f1: 0.7610 - val_loss: 1.1607 - val_accuracy: 0.5689 - val_tf_f1: 0.7767\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3028 - accuracy: 0.8759 - tf_f1: 0.7887 - val_loss: 1.2032 - val_accuracy: 0.5931 - val_tf_f1: 0.7989\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2765 - accuracy: 0.8879 - tf_f1: 0.8070 - val_loss: 1.2179 - val_accuracy: 0.6124 - val_tf_f1: 0.8145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:57:02,200]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_27/dense_54/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_27/dense_54/embedding_lookup_sparse/Reshape:0\", shape=(None, 35), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_27/dense_54/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8374 - accuracy: 0.6617 - tf_f1: 0.5293 - val_loss: 1.0105 - val_accuracy: 0.5697 - val_tf_f1: 0.6553\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4645 - accuracy: 0.8127 - tf_f1: 0.6984 - val_loss: 1.1410 - val_accuracy: 0.6100 - val_tf_f1: 0.7307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:57:51,236]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_28/dense_56/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_28/dense_56/embedding_lookup_sparse/Reshape:0\", shape=(None, 28), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_28/dense_56/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8118 - accuracy: 0.6666 - tf_f1: 0.5366 - val_loss: 1.1931 - val_accuracy: 0.5077 - val_tf_f1: 0.6594\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4701 - accuracy: 0.8085 - tf_f1: 0.6998 - val_loss: 1.0950 - val_accuracy: 0.5669 - val_tf_f1: 0.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:58:40,363]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_29/dense_58/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_29/dense_58/embedding_lookup_sparse/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_29/dense_58/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8188 - accuracy: 0.6628 - tf_f1: 0.5289 - val_loss: 1.1217 - val_accuracy: 0.5604 - val_tf_f1: 0.6578\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4730 - accuracy: 0.8079 - tf_f1: 0.6986 - val_loss: 1.2447 - val_accuracy: 0.4762 - val_tf_f1: 0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 03:59:29,077]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_30/dense_60/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_30/dense_60/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_30/dense_60/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8899 - accuracy: 0.6438 - tf_f1: 0.5108 - val_loss: 0.9268 - val_accuracy: 0.6414 - val_tf_f1: 0.6398\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4921 - accuracy: 0.8037 - tf_f1: 0.6860 - val_loss: 0.8844 - val_accuracy: 0.6757 - val_tf_f1: 0.7205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:00:17,843]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_31/dense_62/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_31/dense_62/embedding_lookup_sparse/Reshape:0\", shape=(None, 14), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_31/dense_62/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8488 - accuracy: 0.6511 - tf_f1: 0.5235 - val_loss: 1.0527 - val_accuracy: 0.6018 - val_tf_f1: 0.6450\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5466 - accuracy: 0.7818 - tf_f1: 0.6837 - val_loss: 1.1005 - val_accuracy: 0.6116 - val_tf_f1: 0.7106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:01:06,690]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_32/dense_64/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_32/dense_64/embedding_lookup_sparse/Reshape:0\", shape=(None, 23), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_32/dense_64/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8167 - accuracy: 0.6643 - tf_f1: 0.5395 - val_loss: 1.0502 - val_accuracy: 0.6310 - val_tf_f1: 0.6605\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4876 - accuracy: 0.8037 - tf_f1: 0.7015 - val_loss: 0.9996 - val_accuracy: 0.6734 - val_tf_f1: 0.7306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:01:55,398]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_33/dense_66/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_33/dense_66/embedding_lookup_sparse/Reshape:0\", shape=(None, 14), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_33/dense_66/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8188 - accuracy: 0.6620 - tf_f1: 0.5432 - val_loss: 1.2079 - val_accuracy: 0.4909 - val_tf_f1: 0.6552\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5374 - accuracy: 0.7874 - tf_f1: 0.6909 - val_loss: 1.0876 - val_accuracy: 0.6258 - val_tf_f1: 0.7177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:02:44,123]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_34/dense_68/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_34/dense_68/embedding_lookup_sparse/Reshape:0\", shape=(None, 31), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_34/dense_68/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7899 - accuracy: 0.6742 - tf_f1: 0.5445 - val_loss: 1.0493 - val_accuracy: 0.5876 - val_tf_f1: 0.6688\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4516 - accuracy: 0.8159 - tf_f1: 0.7099 - val_loss: 1.1264 - val_accuracy: 0.5244 - val_tf_f1: 0.7386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:03:32,750]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_35/dense_70/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_35/dense_70/embedding_lookup_sparse/Reshape:0\", shape=(None, 24), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_35/dense_70/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8120 - accuracy: 0.6698 - tf_f1: 0.5430 - val_loss: 0.9418 - val_accuracy: 0.6382 - val_tf_f1: 0.6664\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4585 - accuracy: 0.8149 - tf_f1: 0.7087 - val_loss: 0.9360 - val_accuracy: 0.6783 - val_tf_f1: 0.7395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:04:21,443]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_36/dense_72/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_36/dense_72/embedding_lookup_sparse/Reshape:0\", shape=(None, 34), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_36/dense_72/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8141 - accuracy: 0.6649 - tf_f1: 0.5344 - val_loss: 0.9027 - val_accuracy: 0.7001 - val_tf_f1: 0.6626\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4835 - accuracy: 0.8056 - tf_f1: 0.7046 - val_loss: 1.0066 - val_accuracy: 0.6579 - val_tf_f1: 0.7332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:05:10,381]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_37/dense_74/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_37/dense_74/embedding_lookup_sparse/Reshape:0\", shape=(None, 29), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_37/dense_74/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7636 - accuracy: 0.6847 - tf_f1: 0.5629 - val_loss: 1.0613 - val_accuracy: 0.5624 - val_tf_f1: 0.6795\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4495 - accuracy: 0.8153 - tf_f1: 0.7170 - val_loss: 1.2158 - val_accuracy: 0.5141 - val_tf_f1: 0.7429\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3621 - accuracy: 0.8509 - tf_f1: 0.7605 - val_loss: 1.0056 - val_accuracy: 0.6987 - val_tf_f1: 0.7764\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3221 - accuracy: 0.8683 - tf_f1: 0.7883 - val_loss: 1.0839 - val_accuracy: 0.6853 - val_tf_f1: 0.7982\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2927 - accuracy: 0.8818 - tf_f1: 0.8065 - val_loss: 1.2675 - val_accuracy: 0.6084 - val_tf_f1: 0.8133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:07:11,786]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_38/dense_76/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_38/dense_76/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_38/dense_76/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 26s 5ms/step - loss: 0.7867 - accuracy: 0.6750 - tf_f1: 0.5471 - val_loss: 1.0242 - val_accuracy: 0.5933 - val_tf_f1: 0.6708\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4504 - accuracy: 0.8178 - tf_f1: 0.7121 - val_loss: 1.0318 - val_accuracy: 0.6351 - val_tf_f1: 0.7422\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3657 - accuracy: 0.8508 - tf_f1: 0.7613 - val_loss: 1.1048 - val_accuracy: 0.6252 - val_tf_f1: 0.7764\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3277 - accuracy: 0.8678 - tf_f1: 0.7876 - val_loss: 1.4407 - val_accuracy: 0.4541 - val_tf_f1: 0.7961\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3044 - accuracy: 0.8770 - tf_f1: 0.8028 - val_loss: 1.1495 - val_accuracy: 0.6432 - val_tf_f1: 0.8097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:09:13,513]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_39/dense_78/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_39/dense_78/embedding_lookup_sparse/Reshape:0\", shape=(None, 39), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_39/dense_78/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 26s 5ms/step - loss: 0.7757 - accuracy: 0.6819 - tf_f1: 0.5564 - val_loss: 1.0353 - val_accuracy: 0.6135 - val_tf_f1: 0.6776\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4450 - accuracy: 0.8187 - tf_f1: 0.7171 - val_loss: 0.9949 - val_accuracy: 0.6573 - val_tf_f1: 0.7461\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3654 - accuracy: 0.8507 - tf_f1: 0.7646 - val_loss: 1.2057 - val_accuracy: 0.5563 - val_tf_f1: 0.7784\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3179 - accuracy: 0.8711 - tf_f1: 0.7893 - val_loss: 1.6589 - val_accuracy: 0.5117 - val_tf_f1: 0.7981\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2876 - accuracy: 0.8835 - tf_f1: 0.8054 - val_loss: 1.4091 - val_accuracy: 0.5215 - val_tf_f1: 0.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:11:15,329]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_40/dense_80/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_40/dense_80/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_40/dense_80/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8056 - accuracy: 0.6718 - tf_f1: 0.5421 - val_loss: 1.0931 - val_accuracy: 0.5364 - val_tf_f1: 0.6652\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4372 - accuracy: 0.8221 - tf_f1: 0.7078 - val_loss: 1.0269 - val_accuracy: 0.6406 - val_tf_f1: 0.7403\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3349 - accuracy: 0.8645 - tf_f1: 0.7618 - val_loss: 1.0173 - val_accuracy: 0.6607 - val_tf_f1: 0.7797\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2829 - accuracy: 0.8855 - tf_f1: 0.7930 - val_loss: 1.2989 - val_accuracy: 0.5591 - val_tf_f1: 0.8036\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2483 - accuracy: 0.9020 - tf_f1: 0.8125 - val_loss: 1.1957 - val_accuracy: 0.6430 - val_tf_f1: 0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:13:15,864]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_41/dense_82/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_41/dense_82/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_41/dense_82/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8202 - accuracy: 0.6642 - tf_f1: 0.5317 - val_loss: 1.0306 - val_accuracy: 0.5976 - val_tf_f1: 0.6595\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4655 - accuracy: 0.8113 - tf_f1: 0.7017 - val_loss: 1.0108 - val_accuracy: 0.6390 - val_tf_f1: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:14:04,538]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_42/dense_84/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_42/dense_84/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_42/dense_84/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8162 - accuracy: 0.6669 - tf_f1: 0.5416 - val_loss: 0.8597 - val_accuracy: 0.6722 - val_tf_f1: 0.6635\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4475 - accuracy: 0.8183 - tf_f1: 0.7079 - val_loss: 0.9340 - val_accuracy: 0.6789 - val_tf_f1: 0.7401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:14:53,222]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_43/dense_86/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_43/dense_86/embedding_lookup_sparse/Reshape:0\", shape=(None, 43), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_43/dense_86/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8309 - accuracy: 0.6621 - tf_f1: 0.5317 - val_loss: 1.0053 - val_accuracy: 0.5882 - val_tf_f1: 0.6579\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4658 - accuracy: 0.8127 - tf_f1: 0.7010 - val_loss: 1.0441 - val_accuracy: 0.5811 - val_tf_f1: 0.7321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:15:41,868]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_44/dense_88/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_44/dense_88/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_44/dense_88/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7885 - accuracy: 0.6760 - tf_f1: 0.5462 - val_loss: 1.0439 - val_accuracy: 0.5702 - val_tf_f1: 0.6710\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4457 - accuracy: 0.8190 - tf_f1: 0.7121 - val_loss: 1.1593 - val_accuracy: 0.5386 - val_tf_f1: 0.7409\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3596 - accuracy: 0.8536 - tf_f1: 0.7595 - val_loss: 1.0984 - val_accuracy: 0.6254 - val_tf_f1: 0.7755\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3144 - accuracy: 0.8718 - tf_f1: 0.7874 - val_loss: 1.1465 - val_accuracy: 0.6100 - val_tf_f1: 0.7974\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2829 - accuracy: 0.8860 - tf_f1: 0.8057 - val_loss: 1.1224 - val_accuracy: 0.6638 - val_tf_f1: 0.8133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:17:42,590]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_45/dense_90/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_45/dense_90/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_45/dense_90/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7804 - accuracy: 0.6786 - tf_f1: 0.5516 - val_loss: 0.8568 - val_accuracy: 0.6942 - val_tf_f1: 0.6771\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4309 - accuracy: 0.8245 - tf_f1: 0.7199 - val_loss: 1.1165 - val_accuracy: 0.5759 - val_tf_f1: 0.7488\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3387 - accuracy: 0.8611 - tf_f1: 0.7676 - val_loss: 1.0098 - val_accuracy: 0.6761 - val_tf_f1: 0.7839\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2927 - accuracy: 0.8819 - tf_f1: 0.7962 - val_loss: 1.1276 - val_accuracy: 0.6507 - val_tf_f1: 0.8067\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2605 - accuracy: 0.8972 - tf_f1: 0.8154 - val_loss: 1.1617 - val_accuracy: 0.6559 - val_tf_f1: 0.8230\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2382 - accuracy: 0.9066 - tf_f1: 0.8295 - val_loss: 1.1391 - val_accuracy: 0.6956 - val_tf_f1: 0.8355\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2171 - accuracy: 0.9166 - tf_f1: 0.8409 - val_loss: 1.2521 - val_accuracy: 0.6715 - val_tf_f1: 0.8457\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2017 - accuracy: 0.9238 - tf_f1: 0.8501 - val_loss: 1.4057 - val_accuracy: 0.6139 - val_tf_f1: 0.8539\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1875 - accuracy: 0.9296 - tf_f1: 0.8575 - val_loss: 1.3504 - val_accuracy: 0.6717 - val_tf_f1: 0.8609\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1767 - accuracy: 0.9345 - tf_f1: 0.8641 - val_loss: 1.3494 - val_accuracy: 0.6716 - val_tf_f1: 0.8670\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1650 - accuracy: 0.9394 - tf_f1: 0.8698 - val_loss: 1.4175 - val_accuracy: 0.6736 - val_tf_f1: 0.8724\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1571 - accuracy: 0.9426 - tf_f1: 0.8749 - val_loss: 1.4470 - val_accuracy: 0.6769 - val_tf_f1: 0.8772\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1485 - accuracy: 0.9464 - tf_f1: 0.8794 - val_loss: 1.5599 - val_accuracy: 0.6312 - val_tf_f1: 0.8814\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1431 - accuracy: 0.9486 - tf_f1: 0.8833 - val_loss: 1.6363 - val_accuracy: 0.6367 - val_tf_f1: 0.8850\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1342 - accuracy: 0.9520 - tf_f1: 0.8868 - val_loss: 1.5524 - val_accuracy: 0.6798 - val_tf_f1: 0.8885\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1306 - accuracy: 0.9531 - tf_f1: 0.8901 - val_loss: 1.5738 - val_accuracy: 0.6946 - val_tf_f1: 0.8917\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1232 - accuracy: 0.9556 - tf_f1: 0.8932 - val_loss: 1.6485 - val_accuracy: 0.6661 - val_tf_f1: 0.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:24:29,768]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 16.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_46/dense_92/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_46/dense_92/embedding_lookup_sparse/Reshape:0\", shape=(None, 42), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_46/dense_92/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7872 - accuracy: 0.6764 - tf_f1: 0.5482 - val_loss: 1.0177 - val_accuracy: 0.6166 - val_tf_f1: 0.6724\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4427 - accuracy: 0.8199 - tf_f1: 0.7134 - val_loss: 1.0690 - val_accuracy: 0.6317 - val_tf_f1: 0.7437\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3507 - accuracy: 0.8576 - tf_f1: 0.7632 - val_loss: 1.1280 - val_accuracy: 0.6240 - val_tf_f1: 0.7793\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3061 - accuracy: 0.8757 - tf_f1: 0.7911 - val_loss: 1.1105 - val_accuracy: 0.6216 - val_tf_f1: 0.8012\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2768 - accuracy: 0.8885 - tf_f1: 0.8095 - val_loss: 1.1079 - val_accuracy: 0.6852 - val_tf_f1: 0.8171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:26:30,116]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_47/dense_94/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_47/dense_94/embedding_lookup_sparse/Reshape:0\", shape=(None, 26), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_47/dense_94/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7818 - accuracy: 0.6785 - tf_f1: 0.5514 - val_loss: 1.0085 - val_accuracy: 0.5711 - val_tf_f1: 0.6737\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4362 - accuracy: 0.8217 - tf_f1: 0.7147 - val_loss: 0.9114 - val_accuracy: 0.7016 - val_tf_f1: 0.7458\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3496 - accuracy: 0.8571 - tf_f1: 0.7659 - val_loss: 0.9984 - val_accuracy: 0.7019 - val_tf_f1: 0.7819\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3057 - accuracy: 0.8753 - tf_f1: 0.7939 - val_loss: 1.0597 - val_accuracy: 0.6841 - val_tf_f1: 0.8040\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2727 - accuracy: 0.8903 - tf_f1: 0.8125 - val_loss: 1.0887 - val_accuracy: 0.7113 - val_tf_f1: 0.8201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:28:31,089]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_48/dense_96/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_48/dense_96/embedding_lookup_sparse/Reshape:0\", shape=(None, 21), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_48/dense_96/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7924 - accuracy: 0.6742 - tf_f1: 0.5445 - val_loss: 0.9517 - val_accuracy: 0.6434 - val_tf_f1: 0.6702\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4578 - accuracy: 0.8132 - tf_f1: 0.7112 - val_loss: 0.9820 - val_accuracy: 0.6409 - val_tf_f1: 0.7403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:29:19,853]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_49/dense_98/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_49/dense_98/embedding_lookup_sparse/Reshape:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_49/dense_98/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8128 - accuracy: 0.6662 - tf_f1: 0.5432 - val_loss: 1.0436 - val_accuracy: 0.5903 - val_tf_f1: 0.6614\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5300 - accuracy: 0.7870 - tf_f1: 0.6968 - val_loss: 1.3711 - val_accuracy: 0.4123 - val_tf_f1: 0.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:30:08,716]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_50/dense_100/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_50/dense_100/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_50/dense_100/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7636 - accuracy: 0.6843 - tf_f1: 0.5633 - val_loss: 1.0818 - val_accuracy: 0.5459 - val_tf_f1: 0.6792\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4339 - accuracy: 0.8219 - tf_f1: 0.7182 - val_loss: 1.0584 - val_accuracy: 0.6311 - val_tf_f1: 0.7474\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3454 - accuracy: 0.8577 - tf_f1: 0.7667 - val_loss: 1.0937 - val_accuracy: 0.6408 - val_tf_f1: 0.7821\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3012 - accuracy: 0.8777 - tf_f1: 0.7938 - val_loss: 1.1489 - val_accuracy: 0.6453 - val_tf_f1: 0.8041\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2686 - accuracy: 0.8919 - tf_f1: 0.8125 - val_loss: 1.2543 - val_accuracy: 0.6175 - val_tf_f1: 0.8198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:32:09,235]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_51/dense_102/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_51/dense_102/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_51/dense_102/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7794 - accuracy: 0.6826 - tf_f1: 0.5556 - val_loss: 1.0785 - val_accuracy: 0.5374 - val_tf_f1: 0.6766\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4176 - accuracy: 0.8314 - tf_f1: 0.7186 - val_loss: 1.0709 - val_accuracy: 0.5909 - val_tf_f1: 0.7500\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3190 - accuracy: 0.8701 - tf_f1: 0.7705 - val_loss: 1.2087 - val_accuracy: 0.5656 - val_tf_f1: 0.7866\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2697 - accuracy: 0.8912 - tf_f1: 0.7988 - val_loss: 1.2183 - val_accuracy: 0.6072 - val_tf_f1: 0.8097\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2369 - accuracy: 0.9063 - tf_f1: 0.8186 - val_loss: 1.1432 - val_accuracy: 0.6499 - val_tf_f1: 0.8268\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2091 - accuracy: 0.9192 - tf_f1: 0.8339 - val_loss: 1.1836 - val_accuracy: 0.6635 - val_tf_f1: 0.8404\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1875 - accuracy: 0.9289 - tf_f1: 0.8462 - val_loss: 1.1870 - val_accuracy: 0.7401 - val_tf_f1: 0.8517\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1732 - accuracy: 0.9355 - tf_f1: 0.8567 - val_loss: 1.2704 - val_accuracy: 0.6723 - val_tf_f1: 0.8609\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1563 - accuracy: 0.9432 - tf_f1: 0.8649 - val_loss: 1.4879 - val_accuracy: 0.5941 - val_tf_f1: 0.8684\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1436 - accuracy: 0.9484 - tf_f1: 0.8716 - val_loss: 1.3471 - val_accuracy: 0.7047 - val_tf_f1: 0.8748\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1346 - accuracy: 0.9523 - tf_f1: 0.8779 - val_loss: 1.3986 - val_accuracy: 0.6805 - val_tf_f1: 0.8807\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1263 - accuracy: 0.9555 - tf_f1: 0.8833 - val_loss: 1.5921 - val_accuracy: 0.6168 - val_tf_f1: 0.8856\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1184 - accuracy: 0.9584 - tf_f1: 0.8878 - val_loss: 1.5257 - val_accuracy: 0.6577 - val_tf_f1: 0.8899\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1126 - accuracy: 0.9603 - tf_f1: 0.8919 - val_loss: 1.5561 - val_accuracy: 0.6639 - val_tf_f1: 0.8938\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1074 - accuracy: 0.9622 - tf_f1: 0.8956 - val_loss: 1.5673 - val_accuracy: 0.6857 - val_tf_f1: 0.8973\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1028 - accuracy: 0.9640 - tf_f1: 0.8990 - val_loss: 1.5821 - val_accuracy: 0.6767 - val_tf_f1: 0.9006\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1008 - accuracy: 0.9650 - tf_f1: 0.9020 - val_loss: 1.6109 - val_accuracy: 0.6664 - val_tf_f1: 0.9034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:38:57,903]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 16.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_52/dense_104/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_52/dense_104/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_52/dense_104/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8117 - accuracy: 0.6677 - tf_f1: 0.5404 - val_loss: 0.9052 - val_accuracy: 0.6587 - val_tf_f1: 0.6659\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4481 - accuracy: 0.8176 - tf_f1: 0.7094 - val_loss: 0.9404 - val_accuracy: 0.6693 - val_tf_f1: 0.7405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:39:46,737]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_53/dense_106/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_53/dense_106/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_53/dense_106/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7933 - accuracy: 0.6747 - tf_f1: 0.5416 - val_loss: 0.9191 - val_accuracy: 0.6555 - val_tf_f1: 0.6710\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4324 - accuracy: 0.8248 - tf_f1: 0.7152 - val_loss: 1.0118 - val_accuracy: 0.6276 - val_tf_f1: 0.7460\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3369 - accuracy: 0.8624 - tf_f1: 0.7661 - val_loss: 1.3998 - val_accuracy: 0.4527 - val_tf_f1: 0.7809\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2853 - accuracy: 0.8835 - tf_f1: 0.7923 - val_loss: 1.0948 - val_accuracy: 0.6494 - val_tf_f1: 0.8034\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2531 - accuracy: 0.8985 - tf_f1: 0.8125 - val_loss: 1.0742 - val_accuracy: 0.7016 - val_tf_f1: 0.8209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:41:47,286]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_54/dense_108/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_54/dense_108/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_54/dense_108/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7805 - accuracy: 0.6774 - tf_f1: 0.5514 - val_loss: 1.0337 - val_accuracy: 0.6028 - val_tf_f1: 0.6730\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4356 - accuracy: 0.8216 - tf_f1: 0.7144 - val_loss: 1.0509 - val_accuracy: 0.6524 - val_tf_f1: 0.7450\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3448 - accuracy: 0.8575 - tf_f1: 0.7647 - val_loss: 1.2499 - val_accuracy: 0.5508 - val_tf_f1: 0.7798\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2938 - accuracy: 0.8799 - tf_f1: 0.7914 - val_loss: 1.3151 - val_accuracy: 0.5326 - val_tf_f1: 0.8015\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2636 - accuracy: 0.8945 - tf_f1: 0.8098 - val_loss: 1.2975 - val_accuracy: 0.6017 - val_tf_f1: 0.8175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:43:47,688]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_55/dense_110/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_55/dense_110/embedding_lookup_sparse/Reshape:0\", shape=(None, 41), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_55/dense_110/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8243 - accuracy: 0.6647 - tf_f1: 0.5314 - val_loss: 1.0599 - val_accuracy: 0.5794 - val_tf_f1: 0.6589\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4566 - accuracy: 0.8144 - tf_f1: 0.7019 - val_loss: 0.8154 - val_accuracy: 0.7434 - val_tf_f1: 0.7350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:44:36,291]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_56/dense_112/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_56/dense_112/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_56/dense_112/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7876 - accuracy: 0.6767 - tf_f1: 0.5448 - val_loss: 1.3029 - val_accuracy: 0.3002 - val_tf_f1: 0.6642\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4405 - accuracy: 0.8209 - tf_f1: 0.7029 - val_loss: 1.0455 - val_accuracy: 0.6323 - val_tf_f1: 0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:45:25,110]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_57/dense_114/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_57/dense_114/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_57/dense_114/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8455 - accuracy: 0.6586 - tf_f1: 0.5267 - val_loss: 0.8757 - val_accuracy: 0.6710 - val_tf_f1: 0.6552\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4636 - accuracy: 0.8142 - tf_f1: 0.7011 - val_loss: 0.8747 - val_accuracy: 0.6914 - val_tf_f1: 0.7342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:46:13,974]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_58/dense_116/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_58/dense_116/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_58/dense_116/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8078 - accuracy: 0.6688 - tf_f1: 0.5350 - val_loss: 0.9616 - val_accuracy: 0.5909 - val_tf_f1: 0.6637\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4436 - accuracy: 0.8202 - tf_f1: 0.7074 - val_loss: 0.9764 - val_accuracy: 0.6567 - val_tf_f1: 0.7398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:47:02,647]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_59/dense_118/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_59/dense_118/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_59/dense_118/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8157 - accuracy: 0.6667 - tf_f1: 0.5382 - val_loss: 0.9151 - val_accuracy: 0.6607 - val_tf_f1: 0.6639\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4584 - accuracy: 0.8139 - tf_f1: 0.7071 - val_loss: 1.2410 - val_accuracy: 0.5248 - val_tf_f1: 0.7358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:47:51,244]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_60/dense_120/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_60/dense_120/embedding_lookup_sparse/Reshape:0\", shape=(None, 38), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_60/dense_120/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.9955 - accuracy: 0.6080 - tf_f1: 0.4796 - val_loss: 0.8828 - val_accuracy: 0.6845 - val_tf_f1: 0.6041\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5627 - accuracy: 0.7808 - tf_f1: 0.6547 - val_loss: 0.9585 - val_accuracy: 0.6217 - val_tf_f1: 0.6909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:48:40,119]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_61/dense_122/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_61/dense_122/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_61/dense_122/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 26s 6ms/step - loss: 0.7917 - accuracy: 0.6772 - tf_f1: 0.5482 - val_loss: 0.9139 - val_accuracy: 0.6558 - val_tf_f1: 0.6757\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4330 - accuracy: 0.8239 - tf_f1: 0.7181 - val_loss: 1.1672 - val_accuracy: 0.5326 - val_tf_f1: 0.7468\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3349 - accuracy: 0.8638 - tf_f1: 0.7658 - val_loss: 0.9863 - val_accuracy: 0.6748 - val_tf_f1: 0.7829\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2864 - accuracy: 0.8843 - tf_f1: 0.7957 - val_loss: 1.2553 - val_accuracy: 0.5502 - val_tf_f1: 0.8058\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2545 - accuracy: 0.8989 - tf_f1: 0.8142 - val_loss: 1.2233 - val_accuracy: 0.5828 - val_tf_f1: 0.8217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:50:42,255]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_62/dense_124/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_62/dense_124/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_62/dense_124/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7919 - accuracy: 0.6769 - tf_f1: 0.5503 - val_loss: 0.9372 - val_accuracy: 0.6136 - val_tf_f1: 0.6732\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4296 - accuracy: 0.8240 - tf_f1: 0.7156 - val_loss: 1.0229 - val_accuracy: 0.5963 - val_tf_f1: 0.7461\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3325 - accuracy: 0.8640 - tf_f1: 0.7661 - val_loss: 1.0360 - val_accuracy: 0.6481 - val_tf_f1: 0.7830\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2800 - accuracy: 0.8872 - tf_f1: 0.7959 - val_loss: 1.2081 - val_accuracy: 0.5747 - val_tf_f1: 0.8065\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2416 - accuracy: 0.9050 - tf_f1: 0.8155 - val_loss: 1.0290 - val_accuracy: 0.7224 - val_tf_f1: 0.8242\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2105 - accuracy: 0.9190 - tf_f1: 0.8319 - val_loss: 1.3852 - val_accuracy: 0.5716 - val_tf_f1: 0.8381\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1871 - accuracy: 0.9298 - tf_f1: 0.8437 - val_loss: 1.2208 - val_accuracy: 0.7222 - val_tf_f1: 0.8494\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1674 - accuracy: 0.9384 - tf_f1: 0.8546 - val_loss: 1.2579 - val_accuracy: 0.7059 - val_tf_f1: 0.8593\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1545 - accuracy: 0.9439 - tf_f1: 0.8636 - val_loss: 1.3342 - val_accuracy: 0.6581 - val_tf_f1: 0.8673\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1422 - accuracy: 0.9491 - tf_f1: 0.8708 - val_loss: 1.3595 - val_accuracy: 0.7016 - val_tf_f1: 0.8742\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1324 - accuracy: 0.9528 - tf_f1: 0.8773 - val_loss: 1.4384 - val_accuracy: 0.6797 - val_tf_f1: 0.8801\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1251 - accuracy: 0.9556 - tf_f1: 0.8827 - val_loss: 1.4100 - val_accuracy: 0.6794 - val_tf_f1: 0.8852\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1181 - accuracy: 0.9585 - tf_f1: 0.8875 - val_loss: 1.4916 - val_accuracy: 0.7241 - val_tf_f1: 0.8898\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1123 - accuracy: 0.9604 - tf_f1: 0.8920 - val_loss: 1.4778 - val_accuracy: 0.6971 - val_tf_f1: 0.8939\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1092 - accuracy: 0.9618 - tf_f1: 0.8958 - val_loss: 1.5018 - val_accuracy: 0.7233 - val_tf_f1: 0.8976\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1034 - accuracy: 0.9639 - tf_f1: 0.8993 - val_loss: 1.5955 - val_accuracy: 0.6788 - val_tf_f1: 0.9008\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1002 - accuracy: 0.9648 - tf_f1: 0.9023 - val_loss: 1.5744 - val_accuracy: 0.6956 - val_tf_f1: 0.9037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:57:30,857]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 16.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_63/dense_126/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_63/dense_126/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_63/dense_126/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8230 - accuracy: 0.6661 - tf_f1: 0.5354 - val_loss: 1.1259 - val_accuracy: 0.5194 - val_tf_f1: 0.6596\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4516 - accuracy: 0.8185 - tf_f1: 0.7025 - val_loss: 1.0650 - val_accuracy: 0.5907 - val_tf_f1: 0.7349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 04:58:19,985]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_64/dense_128/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_64/dense_128/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_64/dense_128/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7793 - accuracy: 0.6783 - tf_f1: 0.5488 - val_loss: 1.1217 - val_accuracy: 0.5823 - val_tf_f1: 0.6731\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4253 - accuracy: 0.8257 - tf_f1: 0.7154 - val_loss: 1.0667 - val_accuracy: 0.6065 - val_tf_f1: 0.7461\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3344 - accuracy: 0.8632 - tf_f1: 0.7660 - val_loss: 1.0377 - val_accuracy: 0.6654 - val_tf_f1: 0.7829\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2900 - accuracy: 0.8815 - tf_f1: 0.7954 - val_loss: 1.1433 - val_accuracy: 0.6265 - val_tf_f1: 0.8057\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 26s 5ms/step - loss: 0.2592 - accuracy: 0.8960 - tf_f1: 0.8142 - val_loss: 1.2614 - val_accuracy: 0.5953 - val_tf_f1: 0.8216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:00:23,782]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_65/dense_130/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_65/dense_130/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_65/dense_130/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 26s 5ms/step - loss: 0.7771 - accuracy: 0.6825 - tf_f1: 0.5578 - val_loss: 0.9426 - val_accuracy: 0.6487 - val_tf_f1: 0.6797\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4224 - accuracy: 0.8280 - tf_f1: 0.7215 - val_loss: 1.0183 - val_accuracy: 0.6132 - val_tf_f1: 0.7515\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3258 - accuracy: 0.8675 - tf_f1: 0.7713 - val_loss: 1.1533 - val_accuracy: 0.5802 - val_tf_f1: 0.7871\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2692 - accuracy: 0.8924 - tf_f1: 0.7996 - val_loss: 1.2736 - val_accuracy: 0.5874 - val_tf_f1: 0.8103\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2323 - accuracy: 0.9091 - tf_f1: 0.8193 - val_loss: 1.1467 - val_accuracy: 0.6616 - val_tf_f1: 0.8277\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2049 - accuracy: 0.9216 - tf_f1: 0.8351 - val_loss: 1.2240 - val_accuracy: 0.6716 - val_tf_f1: 0.8416\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1818 - accuracy: 0.9322 - tf_f1: 0.8475 - val_loss: 1.2419 - val_accuracy: 0.7002 - val_tf_f1: 0.8530\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1666 - accuracy: 0.9381 - tf_f1: 0.8579 - val_loss: 1.5203 - val_accuracy: 0.6061 - val_tf_f1: 0.8619\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1522 - accuracy: 0.9447 - tf_f1: 0.8657 - val_loss: 1.4374 - val_accuracy: 0.6437 - val_tf_f1: 0.8694\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1391 - accuracy: 0.9499 - tf_f1: 0.8728 - val_loss: 1.4699 - val_accuracy: 0.6600 - val_tf_f1: 0.8759\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1320 - accuracy: 0.9533 - tf_f1: 0.8789 - val_loss: 1.4384 - val_accuracy: 0.7094 - val_tf_f1: 0.8817\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 26s 5ms/step - loss: 0.1229 - accuracy: 0.9568 - tf_f1: 0.8844 - val_loss: 1.4915 - val_accuracy: 0.6910 - val_tf_f1: 0.8869\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1176 - accuracy: 0.9589 - tf_f1: 0.8892 - val_loss: 1.5502 - val_accuracy: 0.7214 - val_tf_f1: 0.8914\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1121 - accuracy: 0.9608 - tf_f1: 0.8935 - val_loss: 1.5858 - val_accuracy: 0.6835 - val_tf_f1: 0.8954\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1063 - accuracy: 0.9628 - tf_f1: 0.8972 - val_loss: 1.6066 - val_accuracy: 0.7076 - val_tf_f1: 0.8990\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1046 - accuracy: 0.9630 - tf_f1: 0.9006 - val_loss: 1.5787 - val_accuracy: 0.6875 - val_tf_f1: 0.9021\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1002 - accuracy: 0.9650 - tf_f1: 0.9035 - val_loss: 1.7403 - val_accuracy: 0.6302 - val_tf_f1: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:07:16,421]\u001b[0m Trial 65 finished with value: 0.9048206210136414 and parameters: {'lr': 0.07345220109155583, 'units': 47}. Best is trial 65 with value: 0.9048206210136414.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_66/dense_132/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_66/dense_132/embedding_lookup_sparse/Reshape:0\", shape=(None, 43), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_66/dense_132/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7851 - accuracy: 0.6771 - tf_f1: 0.5490 - val_loss: 1.0130 - val_accuracy: 0.5953 - val_tf_f1: 0.6720\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4292 - accuracy: 0.8248 - tf_f1: 0.7142 - val_loss: 1.0089 - val_accuracy: 0.6368 - val_tf_f1: 0.7458\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3298 - accuracy: 0.8646 - tf_f1: 0.7665 - val_loss: 1.0176 - val_accuracy: 0.6905 - val_tf_f1: 0.7836\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2855 - accuracy: 0.8851 - tf_f1: 0.7966 - val_loss: 1.1365 - val_accuracy: 0.6395 - val_tf_f1: 0.8072\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2547 - accuracy: 0.8990 - tf_f1: 0.8161 - val_loss: 1.1347 - val_accuracy: 0.6822 - val_tf_f1: 0.8238\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2286 - accuracy: 0.9107 - tf_f1: 0.8307 - val_loss: 1.1104 - val_accuracy: 0.7357 - val_tf_f1: 0.8371\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2104 - accuracy: 0.9191 - tf_f1: 0.8427 - val_loss: 1.2741 - val_accuracy: 0.6362 - val_tf_f1: 0.8475\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1924 - accuracy: 0.9272 - tf_f1: 0.8518 - val_loss: 1.2801 - val_accuracy: 0.6603 - val_tf_f1: 0.8559\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1779 - accuracy: 0.9341 - tf_f1: 0.8597 - val_loss: 1.3235 - val_accuracy: 0.7446 - val_tf_f1: 0.8634\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1685 - accuracy: 0.9382 - tf_f1: 0.8669 - val_loss: 1.4554 - val_accuracy: 0.6160 - val_tf_f1: 0.8697\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1599 - accuracy: 0.9417 - tf_f1: 0.8723 - val_loss: 1.3914 - val_accuracy: 0.6920 - val_tf_f1: 0.8750\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 26s 5ms/step - loss: 0.1524 - accuracy: 0.9441 - tf_f1: 0.8775 - val_loss: 1.5303 - val_accuracy: 0.6503 - val_tf_f1: 0.8796\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1446 - accuracy: 0.9481 - tf_f1: 0.8818 - val_loss: 1.4868 - val_accuracy: 0.6458 - val_tf_f1: 0.8837\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1363 - accuracy: 0.9511 - tf_f1: 0.8856 - val_loss: 1.5845 - val_accuracy: 0.6406 - val_tf_f1: 0.8874\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1322 - accuracy: 0.9526 - tf_f1: 0.8891 - val_loss: 1.5191 - val_accuracy: 0.7031 - val_tf_f1: 0.8908\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1258 - accuracy: 0.9550 - tf_f1: 0.8924 - val_loss: 1.5715 - val_accuracy: 0.6659 - val_tf_f1: 0.8939\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1250 - accuracy: 0.9556 - tf_f1: 0.8953 - val_loss: 1.5358 - val_accuracy: 0.7100 - val_tf_f1: 0.8968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:14:06,045]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 16.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_67/dense_134/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_67/dense_134/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_67/dense_134/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8678 - accuracy: 0.6481 - tf_f1: 0.5134 - val_loss: 0.9185 - val_accuracy: 0.6642 - val_tf_f1: 0.6440\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4790 - accuracy: 0.8061 - tf_f1: 0.6899 - val_loss: 0.9838 - val_accuracy: 0.6346 - val_tf_f1: 0.7236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:14:54,794]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_68/dense_136/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_68/dense_136/embedding_lookup_sparse/Reshape:0\", shape=(None, 41), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_68/dense_136/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8073 - accuracy: 0.6674 - tf_f1: 0.5380 - val_loss: 1.0070 - val_accuracy: 0.5965 - val_tf_f1: 0.6631\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4498 - accuracy: 0.8163 - tf_f1: 0.7059 - val_loss: 1.0522 - val_accuracy: 0.6320 - val_tf_f1: 0.7372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:15:43,533]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_69/dense_138/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_69/dense_138/embedding_lookup_sparse/Reshape:0\", shape=(None, 33), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_69/dense_138/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8243 - accuracy: 0.6607 - tf_f1: 0.5240 - val_loss: 0.8907 - val_accuracy: 0.6557 - val_tf_f1: 0.6572\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4807 - accuracy: 0.8057 - tf_f1: 0.7003 - val_loss: 1.2671 - val_accuracy: 0.4536 - val_tf_f1: 0.7279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:16:32,593]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_70/dense_140/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_70/dense_140/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_70/dense_140/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7739 - accuracy: 0.6837 - tf_f1: 0.5588 - val_loss: 1.0100 - val_accuracy: 0.6324 - val_tf_f1: 0.6806\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4190 - accuracy: 0.8286 - tf_f1: 0.7219 - val_loss: 1.0669 - val_accuracy: 0.6104 - val_tf_f1: 0.7521\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3191 - accuracy: 0.8696 - tf_f1: 0.7722 - val_loss: 1.1309 - val_accuracy: 0.6161 - val_tf_f1: 0.7886\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2669 - accuracy: 0.8929 - tf_f1: 0.8014 - val_loss: 1.0490 - val_accuracy: 0.6890 - val_tf_f1: 0.8126\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2299 - accuracy: 0.9097 - tf_f1: 0.8221 - val_loss: 1.2875 - val_accuracy: 0.5907 - val_tf_f1: 0.8299\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2002 - accuracy: 0.9236 - tf_f1: 0.8367 - val_loss: 1.1782 - val_accuracy: 0.6845 - val_tf_f1: 0.8434\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1803 - accuracy: 0.9332 - tf_f1: 0.8493 - val_loss: 1.2600 - val_accuracy: 0.6501 - val_tf_f1: 0.8545\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1625 - accuracy: 0.9403 - tf_f1: 0.8593 - val_loss: 1.3639 - val_accuracy: 0.6374 - val_tf_f1: 0.8635\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1479 - accuracy: 0.9463 - tf_f1: 0.8674 - val_loss: 1.4598 - val_accuracy: 0.6262 - val_tf_f1: 0.8710\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1375 - accuracy: 0.9509 - tf_f1: 0.8743 - val_loss: 1.4960 - val_accuracy: 0.6519 - val_tf_f1: 0.8774\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1278 - accuracy: 0.9544 - tf_f1: 0.8802 - val_loss: 1.4617 - val_accuracy: 0.7085 - val_tf_f1: 0.8831\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1211 - accuracy: 0.9571 - tf_f1: 0.8857 - val_loss: 1.4787 - val_accuracy: 0.7188 - val_tf_f1: 0.8882\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1141 - accuracy: 0.9598 - tf_f1: 0.8906 - val_loss: 1.5288 - val_accuracy: 0.7256 - val_tf_f1: 0.8928\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1105 - accuracy: 0.9611 - tf_f1: 0.8948 - val_loss: 1.6589 - val_accuracy: 0.6300 - val_tf_f1: 0.8966\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1067 - accuracy: 0.9624 - tf_f1: 0.8982 - val_loss: 1.5452 - val_accuracy: 0.7006 - val_tf_f1: 0.8999\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1011 - accuracy: 0.9644 - tf_f1: 0.9015 - val_loss: 1.5985 - val_accuracy: 0.6858 - val_tf_f1: 0.9030\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.0992 - accuracy: 0.9655 - tf_f1: 0.9045 - val_loss: 1.5920 - val_accuracy: 0.7098 - val_tf_f1: 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:23:20,029]\u001b[0m Trial 70 finished with value: 0.9058654308319092 and parameters: {'lr': 0.07441522157885706, 'units': 49}. Best is trial 70 with value: 0.9058654308319092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_71/dense_142/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_71/dense_142/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_71/dense_142/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7838 - accuracy: 0.6784 - tf_f1: 0.5538 - val_loss: 1.0426 - val_accuracy: 0.5771 - val_tf_f1: 0.6730\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4250 - accuracy: 0.8269 - tf_f1: 0.7153 - val_loss: 0.9701 - val_accuracy: 0.6450 - val_tf_f1: 0.7473\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3223 - accuracy: 0.8692 - tf_f1: 0.7686 - val_loss: 1.1830 - val_accuracy: 0.5773 - val_tf_f1: 0.7853\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2779 - accuracy: 0.8876 - tf_f1: 0.7975 - val_loss: 0.9998 - val_accuracy: 0.7163 - val_tf_f1: 0.8089\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2416 - accuracy: 0.9046 - tf_f1: 0.8184 - val_loss: 1.1795 - val_accuracy: 0.6689 - val_tf_f1: 0.8265\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2160 - accuracy: 0.9168 - tf_f1: 0.8336 - val_loss: 1.1565 - val_accuracy: 0.6944 - val_tf_f1: 0.8400\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1923 - accuracy: 0.9276 - tf_f1: 0.8458 - val_loss: 1.3527 - val_accuracy: 0.6283 - val_tf_f1: 0.8509\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1782 - accuracy: 0.9337 - tf_f1: 0.8554 - val_loss: 1.4342 - val_accuracy: 0.6309 - val_tf_f1: 0.8594\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1634 - accuracy: 0.9400 - tf_f1: 0.8632 - val_loss: 1.3433 - val_accuracy: 0.6786 - val_tf_f1: 0.8669\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1515 - accuracy: 0.9455 - tf_f1: 0.8702 - val_loss: 1.4638 - val_accuracy: 0.6290 - val_tf_f1: 0.8733\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1428 - accuracy: 0.9484 - tf_f1: 0.8760 - val_loss: 1.3939 - val_accuracy: 0.7195 - val_tf_f1: 0.8789\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1342 - accuracy: 0.9524 - tf_f1: 0.8816 - val_loss: 1.7610 - val_accuracy: 0.5855 - val_tf_f1: 0.8837\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1283 - accuracy: 0.9544 - tf_f1: 0.8857 - val_loss: 1.4937 - val_accuracy: 0.7121 - val_tf_f1: 0.8879\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1221 - accuracy: 0.9566 - tf_f1: 0.8900 - val_loss: 1.5980 - val_accuracy: 0.6485 - val_tf_f1: 0.8918\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1173 - accuracy: 0.9590 - tf_f1: 0.8935 - val_loss: 1.5084 - val_accuracy: 0.6896 - val_tf_f1: 0.8953\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1113 - accuracy: 0.9610 - tf_f1: 0.8969 - val_loss: 1.5779 - val_accuracy: 0.6814 - val_tf_f1: 0.8985\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1082 - accuracy: 0.9623 - tf_f1: 0.8999 - val_loss: 1.6320 - val_accuracy: 0.6833 - val_tf_f1: 0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:30:08,328]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 16.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_72/dense_144/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_72/dense_144/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_72/dense_144/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8029 - accuracy: 0.6720 - tf_f1: 0.5418 - val_loss: 0.9716 - val_accuracy: 0.6309 - val_tf_f1: 0.6684\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4316 - accuracy: 0.8248 - tf_f1: 0.7122 - val_loss: 0.9892 - val_accuracy: 0.6541 - val_tf_f1: 0.7446\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3322 - accuracy: 0.8656 - tf_f1: 0.7659 - val_loss: 1.1483 - val_accuracy: 0.5782 - val_tf_f1: 0.7824\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2796 - accuracy: 0.8872 - tf_f1: 0.7950 - val_loss: 1.1118 - val_accuracy: 0.6316 - val_tf_f1: 0.8060\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2445 - accuracy: 0.9034 - tf_f1: 0.8152 - val_loss: 1.1637 - val_accuracy: 0.6446 - val_tf_f1: 0.8234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:32:09,051]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_73/dense_146/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_73/dense_146/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_73/dense_146/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 1.3347 - accuracy: 0.4811 - tf_f1: 0.3801 - val_loss: 1.1157 - val_accuracy: 0.5745 - val_tf_f1: 0.4688\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.9293 - accuracy: 0.6590 - tf_f1: 0.5189 - val_loss: 0.9063 - val_accuracy: 0.6644 - val_tf_f1: 0.5612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:32:57,827]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_74/dense_148/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_74/dense_148/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_74/dense_148/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7677 - accuracy: 0.6844 - tf_f1: 0.5580 - val_loss: 1.0622 - val_accuracy: 0.5169 - val_tf_f1: 0.6783\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4219 - accuracy: 0.8277 - tf_f1: 0.7187 - val_loss: 0.9932 - val_accuracy: 0.6745 - val_tf_f1: 0.7500\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3293 - accuracy: 0.8657 - tf_f1: 0.7705 - val_loss: 1.4125 - val_accuracy: 0.4209 - val_tf_f1: 0.7847\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2854 - accuracy: 0.8851 - tf_f1: 0.7954 - val_loss: 1.0245 - val_accuracy: 0.7072 - val_tf_f1: 0.8068\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2527 - accuracy: 0.8996 - tf_f1: 0.8161 - val_loss: 1.1770 - val_accuracy: 0.6363 - val_tf_f1: 0.8237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:34:58,557]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_75/dense_150/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_75/dense_150/embedding_lookup_sparse/Reshape:0\", shape=(None, 12), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_75/dense_150/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8368 - accuracy: 0.6596 - tf_f1: 0.5385 - val_loss: 1.2793 - val_accuracy: 0.4319 - val_tf_f1: 0.6506\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.5284 - accuracy: 0.7880 - tf_f1: 0.6863 - val_loss: 1.0541 - val_accuracy: 0.5679 - val_tf_f1: 0.7137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:35:47,531]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_76/dense_152/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_76/dense_152/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_76/dense_152/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7930 - accuracy: 0.6759 - tf_f1: 0.5435 - val_loss: 1.1552 - val_accuracy: 0.4959 - val_tf_f1: 0.6693\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4362 - accuracy: 0.8226 - tf_f1: 0.7105 - val_loss: 1.1294 - val_accuracy: 0.5262 - val_tf_f1: 0.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:36:37,242]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_77/dense_154/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_77/dense_154/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_77/dense_154/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8128 - accuracy: 0.6671 - tf_f1: 0.5364 - val_loss: 0.9862 - val_accuracy: 0.6278 - val_tf_f1: 0.6626\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4476 - accuracy: 0.8176 - tf_f1: 0.7063 - val_loss: 1.1047 - val_accuracy: 0.5881 - val_tf_f1: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:37:26,061]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_78/dense_156/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_78/dense_156/embedding_lookup_sparse/Reshape:0\", shape=(None, 43), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_78/dense_156/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8178 - accuracy: 0.6637 - tf_f1: 0.5328 - val_loss: 0.9176 - val_accuracy: 0.6733 - val_tf_f1: 0.6606\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4678 - accuracy: 0.8105 - tf_f1: 0.7038 - val_loss: 0.8959 - val_accuracy: 0.7124 - val_tf_f1: 0.7349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:38:14,863]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_79/dense_158/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_79/dense_158/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_79/dense_158/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8179 - accuracy: 0.6662 - tf_f1: 0.5349 - val_loss: 1.1231 - val_accuracy: 0.5335 - val_tf_f1: 0.6603\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4426 - accuracy: 0.8214 - tf_f1: 0.7035 - val_loss: 0.9162 - val_accuracy: 0.6745 - val_tf_f1: 0.7378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:39:03,659]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_80/dense_160/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_80/dense_160/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_80/dense_160/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7892 - accuracy: 0.6762 - tf_f1: 0.5455 - val_loss: 1.0926 - val_accuracy: 0.5939 - val_tf_f1: 0.6718\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4327 - accuracy: 0.8243 - tf_f1: 0.7145 - val_loss: 0.9942 - val_accuracy: 0.6463 - val_tf_f1: 0.7456\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3355 - accuracy: 0.8635 - tf_f1: 0.7660 - val_loss: 1.1395 - val_accuracy: 0.6328 - val_tf_f1: 0.7827\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2888 - accuracy: 0.8831 - tf_f1: 0.7950 - val_loss: 1.1532 - val_accuracy: 0.6146 - val_tf_f1: 0.8055\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2580 - accuracy: 0.8978 - tf_f1: 0.8142 - val_loss: 1.1768 - val_accuracy: 0.6506 - val_tf_f1: 0.8220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:41:04,150]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_81/dense_162/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_81/dense_162/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_81/dense_162/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7829 - accuracy: 0.6787 - tf_f1: 0.5487 - val_loss: 1.0368 - val_accuracy: 0.5649 - val_tf_f1: 0.6730\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4258 - accuracy: 0.8265 - tf_f1: 0.7153 - val_loss: 0.9948 - val_accuracy: 0.6565 - val_tf_f1: 0.7470\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3264 - accuracy: 0.8663 - tf_f1: 0.7677 - val_loss: 0.9956 - val_accuracy: 0.6954 - val_tf_f1: 0.7852\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2768 - accuracy: 0.8889 - tf_f1: 0.7986 - val_loss: 1.2736 - val_accuracy: 0.5792 - val_tf_f1: 0.8090\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2428 - accuracy: 0.9041 - tf_f1: 0.8176 - val_loss: 1.1350 - val_accuracy: 0.6745 - val_tf_f1: 0.8258\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2172 - accuracy: 0.9161 - tf_f1: 0.8329 - val_loss: 1.1604 - val_accuracy: 0.7291 - val_tf_f1: 0.8395\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1959 - accuracy: 0.9256 - tf_f1: 0.8454 - val_loss: 1.2219 - val_accuracy: 0.7170 - val_tf_f1: 0.8506\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1788 - accuracy: 0.9334 - tf_f1: 0.8554 - val_loss: 1.4353 - val_accuracy: 0.6272 - val_tf_f1: 0.8595\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1670 - accuracy: 0.9385 - tf_f1: 0.8632 - val_loss: 1.5647 - val_accuracy: 0.5724 - val_tf_f1: 0.8664\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1551 - accuracy: 0.9441 - tf_f1: 0.8695 - val_loss: 1.3656 - val_accuracy: 0.6809 - val_tf_f1: 0.8726\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1462 - accuracy: 0.9470 - tf_f1: 0.8755 - val_loss: 1.3814 - val_accuracy: 0.7050 - val_tf_f1: 0.8783\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1395 - accuracy: 0.9500 - tf_f1: 0.8808 - val_loss: 1.5640 - val_accuracy: 0.6705 - val_tf_f1: 0.8831\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1325 - accuracy: 0.9521 - tf_f1: 0.8853 - val_loss: 1.6384 - val_accuracy: 0.6369 - val_tf_f1: 0.8873\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1262 - accuracy: 0.9550 - tf_f1: 0.8891 - val_loss: 1.5689 - val_accuracy: 0.6719 - val_tf_f1: 0.8910\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1216 - accuracy: 0.9568 - tf_f1: 0.8927 - val_loss: 1.6090 - val_accuracy: 0.6898 - val_tf_f1: 0.8944\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1186 - accuracy: 0.9576 - tf_f1: 0.8960 - val_loss: 1.6814 - val_accuracy: 0.6606 - val_tf_f1: 0.8974\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1137 - accuracy: 0.9599 - tf_f1: 0.8988 - val_loss: 1.6308 - val_accuracy: 0.6855 - val_tf_f1: 0.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:47:52,293]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 16.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_82/dense_164/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_82/dense_164/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_82/dense_164/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7818 - accuracy: 0.6812 - tf_f1: 0.5597 - val_loss: 1.0338 - val_accuracy: 0.6065 - val_tf_f1: 0.6775\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4249 - accuracy: 0.8265 - tf_f1: 0.7190 - val_loss: 1.0089 - val_accuracy: 0.6118 - val_tf_f1: 0.7491\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3263 - accuracy: 0.8672 - tf_f1: 0.7693 - val_loss: 1.1162 - val_accuracy: 0.5823 - val_tf_f1: 0.7855\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2693 - accuracy: 0.8915 - tf_f1: 0.7982 - val_loss: 1.2122 - val_accuracy: 0.6088 - val_tf_f1: 0.8092\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2356 - accuracy: 0.9073 - tf_f1: 0.8183 - val_loss: 1.5165 - val_accuracy: 0.4649 - val_tf_f1: 0.8256\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2125 - accuracy: 0.9182 - tf_f1: 0.8319 - val_loss: 1.2064 - val_accuracy: 0.6539 - val_tf_f1: 0.8383\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1905 - accuracy: 0.9276 - tf_f1: 0.8441 - val_loss: 1.2963 - val_accuracy: 0.6626 - val_tf_f1: 0.8494\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1709 - accuracy: 0.9371 - tf_f1: 0.8543 - val_loss: 1.3074 - val_accuracy: 0.6608 - val_tf_f1: 0.8588\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1583 - accuracy: 0.9419 - tf_f1: 0.8628 - val_loss: 1.3511 - val_accuracy: 0.6773 - val_tf_f1: 0.8665\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1453 - accuracy: 0.9475 - tf_f1: 0.8700 - val_loss: 1.4130 - val_accuracy: 0.6449 - val_tf_f1: 0.8732\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1349 - accuracy: 0.9514 - tf_f1: 0.8761 - val_loss: 1.3665 - val_accuracy: 0.6987 - val_tf_f1: 0.8790\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1309 - accuracy: 0.9534 - tf_f1: 0.8817 - val_loss: 1.4910 - val_accuracy: 0.6919 - val_tf_f1: 0.8841\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1215 - accuracy: 0.9574 - tf_f1: 0.8865 - val_loss: 1.5387 - val_accuracy: 0.6762 - val_tf_f1: 0.8887\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1158 - accuracy: 0.9592 - tf_f1: 0.8907 - val_loss: 1.5832 - val_accuracy: 0.6598 - val_tf_f1: 0.8926\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1126 - accuracy: 0.9607 - tf_f1: 0.8944 - val_loss: 1.5744 - val_accuracy: 0.6675 - val_tf_f1: 0.8961\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1077 - accuracy: 0.9628 - tf_f1: 0.8977 - val_loss: 1.5275 - val_accuracy: 0.6925 - val_tf_f1: 0.8993\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1037 - accuracy: 0.9640 - tf_f1: 0.9008 - val_loss: 1.5895 - val_accuracy: 0.6669 - val_tf_f1: 0.9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:54:39,080]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 16.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_83/dense_166/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_83/dense_166/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_83/dense_166/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7974 - accuracy: 0.6739 - tf_f1: 0.5479 - val_loss: 0.9552 - val_accuracy: 0.6406 - val_tf_f1: 0.6702\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4433 - accuracy: 0.8202 - tf_f1: 0.7126 - val_loss: 1.0050 - val_accuracy: 0.6398 - val_tf_f1: 0.7433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:55:27,574]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_84/dense_168/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_84/dense_168/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_84/dense_168/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7954 - accuracy: 0.6746 - tf_f1: 0.5460 - val_loss: 0.9949 - val_accuracy: 0.6116 - val_tf_f1: 0.6707\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4285 - accuracy: 0.8258 - tf_f1: 0.7146 - val_loss: 0.9663 - val_accuracy: 0.6695 - val_tf_f1: 0.7463\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3346 - accuracy: 0.8642 - tf_f1: 0.7672 - val_loss: 1.2680 - val_accuracy: 0.4795 - val_tf_f1: 0.7822\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2867 - accuracy: 0.8843 - tf_f1: 0.7936 - val_loss: 1.1481 - val_accuracy: 0.6106 - val_tf_f1: 0.8044\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2521 - accuracy: 0.8998 - tf_f1: 0.8133 - val_loss: 1.3700 - val_accuracy: 0.5387 - val_tf_f1: 0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:57:28,117]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_85/dense_170/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_85/dense_170/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_85/dense_170/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7699 - accuracy: 0.6837 - tf_f1: 0.5589 - val_loss: 1.1089 - val_accuracy: 0.5566 - val_tf_f1: 0.6775\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4213 - accuracy: 0.8258 - tf_f1: 0.7179 - val_loss: 0.9717 - val_accuracy: 0.6659 - val_tf_f1: 0.7489\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3290 - accuracy: 0.8640 - tf_f1: 0.7691 - val_loss: 1.1353 - val_accuracy: 0.6198 - val_tf_f1: 0.7850\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2788 - accuracy: 0.8850 - tf_f1: 0.7972 - val_loss: 1.2229 - val_accuracy: 0.5969 - val_tf_f1: 0.8076\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2496 - accuracy: 0.8997 - tf_f1: 0.8161 - val_loss: 1.2449 - val_accuracy: 0.6264 - val_tf_f1: 0.8237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 05:59:29,403]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_86/dense_172/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_86/dense_172/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_86/dense_172/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7791 - accuracy: 0.6792 - tf_f1: 0.5531 - val_loss: 0.9728 - val_accuracy: 0.6080 - val_tf_f1: 0.6746\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4413 - accuracy: 0.8190 - tf_f1: 0.7148 - val_loss: 0.8817 - val_accuracy: 0.7248 - val_tf_f1: 0.7456\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3432 - accuracy: 0.8596 - tf_f1: 0.7665 - val_loss: 1.2182 - val_accuracy: 0.5584 - val_tf_f1: 0.7816\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2936 - accuracy: 0.8812 - tf_f1: 0.7933 - val_loss: 1.0911 - val_accuracy: 0.6650 - val_tf_f1: 0.8041\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2596 - accuracy: 0.8964 - tf_f1: 0.8132 - val_loss: 1.1992 - val_accuracy: 0.6346 - val_tf_f1: 0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:01:30,269]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_87/dense_174/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_87/dense_174/embedding_lookup_sparse/Reshape:0\", shape=(None, 42), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_87/dense_174/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8338 - accuracy: 0.6627 - tf_f1: 0.5317 - val_loss: 1.0641 - val_accuracy: 0.5797 - val_tf_f1: 0.6576\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4571 - accuracy: 0.8157 - tf_f1: 0.7011 - val_loss: 0.9934 - val_accuracy: 0.6685 - val_tf_f1: 0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:02:19,031]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_88/dense_176/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_88/dense_176/embedding_lookup_sparse/Reshape:0\", shape=(None, 18), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_88/dense_176/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8177 - accuracy: 0.6655 - tf_f1: 0.5399 - val_loss: 0.9361 - val_accuracy: 0.6438 - val_tf_f1: 0.6620\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4908 - accuracy: 0.8006 - tf_f1: 0.7020 - val_loss: 1.0080 - val_accuracy: 0.6122 - val_tf_f1: 0.7294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:03:07,783]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_89/dense_178/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_89/dense_178/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_89/dense_178/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.8146 - accuracy: 0.6693 - tf_f1: 0.5421 - val_loss: 1.1848 - val_accuracy: 0.5216 - val_tf_f1: 0.6625\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4476 - accuracy: 0.8203 - tf_f1: 0.7048 - val_loss: 1.1975 - val_accuracy: 0.5462 - val_tf_f1: 0.7363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:03:56,494]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_90/dense_180/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_90/dense_180/embedding_lookup_sparse/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_90/dense_180/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7971 - accuracy: 0.6750 - tf_f1: 0.5451 - val_loss: 1.0203 - val_accuracy: 0.6263 - val_tf_f1: 0.6715\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4380 - accuracy: 0.8227 - tf_f1: 0.7142 - val_loss: 1.0793 - val_accuracy: 0.6072 - val_tf_f1: 0.7443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:04:45,223]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_91/dense_182/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_91/dense_182/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_91/dense_182/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7978 - accuracy: 0.6722 - tf_f1: 0.5421 - val_loss: 1.0555 - val_accuracy: 0.5607 - val_tf_f1: 0.6661\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4486 - accuracy: 0.8170 - tf_f1: 0.7075 - val_loss: 1.1326 - val_accuracy: 0.5920 - val_tf_f1: 0.7380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:05:33,735]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_92/dense_184/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_92/dense_184/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_92/dense_184/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7947 - accuracy: 0.6719 - tf_f1: 0.5424 - val_loss: 1.0846 - val_accuracy: 0.5926 - val_tf_f1: 0.6673\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4509 - accuracy: 0.8154 - tf_f1: 0.7087 - val_loss: 0.9782 - val_accuracy: 0.6504 - val_tf_f1: 0.7390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:06:22,409]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_93/dense_186/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_93/dense_186/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_93/dense_186/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7706 - accuracy: 0.6837 - tf_f1: 0.5592 - val_loss: 1.1736 - val_accuracy: 0.5695 - val_tf_f1: 0.6786\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4152 - accuracy: 0.8308 - tf_f1: 0.7197 - val_loss: 1.0483 - val_accuracy: 0.6064 - val_tf_f1: 0.7510\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3206 - accuracy: 0.8689 - tf_f1: 0.7712 - val_loss: 1.1756 - val_accuracy: 0.5634 - val_tf_f1: 0.7871\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2763 - accuracy: 0.8877 - tf_f1: 0.7990 - val_loss: 1.0575 - val_accuracy: 0.6922 - val_tf_f1: 0.8100\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2451 - accuracy: 0.9024 - tf_f1: 0.8191 - val_loss: 1.1251 - val_accuracy: 0.6984 - val_tf_f1: 0.8270\n",
      "Epoch 6/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2209 - accuracy: 0.9127 - tf_f1: 0.8338 - val_loss: 1.2302 - val_accuracy: 0.6505 - val_tf_f1: 0.8397\n",
      "Epoch 7/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1999 - accuracy: 0.9228 - tf_f1: 0.8451 - val_loss: 1.2330 - val_accuracy: 0.6516 - val_tf_f1: 0.8499\n",
      "Epoch 8/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1852 - accuracy: 0.9300 - tf_f1: 0.8543 - val_loss: 1.3273 - val_accuracy: 0.6658 - val_tf_f1: 0.8584\n",
      "Epoch 9/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1696 - accuracy: 0.9365 - tf_f1: 0.8623 - val_loss: 1.3147 - val_accuracy: 0.6625 - val_tf_f1: 0.8657\n",
      "Epoch 10/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1592 - accuracy: 0.9416 - tf_f1: 0.8689 - val_loss: 1.3999 - val_accuracy: 0.6575 - val_tf_f1: 0.8719\n",
      "Epoch 11/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1468 - accuracy: 0.9468 - tf_f1: 0.8748 - val_loss: 1.4318 - val_accuracy: 0.6668 - val_tf_f1: 0.8775\n",
      "Epoch 12/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1390 - accuracy: 0.9495 - tf_f1: 0.8800 - val_loss: 1.5060 - val_accuracy: 0.6441 - val_tf_f1: 0.8822\n",
      "Epoch 13/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1332 - accuracy: 0.9520 - tf_f1: 0.8844 - val_loss: 1.5505 - val_accuracy: 0.7074 - val_tf_f1: 0.8865\n",
      "Epoch 14/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1265 - accuracy: 0.9547 - tf_f1: 0.8886 - val_loss: 1.5232 - val_accuracy: 0.6715 - val_tf_f1: 0.8904\n",
      "Epoch 15/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1201 - accuracy: 0.9580 - tf_f1: 0.8922 - val_loss: 1.6180 - val_accuracy: 0.6356 - val_tf_f1: 0.8939\n",
      "Epoch 16/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1163 - accuracy: 0.9589 - tf_f1: 0.8954 - val_loss: 1.5993 - val_accuracy: 0.7164 - val_tf_f1: 0.8970\n",
      "Epoch 17/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.1130 - accuracy: 0.9599 - tf_f1: 0.8985 - val_loss: 1.6220 - val_accuracy: 0.6865 - val_tf_f1: 0.8999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:13:10,266]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 16.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_94/dense_188/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_94/dense_188/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_94/dense_188/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.7892 - accuracy: 0.6779 - tf_f1: 0.5480 - val_loss: 1.1382 - val_accuracy: 0.5091 - val_tf_f1: 0.6704\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4327 - accuracy: 0.8242 - tf_f1: 0.7115 - val_loss: 1.0545 - val_accuracy: 0.5972 - val_tf_f1: 0.7430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:13:59,005]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_95/dense_190/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_95/dense_190/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_95/dense_190/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7907 - accuracy: 0.6755 - tf_f1: 0.5422 - val_loss: 1.0947 - val_accuracy: 0.5626 - val_tf_f1: 0.6703\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4272 - accuracy: 0.8250 - tf_f1: 0.7126 - val_loss: 0.8942 - val_accuracy: 0.7116 - val_tf_f1: 0.7456\n",
      "Epoch 3/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.3339 - accuracy: 0.8634 - tf_f1: 0.7669 - val_loss: 1.1640 - val_accuracy: 0.5676 - val_tf_f1: 0.7828\n",
      "Epoch 4/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2832 - accuracy: 0.8852 - tf_f1: 0.7948 - val_loss: 1.1827 - val_accuracy: 0.6132 - val_tf_f1: 0.8056\n",
      "Epoch 5/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.2519 - accuracy: 0.9005 - tf_f1: 0.8146 - val_loss: 1.1225 - val_accuracy: 0.6824 - val_tf_f1: 0.8227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:15:58,904]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_96/dense_192/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_96/dense_192/embedding_lookup_sparse/Reshape:0\", shape=(None, 30), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_96/dense_192/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 25s 5ms/step - loss: 0.8076 - accuracy: 0.6721 - tf_f1: 0.5473 - val_loss: 0.9937 - val_accuracy: 0.6296 - val_tf_f1: 0.6675\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4557 - accuracy: 0.8157 - tf_f1: 0.7090 - val_loss: 1.1021 - val_accuracy: 0.5689 - val_tf_f1: 0.7385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:16:48,124]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_97/dense_194/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_97/dense_194/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_97/dense_194/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7966 - accuracy: 0.6748 - tf_f1: 0.5449 - val_loss: 1.0267 - val_accuracy: 0.6102 - val_tf_f1: 0.6695\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4422 - accuracy: 0.8198 - tf_f1: 0.7112 - val_loss: 1.2544 - val_accuracy: 0.5051 - val_tf_f1: 0.7405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:17:36,693]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_98/dense_196/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_98/dense_196/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_98/dense_196/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7951 - accuracy: 0.6714 - tf_f1: 0.5458 - val_loss: 1.0743 - val_accuracy: 0.5444 - val_tf_f1: 0.6656\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4657 - accuracy: 0.8103 - tf_f1: 0.7054 - val_loss: 1.2535 - val_accuracy: 0.5008 - val_tf_f1: 0.7329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:18:25,240]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_99/dense_198/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_99/dense_198/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_99/dense_198/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.7773 - accuracy: 0.6788 - tf_f1: 0.5493 - val_loss: 1.1152 - val_accuracy: 0.5157 - val_tf_f1: 0.6728\n",
      "Epoch 2/50\n",
      "4644/4644 [==============================] - 24s 5ms/step - loss: 0.4204 - accuracy: 0.8282 - tf_f1: 0.7148 - val_loss: 1.2379 - val_accuracy: 0.4927 - val_tf_f1: 0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 06:19:13,749]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 completed rungs: {}\n",
      "Trial 1 completed rungs: {'completed_rung_0': 0.7427323460578918, 'completed_rung_1': 0.8189261555671692, 'completed_rung_2': 0.8944036960601807}\n",
      "Trial 2 completed rungs: {'completed_rung_0': 0.6741511821746826}\n",
      "Trial 3 completed rungs: {'completed_rung_0': 0.7349013090133667}\n",
      "Trial 4 completed rungs: {'completed_rung_0': 0.7399435639381409}\n",
      "Trial 5 completed rungs: {'completed_rung_0': 0.5655180215835571}\n",
      "Trial 6 completed rungs: {'completed_rung_0': 0.738447368144989}\n",
      "Trial 7 completed rungs: {'completed_rung_0': 0.7282981276512146}\n",
      "Trial 8 completed rungs: {'completed_rung_0': 0.7315474152565002}\n",
      "Trial 9 completed rungs: {'completed_rung_0': 0.7375059723854065}\n",
      "Trial 10 completed rungs: {'completed_rung_0': 0.7100772857666016}\n",
      "Trial 11 completed rungs: {'completed_rung_0': 0.727260947227478}\n",
      "Trial 12 completed rungs: {'completed_rung_0': 0.6876068115234375}\n",
      "Trial 13 completed rungs: {'completed_rung_0': 0.6354276537895203}\n",
      "Trial 14 completed rungs: {'completed_rung_0': 0.7228445410728455}\n",
      "Trial 15 completed rungs: {'completed_rung_0': 0.7441674470901489, 'completed_rung_1': 0.8236167430877686, 'completed_rung_2': 0.9005640745162964}\n",
      "Trial 16 completed rungs: {'completed_rung_0': 0.730474054813385}\n",
      "Trial 17 completed rungs: {'completed_rung_0': 0.7147550582885742}\n",
      "Trial 18 completed rungs: {'completed_rung_0': 0.6442170143127441}\n",
      "Trial 19 completed rungs: {'completed_rung_0': 0.7484606504440308, 'completed_rung_1': 0.8266022205352783, 'completed_rung_2': 0.9045053124427795}\n",
      "Trial 20 completed rungs: {'completed_rung_0': 0.7349953651428223}\n",
      "Trial 21 completed rungs: {'completed_rung_0': 0.7431181073188782, 'completed_rung_1': 0.8188673853874207}\n",
      "Trial 22 completed rungs: {'completed_rung_0': 0.74472975730896, 'completed_rung_1': 0.8187541365623474}\n",
      "Trial 23 completed rungs: {'completed_rung_0': 0.7393723726272583}\n",
      "Trial 24 completed rungs: {'completed_rung_0': 0.7179170846939087}\n",
      "Trial 25 completed rungs: {'completed_rung_0': 0.7396867871284485}\n",
      "Trial 26 completed rungs: {'completed_rung_0': 0.741760790348053, 'completed_rung_1': 0.8145231008529663}\n",
      "Trial 27 completed rungs: {'completed_rung_0': 0.7306957840919495}\n",
      "Trial 28 completed rungs: {'completed_rung_0': 0.7294897437095642}\n",
      "Trial 29 completed rungs: {'completed_rung_0': 0.7274866104125977}\n",
      "Trial 30 completed rungs: {'completed_rung_0': 0.7205042243003845}\n",
      "Trial 31 completed rungs: {'completed_rung_0': 0.7106422185897827}\n",
      "Trial 32 completed rungs: {'completed_rung_0': 0.7305667400360107}\n",
      "Trial 33 completed rungs: {'completed_rung_0': 0.7177122235298157}\n",
      "Trial 34 completed rungs: {'completed_rung_0': 0.7385794520378113}\n",
      "Trial 35 completed rungs: {'completed_rung_0': 0.7394838929176331}\n",
      "Trial 36 completed rungs: {'completed_rung_0': 0.7331900000572205}\n",
      "Trial 37 completed rungs: {'completed_rung_0': 0.7429175972938538, 'completed_rung_1': 0.8133295774459839}\n",
      "Trial 38 completed rungs: {'completed_rung_0': 0.7421708703041077, 'completed_rung_1': 0.8096745014190674}\n",
      "Trial 39 completed rungs: {'completed_rung_0': 0.7461370825767517, 'completed_rung_1': 0.8119391798973083}\n",
      "Trial 40 completed rungs: {'completed_rung_0': 0.7402784824371338, 'completed_rung_1': 0.8207924962043762}\n",
      "Trial 41 completed rungs: {'completed_rung_0': 0.7328228950500488}\n",
      "Trial 42 completed rungs: {'completed_rung_0': 0.7400723695755005}\n",
      "Trial 43 completed rungs: {'completed_rung_0': 0.7320937514305115}\n",
      "Trial 44 completed rungs: {'completed_rung_0': 0.7408791184425354, 'completed_rung_1': 0.8132575750350952}\n",
      "Trial 45 completed rungs: {'completed_rung_0': 0.7488458156585693, 'completed_rung_1': 0.8230043649673462, 'completed_rung_2': 0.8945800065994263}\n",
      "Trial 46 completed rungs: {'completed_rung_0': 0.7437007427215576, 'completed_rung_1': 0.8170688152313232}\n",
      "Trial 47 completed rungs: {'completed_rung_0': 0.7458251714706421, 'completed_rung_1': 0.8200593590736389}\n",
      "Trial 48 completed rungs: {'completed_rung_0': 0.7402812838554382}\n",
      "Trial 49 completed rungs: {'completed_rung_0': 0.7189751863479614}\n",
      "Trial 50 completed rungs: {'completed_rung_0': 0.7474110126495361, 'completed_rung_1': 0.8197559118270874}\n",
      "Trial 51 completed rungs: {'completed_rung_0': 0.749977707862854, 'completed_rung_1': 0.8268052339553833, 'completed_rung_2': 0.9034240245819092}\n",
      "Trial 52 completed rungs: {'completed_rung_0': 0.7405446767807007}\n",
      "Trial 53 completed rungs: {'completed_rung_0': 0.7459887862205505, 'completed_rung_1': 0.8208718299865723}\n",
      "Trial 54 completed rungs: {'completed_rung_0': 0.7450476884841919, 'completed_rung_1': 0.8174612522125244}\n",
      "Trial 55 completed rungs: {'completed_rung_0': 0.7350324988365173}\n",
      "Trial 56 completed rungs: {'completed_rung_0': 0.7361233234405518}\n",
      "Trial 57 completed rungs: {'completed_rung_0': 0.7341527342796326}\n",
      "Trial 58 completed rungs: {'completed_rung_0': 0.7397876381874084}\n",
      "Trial 59 completed rungs: {'completed_rung_0': 0.7358317971229553}\n",
      "Trial 60 completed rungs: {'completed_rung_0': 0.6908945441246033}\n",
      "Trial 61 completed rungs: {'completed_rung_0': 0.7468094229698181, 'completed_rung_1': 0.8217089176177979}\n",
      "Trial 62 completed rungs: {'completed_rung_0': 0.7461361885070801, 'completed_rung_1': 0.8242163062095642, 'completed_rung_2': 0.9037336707115173}\n",
      "Trial 63 completed rungs: {'completed_rung_0': 0.734891951084137}\n",
      "Trial 64 completed rungs: {'completed_rung_0': 0.7460833787918091, 'completed_rung_1': 0.8215740919113159}\n",
      "Trial 65 completed rungs: {'completed_rung_0': 0.7514861226081848, 'completed_rung_1': 0.8277321457862854, 'completed_rung_2': 0.9048206210136414}\n",
      "Trial 66 completed rungs: {'completed_rung_0': 0.7457634210586548, 'completed_rung_1': 0.8238337635993958, 'completed_rung_2': 0.8967649936676025}\n",
      "Trial 67 completed rungs: {'completed_rung_0': 0.7236179113388062}\n",
      "Trial 68 completed rungs: {'completed_rung_0': 0.7371730804443359}\n",
      "Trial 69 completed rungs: {'completed_rung_0': 0.7279105186462402}\n",
      "Trial 70 completed rungs: {'completed_rung_0': 0.752130925655365, 'completed_rung_1': 0.8298806548118591, 'completed_rung_2': 0.9058654308319092}\n",
      "Trial 71 completed rungs: {'completed_rung_0': 0.7473499774932861, 'completed_rung_1': 0.8265363574028015, 'completed_rung_2': 0.9013656377792358}\n",
      "Trial 72 completed rungs: {'completed_rung_0': 0.7446127533912659, 'completed_rung_1': 0.8234444856643677}\n",
      "Trial 73 completed rungs: {'completed_rung_0': 0.561227560043335}\n",
      "Trial 74 completed rungs: {'completed_rung_0': 0.7499924898147583, 'completed_rung_1': 0.8237436413764954}\n",
      "Trial 75 completed rungs: {'completed_rung_0': 0.7137383818626404}\n",
      "Trial 76 completed rungs: {'completed_rung_0': 0.7407331466674805}\n",
      "Trial 77 completed rungs: {'completed_rung_0': 0.7375040650367737}\n",
      "Trial 78 completed rungs: {'completed_rung_0': 0.7349315881729126}\n",
      "Trial 79 completed rungs: {'completed_rung_0': 0.7378072142601013}\n",
      "Trial 80 completed rungs: {'completed_rung_0': 0.7455549240112305, 'completed_rung_1': 0.8219606280326843}\n",
      "Trial 81 completed rungs: {'completed_rung_0': 0.747016966342926, 'completed_rung_1': 0.825781524181366, 'completed_rung_2': 0.9002178907394409}\n",
      "Trial 82 completed rungs: {'completed_rung_0': 0.7491093873977661, 'completed_rung_1': 0.8255964517593384, 'completed_rung_2': 0.9022195339202881}\n",
      "Trial 83 completed rungs: {'completed_rung_0': 0.7432754635810852}\n",
      "Trial 84 completed rungs: {'completed_rung_0': 0.7462674975395203, 'completed_rung_1': 0.8207842707633972}\n",
      "Trial 85 completed rungs: {'completed_rung_0': 0.7488523721694946, 'completed_rung_1': 0.8237410187721252}\n",
      "Trial 86 completed rungs: {'completed_rung_0': 0.7456183433532715, 'completed_rung_1': 0.8207524418830872}\n",
      "Trial 87 completed rungs: {'completed_rung_0': 0.7340137958526611}\n",
      "Trial 88 completed rungs: {'completed_rung_0': 0.7294105291366577}\n",
      "Trial 89 completed rungs: {'completed_rung_0': 0.7362613677978516}\n",
      "Trial 90 completed rungs: {'completed_rung_0': 0.7443379759788513}\n",
      "Trial 91 completed rungs: {'completed_rung_0': 0.7379502654075623}\n",
      "Trial 92 completed rungs: {'completed_rung_0': 0.7389739751815796}\n",
      "Trial 93 completed rungs: {'completed_rung_0': 0.7510308623313904, 'completed_rung_1': 0.8270044922828674, 'completed_rung_2': 0.8999266028404236}\n",
      "Trial 94 completed rungs: {'completed_rung_0': 0.7430282235145569}\n",
      "Trial 95 completed rungs: {'completed_rung_0': 0.7456416487693787, 'completed_rung_1': 0.8227238655090332}\n",
      "Trial 96 completed rungs: {'completed_rung_0': 0.738497257232666}\n",
      "Trial 97 completed rungs: {'completed_rung_0': 0.7404597401618958}\n",
      "Trial 98 completed rungs: {'completed_rung_0': 0.7328950762748718}\n",
      "Trial 99 completed rungs: {'completed_rung_0': 0.7450109720230103}\n",
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  94\n",
      "  Number of complete trials:  6\n",
      "Best trial:\n",
      "  Value:  0.9058654308319092\n",
      "  Params: \n",
      "    lr: 0.07441522157885706\n",
      "    units: 49\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.optimizer_v2.gradient_descent import SGD\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import statistics\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from keras.utils import to_categorical\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
    "\n",
    "tf_x_train_trainvec = convert_sparse_matrix_to_sparse_tensor(x_train_trainvec)\n",
    "\n",
    "tf_x_valvec = convert_sparse_matrix_to_sparse_tensor(x_valvec)\n",
    "\n",
    "def create_model(trial, X):\n",
    "    lr = trial.suggest_uniform('lr', 0.00001, 0.1)\n",
    "    units = trial.suggest_int('units', 10, 50)\n",
    "    input_dim = X\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, input_dim=input_dim, activation = 'relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    optimizer = SGD(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "    \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                    optimizer=optimizer, \n",
    "                    metrics=['accuracy', F1Score(num_classes=5, average= 'macro', name='tf_f1')])\n",
    "    return model\n",
    "            \n",
    "\n",
    "def objective_mlp(trial):\n",
    "\n",
    "    model = create_model(trial, x_train_trainvec.shape[1])\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_tf_f1', mode='max', min_delta=0.01, patience=3, verbose=1), TFKerasPruningCallback(trial,'val_tf_f1')]\n",
    "\n",
    "    fit_model = model.fit(x=tf_x_train_trainvec, y=to_categorical(y_train_train.sub(1)), epochs =50, verbose=1, batch_size= 50, callbacks=callbacks, validation_data=(tf_x_valvec,to_categorical(y_val.sub(1))))\n",
    "\n",
    "    return fit_model.history['val_tf_f1'][-1]\n",
    "\n",
    "def show_result(study):\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    trial_idx = 0\n",
    "    for frozen_trial in study.get_trials(deepcopy=False):\n",
    "\n",
    "        print(\"Trial {} completed rungs: {}\".format(trial_idx, frozen_trial.system_attrs))\n",
    "        trial_idx +=1\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",sampler= TPESampler(),  pruner=SuccessiveHalvingPruner()\n",
    ")\n",
    "study.optimize(objective_mlp, n_trials=100)\n",
    "\n",
    "show_result(study)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_100/dense_200/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_100/dense_200/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_100/dense_200/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.7832 - accuracy: 0.6778 - tf_f1: 0.5581\n",
      "Epoch 2/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.4407 - accuracy: 0.8202 - tf_f1: 0.7155\n",
      "Epoch 3/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.3468 - accuracy: 0.8588 - tf_f1: 0.7670\n",
      "Epoch 4/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.2975 - accuracy: 0.8806 - tf_f1: 0.7966\n",
      "Epoch 5/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.2649 - accuracy: 0.8952 - tf_f1: 0.8170\n",
      "Epoch 6/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.2419 - accuracy: 0.9064 - tf_f1: 0.8323\n",
      "Epoch 7/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.2227 - accuracy: 0.9153 - tf_f1: 0.8444\n",
      "Epoch 8/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.2072 - accuracy: 0.9227 - tf_f1: 0.8544\n",
      "Epoch 9/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.1933 - accuracy: 0.9277 - tf_f1: 0.8627\n",
      "Epoch 10/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.1804 - accuracy: 0.9333 - tf_f1: 0.8699\n",
      "Epoch 11/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.1721 - accuracy: 0.9367 - tf_f1: 0.8761\n",
      "Epoch 12/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.1660 - accuracy: 0.9400 - tf_f1: 0.8815\n",
      "Epoch 13/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.1583 - accuracy: 0.9425 - tf_f1: 0.8863\n",
      "Epoch 14/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.1532 - accuracy: 0.9447 - tf_f1: 0.8906\n",
      "Epoch 15/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.1476 - accuracy: 0.9468 - tf_f1: 0.8944\n",
      "Epoch 16/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.1419 - accuracy: 0.9493 - tf_f1: 0.8978\n",
      "Epoch 17/50\n",
      "5805/5805 [==============================] - 29s 5ms/step - loss: 0.1396 - accuracy: 0.9500 - tf_f1: 0.9010\n",
      "Epoch 18/50\n",
      "5805/5805 [==============================] - 28s 5ms/step - loss: 0.1370 - accuracy: 0.9510 - tf_f1: 0.9038\n",
      "Epoch 19/50\n",
      "5805/5805 [==============================] - 28s 5ms/step - loss: 0.1324 - accuracy: 0.9527 - tf_f1: 0.9064\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_model = create_model(study.best_trial, x_trainvec.shape[1])\n",
    "\n",
    "tf_x_trainvec = convert_sparse_matrix_to_sparse_tensor(x_trainvec)\n",
    "tf_x_testvec = convert_sparse_matrix_to_sparse_tensor(x_testvec)\n",
    "\n",
    "best_model.fit(x=tf_x_trainvec, y=to_categorical(y_train.sub(1)), epochs =50, verbose=1, batch_size= 50, callbacks=EarlyStopping(monitor='tf_f1', mode='max', min_delta=0.01, patience=3, verbose=1))\n",
    "\n",
    "mlp_train_predictions = np.argmax(best_model.predict(x_trainvec),axis=1)+(1)\n",
    "mlp_test_predictions = np.argmax(best_model.predict(x_testvec),axis=1)+(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Train Accuracy Score : 0.9579821508562765\n",
      "MLP Test Accuracy Score : 0.6490807354116707\n",
      "MLP Train F1 Score : 0.9578983028224213\n",
      "MLP Test F1 Score : 0.36164370916557304\n",
      "MLP Confusion matrix:\n",
      "[[  112    31    54    58   205]\n",
      " [   34    56    53    51    97]\n",
      " [   45    73   262   312   607]\n",
      " [   28    41   216   936  2796]\n",
      " [   74    65   292  1453 10814]]\n",
      "MLP Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.38      0.30       293\n",
      "           2       0.19      0.21      0.20       266\n",
      "           3       0.20      0.30      0.24       877\n",
      "           4       0.23      0.33      0.27      2810\n",
      "           5       0.85      0.74      0.79     14519\n",
      "\n",
      "    accuracy                           0.65     18765\n",
      "   macro avg       0.34      0.39      0.36     18765\n",
      "weighted avg       0.71      0.65      0.67     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP Train Accuracy Score :\",accuracy_score(y_pred=mlp_train_predictions, y_true=y_train.to_numpy().ravel()))\n",
    "print(\"MLP Test Accuracy Score :\",accuracy_score(y_pred=mlp_test_predictions, y_true= y_test.to_numpy().ravel()))\n",
    "\n",
    "print(\"MLP Train F1 Score :\",f1_score(y_pred=mlp_train_predictions, y_true=y_train.to_numpy().ravel(), average = 'macro'))\n",
    "print(\"MLP Test F1 Score :\",f1_score(y_pred=mlp_test_predictions, y_true=y_test.to_numpy().ravel(), average = 'macro'))\n",
    "\n",
    "print(\"MLP Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= mlp_test_predictions)))\n",
    "print(\"MLP Classification report:\\n\",classification_report(y_pred=mlp_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 11608\n",
      "max_resources_: 290210\n",
      "aggressive_elimination: False\n",
      "factor: 5\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 100\n",
      "n_resources: 11608\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 1/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.092, test=0.088) total time=   1.3s\n",
      "[CV 2/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 2/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.092, test=0.091) total time=   0.5s\n",
      "[CV 3/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 3/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.093, test=0.090) total time=   0.5s\n",
      "[CV 4/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 4/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.095, test=0.092) total time=   0.6s\n",
      "[CV 5/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 5/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.092, test=0.104) total time=   0.5s\n",
      "[CV 1/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 1/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.270, test=0.254) total time=   1.2s\n",
      "[CV 2/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 2/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.312, test=0.325) total time=   0.4s\n",
      "[CV 3/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 3/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.332, test=0.313) total time=   0.4s\n",
      "[CV 4/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 4/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.250, test=0.236) total time=   0.4s\n",
      "[CV 5/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 5/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.240, test=0.222) total time=   0.4s\n",
      "[CV 1/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 1/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.347, test=0.311) total time=   0.7s\n",
      "[CV 2/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 2/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.369, test=0.353) total time=   0.7s\n",
      "[CV 3/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 3/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.310, test=0.288) total time=   0.7s\n",
      "[CV 4/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 4/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.298, test=0.284) total time=   0.6s\n",
      "[CV 5/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 5/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.328, test=0.296) total time=   0.7s\n",
      "[CV 1/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 1/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.358, test=0.326) total time=   1.0s\n",
      "[CV 2/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 2/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.385, test=0.368) total time=   1.0s\n",
      "[CV 3/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 3/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.369, test=0.355) total time=   1.1s\n",
      "[CV 4/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 4/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.308, test=0.285) total time=   0.9s\n",
      "[CV 5/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 5/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.335, test=0.298) total time=   1.1s\n",
      "[CV 1/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 1/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.395, test=0.369) total time=   1.2s\n",
      "[CV 2/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 2/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.374, test=0.350) total time=   1.3s\n",
      "[CV 3/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 3/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.390, test=0.363) total time=   1.3s\n",
      "[CV 4/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 4/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.335, test=0.304) total time=   1.0s\n",
      "[CV 5/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 5/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.346, test=0.307) total time=   1.3s\n",
      "[CV 1/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 1/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.410, test=0.381) total time=   1.7s\n",
      "[CV 2/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 2/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.371, test=0.353) total time=   1.6s\n",
      "[CV 3/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 3/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.393, test=0.362) total time=   1.7s\n",
      "[CV 4/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 4/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.332, test=0.309) total time=   1.1s\n",
      "[CV 5/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 5/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.356, test=0.318) total time=   1.6s\n",
      "[CV 1/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 1/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.412, test=0.384) total time=   1.8s\n",
      "[CV 2/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 2/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.374, test=0.339) total time=   1.9s\n",
      "[CV 3/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 3/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.392, test=0.362) total time=   1.9s\n",
      "[CV 4/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 4/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.343, test=0.314) total time=   1.6s\n",
      "[CV 5/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 5/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.383, test=0.342) total time=   1.9s\n",
      "[CV 1/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 1/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.404, test=0.375) total time=   2.2s\n",
      "[CV 2/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 2/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.396, test=0.363) total time=   2.3s\n",
      "[CV 3/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 3/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.399, test=0.362) total time=   2.1s\n",
      "[CV 4/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 4/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.347, test=0.319) total time=   1.8s\n",
      "[CV 5/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 5/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.377, test=0.343) total time=   2.1s\n",
      "[CV 1/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 1/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.404, test=0.369) total time=   2.3s\n",
      "[CV 2/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 2/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.398, test=0.361) total time=   2.4s\n",
      "[CV 3/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 3/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.405, test=0.365) total time=   2.4s\n",
      "[CV 4/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 4/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.342, test=0.326) total time=   1.7s\n",
      "[CV 5/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 5/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.372, test=0.333) total time=   2.5s\n",
      "[CV 1/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 1/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.412, test=0.367) total time=   2.5s\n",
      "[CV 2/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 2/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.396, test=0.356) total time=   2.7s\n",
      "[CV 3/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 3/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.397, test=0.370) total time=   2.7s\n",
      "[CV 4/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 4/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.363, test=0.343) total time=   1.9s\n",
      "[CV 5/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 5/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.376, test=0.337) total time=   2.7s\n",
      "[CV 1/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 1/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.133, test=0.142) total time=   0.0s\n",
      "[CV 2/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 2/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.147, test=0.149) total time=   0.0s\n",
      "[CV 3/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 3/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.138, test=0.137) total time=   0.0s\n",
      "[CV 4/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 4/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.152, test=0.147) total time=   0.1s\n",
      "[CV 5/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 5/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.155, test=0.127) total time=   0.0s\n",
      "[CV 1/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 1/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.484, test=0.401) total time=   0.4s\n",
      "[CV 2/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 2/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.452, test=0.396) total time=   0.4s\n",
      "[CV 3/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 3/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.473, test=0.415) total time=   0.4s\n",
      "[CV 4/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 4/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.448, test=0.387) total time=   0.4s\n",
      "[CV 5/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 5/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.459, test=0.388) total time=   0.4s\n",
      "[CV 1/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 1/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.498, test=0.407) total time=   0.6s\n",
      "[CV 2/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 2/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.508, test=0.439) total time=   0.7s\n",
      "[CV 3/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 3/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.504, test=0.425) total time=   0.7s\n",
      "[CV 4/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 4/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.477, test=0.403) total time=   0.6s\n",
      "[CV 5/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 5/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.496, test=0.405) total time=   0.7s\n",
      "[CV 1/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 1/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.503, test=0.412) total time=   1.0s\n",
      "[CV 2/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 2/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.510, test=0.437) total time=   1.0s\n",
      "[CV 3/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 3/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.510, test=0.429) total time=   0.9s\n",
      "[CV 4/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 4/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.481, test=0.396) total time=   0.9s\n",
      "[CV 5/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 5/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.505, test=0.405) total time=   0.9s\n",
      "[CV 1/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 1/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.527, test=0.429) total time=   1.1s\n",
      "[CV 2/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 2/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.516, test=0.418) total time=   1.1s\n",
      "[CV 3/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 3/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.513, test=0.436) total time=   1.1s\n",
      "[CV 4/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 4/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.487, test=0.401) total time=   1.0s\n",
      "[CV 5/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 5/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.499, test=0.390) total time=   1.1s\n",
      "[CV 1/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 1/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.530, test=0.428) total time=   1.2s\n",
      "[CV 2/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 2/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.516, test=0.429) total time=   1.4s\n",
      "[CV 3/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 3/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.513, test=0.434) total time=   1.2s\n",
      "[CV 4/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 4/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.492, test=0.400) total time=   1.2s\n",
      "[CV 5/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 5/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.505, test=0.400) total time=   1.2s\n",
      "[CV 1/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 1/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.528, test=0.425) total time=   1.6s\n",
      "[CV 2/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 2/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.516, test=0.429) total time=   1.6s\n",
      "[CV 3/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 3/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.515, test=0.436) total time=   1.6s\n",
      "[CV 4/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 4/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.497, test=0.405) total time=   1.5s\n",
      "[CV 5/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 5/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.514, test=0.408) total time=   1.6s\n",
      "[CV 1/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 1/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.532, test=0.423) total time=   1.7s\n",
      "[CV 2/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 2/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.523, test=0.428) total time=   1.9s\n",
      "[CV 3/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 3/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.514, test=0.428) total time=   1.6s\n",
      "[CV 4/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 4/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.504, test=0.411) total time=   1.9s\n",
      "[CV 5/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 5/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.514, test=0.406) total time=   1.7s\n",
      "[CV 1/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 1/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.534, test=0.422) total time=   1.8s\n",
      "[CV 2/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 2/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.530, test=0.433) total time=   2.2s\n",
      "[CV 3/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 3/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.518, test=0.438) total time=   1.8s\n",
      "[CV 4/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 4/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.503, test=0.409) total time=   1.7s\n",
      "[CV 5/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 5/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.516, test=0.408) total time=   1.8s\n",
      "[CV 1/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 1/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.538, test=0.418) total time=   2.0s\n",
      "[CV 2/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 2/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.534, test=0.435) total time=   2.2s\n",
      "[CV 3/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 3/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.516, test=0.440) total time=   2.0s\n",
      "[CV 4/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 4/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.512, test=0.420) total time=   2.0s\n",
      "[CV 5/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 5/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.515, test=0.401) total time=   2.0s\n",
      "[CV 1/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 1/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.187, test=0.191) total time=   0.0s\n",
      "[CV 2/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 2/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.200, test=0.178) total time=   0.0s\n",
      "[CV 3/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 3/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.167, test=0.163) total time=   0.0s\n",
      "[CV 4/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 4/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.173, test=0.158) total time=   0.1s\n",
      "[CV 5/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 5/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.233, test=0.208) total time=   0.0s\n",
      "[CV 1/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 1/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.583, test=0.453) total time=   0.4s\n",
      "[CV 2/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 2/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.577, test=0.473) total time=   0.4s\n",
      "[CV 3/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 3/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.579, test=0.464) total time=   0.4s\n",
      "[CV 4/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 4/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.561, test=0.460) total time=   0.4s\n",
      "[CV 5/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 5/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.573, test=0.457) total time=   0.4s\n",
      "[CV 1/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 1/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.617, test=0.466) total time=   0.6s\n",
      "[CV 2/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 2/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.609, test=0.494) total time=   0.6s\n",
      "[CV 3/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 3/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.606, test=0.485) total time=   0.6s\n",
      "[CV 4/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 4/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.599, test=0.456) total time=   0.6s\n",
      "[CV 5/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 5/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.619, test=0.464) total time=   0.6s\n",
      "[CV 1/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 1/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.626, test=0.476) total time=   0.9s\n",
      "[CV 2/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 2/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.622, test=0.490) total time=   0.9s\n",
      "[CV 3/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 3/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.615, test=0.487) total time=   0.9s\n",
      "[CV 4/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 4/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.602, test=0.459) total time=   1.0s\n",
      "[CV 5/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 5/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.624, test=0.469) total time=   0.9s\n",
      "[CV 1/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 1/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.637, test=0.484) total time=   1.1s\n",
      "[CV 2/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 2/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.627, test=0.494) total time=   1.1s\n",
      "[CV 3/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 3/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.616, test=0.482) total time=   1.1s\n",
      "[CV 4/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 4/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.615, test=0.463) total time=   1.1s\n",
      "[CV 5/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 5/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.630, test=0.471) total time=   1.1s\n",
      "[CV 1/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 1/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.640, test=0.480) total time=   1.4s\n",
      "[CV 2/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 2/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.628, test=0.493) total time=   1.4s\n",
      "[CV 3/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 3/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.618, test=0.483) total time=   1.4s\n",
      "[CV 4/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 4/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.619, test=0.468) total time=   1.3s\n",
      "[CV 5/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 5/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.638, test=0.473) total time=   1.4s\n",
      "[CV 1/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 1/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.639, test=0.476) total time=   1.6s\n",
      "[CV 2/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 2/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.632, test=0.488) total time=   1.7s\n",
      "[CV 3/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 3/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.618, test=0.481) total time=   1.6s\n",
      "[CV 4/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 4/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.624, test=0.467) total time=   1.4s\n",
      "[CV 5/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 5/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.638, test=0.479) total time=   1.6s\n",
      "[CV 1/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 1/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.639, test=0.484) total time=   1.9s\n",
      "[CV 2/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 2/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.636, test=0.489) total time=   1.9s\n",
      "[CV 3/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 3/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.620, test=0.474) total time=   1.9s\n",
      "[CV 4/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 4/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.626, test=0.473) total time=   1.7s\n",
      "[CV 5/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 5/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.643, test=0.476) total time=   1.9s\n",
      "[CV 1/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 1/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.642, test=0.485) total time=   2.2s\n",
      "[CV 2/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 2/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.640, test=0.496) total time=   2.2s\n",
      "[CV 3/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 3/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.622, test=0.477) total time=   2.1s\n",
      "[CV 4/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 4/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.629, test=0.474) total time=   1.8s\n",
      "[CV 5/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 5/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.638, test=0.477) total time=   2.2s\n",
      "[CV 1/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 1/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.646, test=0.488) total time=   2.4s\n",
      "[CV 2/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 2/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.642, test=0.489) total time=   2.4s\n",
      "[CV 3/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 3/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.618, test=0.480) total time=   2.4s\n",
      "[CV 4/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 4/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.633, test=0.484) total time=   2.0s\n",
      "[CV 5/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 5/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.636, test=0.470) total time=   2.4s\n",
      "[CV 1/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 1/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.231, test=0.217) total time=   0.0s\n",
      "[CV 2/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 2/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.222, test=0.200) total time=   0.0s\n",
      "[CV 3/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 3/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.214, test=0.190) total time=   0.0s\n",
      "[CV 4/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 4/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.223, test=0.192) total time=   0.1s\n",
      "[CV 5/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 5/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.263, test=0.223) total time=   0.0s\n",
      "[CV 1/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 1/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.666, test=0.495) total time=   0.4s\n",
      "[CV 2/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 2/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.655, test=0.498) total time=   0.4s\n",
      "[CV 3/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 3/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.663, test=0.505) total time=   0.4s\n",
      "[CV 4/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 4/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.650, test=0.482) total time=   0.4s\n",
      "[CV 5/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 5/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.660, test=0.496) total time=   0.4s\n",
      "[CV 1/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 1/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.692, test=0.511) total time=   0.6s\n",
      "[CV 2/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 2/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.691, test=0.516) total time=   0.6s\n",
      "[CV 3/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 3/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.683, test=0.514) total time=   0.6s\n",
      "[CV 4/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 4/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.680, test=0.515) total time=   0.6s\n",
      "[CV 5/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 5/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.693, test=0.509) total time=   0.6s\n",
      "[CV 1/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 1/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.706, test=0.517) total time=   0.9s\n",
      "[CV 2/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 2/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.706, test=0.512) total time=   0.9s\n",
      "[CV 3/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 3/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.699, test=0.524) total time=   0.9s\n",
      "[CV 4/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 4/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.691, test=0.520) total time=   0.9s\n",
      "[CV 5/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 5/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.702, test=0.514) total time=   0.9s\n",
      "[CV 1/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 1/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.710, test=0.519) total time=   1.2s\n",
      "[CV 2/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 2/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.714, test=0.522) total time=   1.1s\n",
      "[CV 3/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 3/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.704, test=0.535) total time=   1.1s\n",
      "[CV 4/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 4/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.702, test=0.533) total time=   1.1s\n",
      "[CV 5/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 5/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.707, test=0.508) total time=   1.1s\n",
      "[CV 1/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 1/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.718, test=0.521) total time=   1.4s\n",
      "[CV 2/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 2/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.715, test=0.527) total time=   1.4s\n",
      "[CV 3/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 3/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.706, test=0.534) total time=   1.4s\n",
      "[CV 4/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 4/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.711, test=0.529) total time=   1.3s\n",
      "[CV 5/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 5/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.707, test=0.515) total time=   1.4s\n",
      "[CV 1/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 1/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.716, test=0.519) total time=   1.6s\n",
      "[CV 2/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 2/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.715, test=0.527) total time=   1.6s\n",
      "[CV 3/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 3/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.702, test=0.535) total time=   1.6s\n",
      "[CV 4/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 4/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.714, test=0.539) total time=   1.5s\n",
      "[CV 5/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 5/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.710, test=0.521) total time=   1.6s\n",
      "[CV 1/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 1/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.717, test=0.515) total time=   1.9s\n",
      "[CV 2/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 2/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.719, test=0.530) total time=   1.9s\n",
      "[CV 3/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 3/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.705, test=0.531) total time=   1.9s\n",
      "[CV 4/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 4/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.714, test=0.538) total time=   1.7s\n",
      "[CV 5/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 5/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.713, test=0.514) total time=   1.8s\n",
      "[CV 1/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 1/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.716, test=0.512) total time=   2.1s\n",
      "[CV 2/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 2/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.720, test=0.529) total time=   2.0s\n",
      "[CV 3/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 3/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.710, test=0.526) total time=   2.0s\n",
      "[CV 4/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 4/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.713, test=0.535) total time=   1.9s\n",
      "[CV 5/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 5/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.715, test=0.516) total time=   2.0s\n",
      "[CV 1/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 1/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.718, test=0.514) total time=   2.2s\n",
      "[CV 2/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 2/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.723, test=0.534) total time=   2.2s\n",
      "[CV 3/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 3/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.709, test=0.520) total time=   2.2s\n",
      "[CV 4/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 4/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.715, test=0.540) total time=   2.0s\n",
      "[CV 5/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 5/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.713, test=0.514) total time=   2.2s\n",
      "[CV 1/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 1/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.272, test=0.243) total time=   0.0s\n",
      "[CV 2/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 2/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.276, test=0.232) total time=   0.0s\n",
      "[CV 3/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 3/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.248, test=0.217) total time=   0.0s\n",
      "[CV 4/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 4/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.270, test=0.224) total time=   0.1s\n",
      "[CV 5/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 5/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.298, test=0.239) total time=   0.0s\n",
      "[CV 1/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 1/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.721, test=0.540) total time=   0.3s\n",
      "[CV 2/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 2/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.723, test=0.525) total time=   0.4s\n",
      "[CV 3/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 3/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.726, test=0.546) total time=   0.4s\n",
      "[CV 4/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 4/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.715, test=0.525) total time=   0.4s\n",
      "[CV 5/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 5/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.722, test=0.530) total time=   0.3s\n",
      "[CV 1/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 1/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.746, test=0.541) total time=   0.6s\n",
      "[CV 2/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 2/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.750, test=0.552) total time=   0.6s\n",
      "[CV 3/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 3/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.750, test=0.553) total time=   0.6s\n",
      "[CV 4/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 4/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.741, test=0.540) total time=   0.7s\n",
      "[CV 5/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 5/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.748, test=0.527) total time=   0.6s\n",
      "[CV 1/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 1/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.758, test=0.544) total time=   0.9s\n",
      "[CV 2/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 2/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.757, test=0.552) total time=   0.9s\n",
      "[CV 3/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 3/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.759, test=0.563) total time=   1.0s\n",
      "[CV 4/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 4/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.753, test=0.559) total time=   1.0s\n",
      "[CV 5/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 5/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.754, test=0.539) total time=   0.9s\n",
      "[CV 1/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 1/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.765, test=0.550) total time=   1.2s\n",
      "[CV 2/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 2/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.764, test=0.555) total time=   1.2s\n",
      "[CV 3/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 3/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.761, test=0.564) total time=   1.2s\n",
      "[CV 4/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 4/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.759, test=0.559) total time=   1.2s\n",
      "[CV 5/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 5/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.759, test=0.542) total time=   1.2s\n",
      "[CV 1/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 1/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.766, test=0.553) total time=   1.6s\n",
      "[CV 2/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 2/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.765, test=0.555) total time=   1.5s\n",
      "[CV 3/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 3/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.761, test=0.564) total time=   1.5s\n",
      "[CV 4/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 4/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.760, test=0.560) total time=   1.5s\n",
      "[CV 5/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 5/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.758, test=0.538) total time=   1.5s\n",
      "[CV 1/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 1/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.766, test=0.546) total time=   1.8s\n",
      "[CV 2/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 2/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.764, test=0.558) total time=   1.7s\n",
      "[CV 3/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 3/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.759, test=0.563) total time=   1.8s\n",
      "[CV 4/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 4/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.762, test=0.558) total time=   1.7s\n",
      "[CV 5/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 5/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.761, test=0.545) total time=   1.7s\n",
      "[CV 1/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 1/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.766, test=0.542) total time=   2.1s\n",
      "[CV 2/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 2/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.767, test=0.560) total time=   2.0s\n",
      "[CV 3/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 3/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.760, test=0.563) total time=   2.1s\n",
      "[CV 4/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 4/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.766, test=0.559) total time=   1.9s\n",
      "[CV 5/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 5/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.763, test=0.545) total time=   2.0s\n",
      "[CV 1/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 1/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.766, test=0.541) total time=   2.3s\n",
      "[CV 2/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 2/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.772, test=0.558) total time=   2.3s\n",
      "[CV 3/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 3/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.763, test=0.560) total time=   2.3s\n",
      "[CV 4/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 4/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.765, test=0.561) total time=   2.2s\n",
      "[CV 5/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 5/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.763, test=0.539) total time=   2.3s\n",
      "[CV 1/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 1/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.768, test=0.551) total time=   2.6s\n",
      "[CV 2/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 2/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.770, test=0.555) total time=   2.6s\n",
      "[CV 3/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 3/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.762, test=0.555) total time=   2.8s\n",
      "[CV 4/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 4/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.766, test=0.565) total time=   2.7s\n",
      "[CV 5/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 5/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.765, test=0.541) total time=   2.7s\n",
      "[CV 1/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 1/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.324, test=0.281) total time=   0.0s\n",
      "[CV 2/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 2/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.301, test=0.262) total time=   0.0s\n",
      "[CV 3/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 3/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.275, test=0.240) total time=   0.0s\n",
      "[CV 4/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 4/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.310, test=0.251) total time=   0.1s\n",
      "[CV 5/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 5/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.339, test=0.281) total time=   0.0s\n",
      "[CV 1/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 1/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.766, test=0.559) total time=   0.4s\n",
      "[CV 2/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 2/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.771, test=0.551) total time=   0.4s\n",
      "[CV 3/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 3/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.772, test=0.559) total time=   0.4s\n",
      "[CV 4/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 4/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.763, test=0.555) total time=   0.5s\n",
      "[CV 5/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 5/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.762, test=0.557) total time=   0.4s\n",
      "[CV 1/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 1/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.787, test=0.569) total time=   0.8s\n",
      "[CV 2/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 2/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.790, test=0.564) total time=   0.7s\n",
      "[CV 3/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 3/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.794, test=0.588) total time=   0.8s\n",
      "[CV 4/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 4/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.793, test=0.569) total time=   0.8s\n",
      "[CV 5/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 5/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.786, test=0.553) total time=   0.7s\n",
      "[CV 1/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 1/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.797, test=0.578) total time=   1.8s\n",
      "[CV 2/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 2/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.799, test=0.568) total time=   1.3s\n",
      "[CV 3/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 3/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.798, test=0.581) total time=   1.3s\n",
      "[CV 4/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 4/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.793, test=0.574) total time=   1.4s\n",
      "[CV 5/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 5/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.795, test=0.557) total time=   1.3s\n",
      "[CV 1/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 1/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.803, test=0.580) total time=   1.7s\n",
      "[CV 2/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 2/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.806, test=0.573) total time=   1.7s\n",
      "[CV 3/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 3/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.800, test=0.581) total time=   1.7s\n",
      "[CV 4/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 4/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.799, test=0.579) total time=   1.7s\n",
      "[CV 5/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 5/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.800, test=0.564) total time=   1.7s\n",
      "[CV 1/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 1/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.802, test=0.577) total time=   2.1s\n",
      "[CV 2/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 2/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.804, test=0.578) total time=   2.1s\n",
      "[CV 3/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 3/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.801, test=0.582) total time=   2.1s\n",
      "[CV 4/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 4/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.804, test=0.582) total time=   2.0s\n",
      "[CV 5/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 5/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.800, test=0.563) total time=   2.1s\n",
      "[CV 1/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 1/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.804, test=0.571) total time=   2.5s\n",
      "[CV 2/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 2/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.799, test=0.576) total time=   2.4s\n",
      "[CV 3/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 3/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.800, test=0.590) total time=   2.4s\n",
      "[CV 4/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 4/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.803, test=0.582) total time=   2.4s\n",
      "[CV 5/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 5/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.803, test=0.564) total time=   2.4s\n",
      "[CV 1/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 1/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.803, test=0.572) total time=   2.8s\n",
      "[CV 2/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 2/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.803, test=0.574) total time=   2.8s\n",
      "[CV 3/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 3/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.801, test=0.592) total time=   2.8s\n",
      "[CV 4/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 4/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.804, test=0.584) total time=   2.7s\n",
      "[CV 5/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 5/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.804, test=0.562) total time=   2.7s\n",
      "[CV 1/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 1/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.806, test=0.571) total time=   3.1s\n",
      "[CV 2/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 2/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.805, test=0.576) total time=   3.0s\n",
      "[CV 3/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 3/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.801, test=0.585) total time=   3.1s\n",
      "[CV 4/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 4/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.805, test=0.583) total time=   3.0s\n",
      "[CV 5/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 5/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.804, test=0.561) total time=   3.0s\n",
      "[CV 1/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 1/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.806, test=0.570) total time=   3.4s\n",
      "[CV 2/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 2/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.807, test=0.583) total time=   3.4s\n",
      "[CV 3/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 3/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.803, test=0.584) total time=   3.4s\n",
      "[CV 4/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 4/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.805, test=0.585) total time=   3.3s\n",
      "[CV 5/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 5/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.804, test=0.559) total time=   3.4s\n",
      "[CV 1/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 1/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.352, test=0.293) total time=   0.0s\n",
      "[CV 2/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 2/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.340, test=0.274) total time=   0.0s\n",
      "[CV 3/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 3/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.304, test=0.251) total time=   0.0s\n",
      "[CV 4/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 4/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.345, test=0.276) total time=   0.1s\n",
      "[CV 5/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 5/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.377, test=0.300) total time=   0.0s\n",
      "[CV 1/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 1/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.807, test=0.587) total time=   0.5s\n",
      "[CV 2/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 2/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.809, test=0.574) total time=   0.5s\n",
      "[CV 3/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 3/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.807, test=0.580) total time=   0.5s\n",
      "[CV 4/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 4/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.797, test=0.571) total time=   0.6s\n",
      "[CV 5/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 5/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.799, test=0.573) total time=   0.5s\n",
      "[CV 1/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 1/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.823, test=0.594) total time=   1.0s\n",
      "[CV 2/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 2/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.824, test=0.588) total time=   1.0s\n",
      "[CV 3/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 3/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.827, test=0.593) total time=   1.0s\n",
      "[CV 4/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 4/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.821, test=0.583) total time=   1.0s\n",
      "[CV 5/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 5/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.814, test=0.572) total time=   0.9s\n",
      "[CV 1/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 1/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.828, test=0.594) total time=   1.5s\n",
      "[CV 2/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 2/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.828, test=0.592) total time=   1.4s\n",
      "[CV 3/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 3/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.831, test=0.602) total time=   1.5s\n",
      "[CV 4/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 4/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.829, test=0.590) total time=   1.5s\n",
      "[CV 5/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 5/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.823, test=0.568) total time=   1.4s\n",
      "[CV 1/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 1/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.834, test=0.601) total time=   1.9s\n",
      "[CV 2/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 2/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.834, test=0.596) total time=   1.9s\n",
      "[CV 3/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 3/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.831, test=0.605) total time=   1.9s\n",
      "[CV 4/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 4/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.830, test=0.598) total time=   1.9s\n",
      "[CV 5/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 5/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.827, test=0.578) total time=   1.9s\n",
      "[CV 1/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 1/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.834, test=0.599) total time=   2.4s\n",
      "[CV 2/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 2/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.833, test=0.596) total time=   2.4s\n",
      "[CV 3/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 3/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.830, test=0.603) total time=   2.4s\n",
      "[CV 4/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 4/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.834, test=0.595) total time=   2.4s\n",
      "[CV 5/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 5/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.826, test=0.572) total time=   2.4s\n",
      "[CV 1/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 1/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.835, test=0.598) total time=   2.9s\n",
      "[CV 2/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 2/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.833, test=0.599) total time=   2.8s\n",
      "[CV 3/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 3/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.829, test=0.609) total time=   2.9s\n",
      "[CV 4/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 4/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.833, test=0.604) total time=   2.7s\n",
      "[CV 5/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 5/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.827, test=0.582) total time=   2.9s\n",
      "[CV 1/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 1/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.835, test=0.595) total time=   3.4s\n",
      "[CV 2/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 2/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.833, test=0.599) total time=   3.3s\n",
      "[CV 3/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 3/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.830, test=0.607) total time=   3.3s\n",
      "[CV 4/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 4/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.833, test=0.600) total time=   3.2s\n",
      "[CV 5/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 5/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.830, test=0.583) total time=   3.3s\n",
      "[CV 1/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 1/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.834, test=0.594) total time=   3.9s\n",
      "[CV 2/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 2/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.835, test=0.600) total time=   3.8s\n",
      "[CV 3/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 3/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.831, test=0.607) total time=   3.8s\n",
      "[CV 4/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 4/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.835, test=0.606) total time=   3.7s\n",
      "[CV 5/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 5/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.828, test=0.587) total time=   3.8s\n",
      "[CV 1/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 1/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.837, test=0.593) total time=   4.4s\n",
      "[CV 2/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 2/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.835, test=0.597) total time=   4.2s\n",
      "[CV 3/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 3/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.832, test=0.606) total time=   4.3s\n",
      "[CV 4/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 4/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.833, test=0.604) total time=   4.1s\n",
      "[CV 5/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 5/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.830, test=0.583) total time=   4.3s\n",
      "[CV 1/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 1/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.393, test=0.314) total time=   0.0s\n",
      "[CV 2/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 2/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.365, test=0.296) total time=   0.0s\n",
      "[CV 3/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 3/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.343, test=0.284) total time=   0.0s\n",
      "[CV 4/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 4/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.390, test=0.308) total time=   0.1s\n",
      "[CV 5/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 5/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.393, test=0.300) total time=   0.0s\n",
      "[CV 1/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 1/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.833, test=0.587) total time=   0.6s\n",
      "[CV 2/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 2/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.836, test=0.581) total time=   0.6s\n",
      "[CV 3/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 3/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.827, test=0.598) total time=   0.6s\n",
      "[CV 4/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 4/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.831, test=0.579) total time=   0.7s\n",
      "[CV 5/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 5/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.819, test=0.579) total time=   0.6s\n",
      "[CV 1/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 1/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.846, test=0.606) total time=   1.2s\n",
      "[CV 2/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 2/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.845, test=0.598) total time=   1.2s\n",
      "[CV 3/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 3/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.849, test=0.598) total time=   1.2s\n",
      "[CV 4/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 4/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.852, test=0.592) total time=   1.2s\n",
      "[CV 5/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 5/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.839, test=0.591) total time=   1.2s\n",
      "[CV 1/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 1/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.851, test=0.605) total time=   1.8s\n",
      "[CV 2/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 2/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.849, test=0.595) total time=   1.8s\n",
      "[CV 3/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 3/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.855, test=0.609) total time=   1.8s\n",
      "[CV 4/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 4/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.852, test=0.608) total time=   1.8s\n",
      "[CV 5/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 5/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.845, test=0.589) total time=   1.7s\n",
      "[CV 1/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 1/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.852, test=0.603) total time=   2.4s\n",
      "[CV 2/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 2/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.855, test=0.598) total time=   2.3s\n",
      "[CV 3/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 3/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.856, test=0.618) total time=   2.4s\n",
      "[CV 4/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 4/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.854, test=0.621) total time=   2.3s\n",
      "[CV 5/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 5/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.847, test=0.599) total time=   2.3s\n",
      "[CV 1/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 1/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.854, test=0.606) total time=   3.0s\n",
      "[CV 2/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 2/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.855, test=0.601) total time=   2.9s\n",
      "[CV 3/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 3/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.853, test=0.613) total time=   3.0s\n",
      "[CV 4/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 4/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.856, test=0.612) total time=   2.9s\n",
      "[CV 5/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 5/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.848, test=0.598) total time=   2.9s\n",
      "[CV 1/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 1/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.855, test=0.610) total time=   3.6s\n",
      "[CV 2/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 2/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.855, test=0.611) total time=   3.5s\n",
      "[CV 3/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 3/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.853, test=0.618) total time=   3.5s\n",
      "[CV 4/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 4/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.860, test=0.622) total time=   3.4s\n",
      "[CV 5/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 5/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.849, test=0.608) total time=   3.5s\n",
      "[CV 1/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 1/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.856, test=0.614) total time=   4.2s\n",
      "[CV 2/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 2/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.857, test=0.612) total time=   4.1s\n",
      "[CV 3/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 3/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.853, test=0.617) total time=   4.1s\n",
      "[CV 4/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 4/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.857, test=0.620) total time=   4.0s\n",
      "[CV 5/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 5/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.849, test=0.606) total time=   4.1s\n",
      "[CV 1/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 1/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.855, test=0.615) total time=   4.7s\n",
      "[CV 2/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 2/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.858, test=0.609) total time=   4.7s\n",
      "[CV 3/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 3/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.852, test=0.619) total time=   4.7s\n",
      "[CV 4/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 4/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.860, test=0.625) total time=   4.5s\n",
      "[CV 5/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 5/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.850, test=0.609) total time=   4.6s\n",
      "[CV 1/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 1/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.859, test=0.613) total time=   5.3s\n",
      "[CV 2/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 2/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.857, test=0.607) total time=   5.3s\n",
      "[CV 3/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 3/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.853, test=0.618) total time=   5.3s\n",
      "[CV 4/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 4/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.860, test=0.633) total time=   5.1s\n",
      "[CV 5/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 5/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.853, test=0.609) total time=   5.3s\n",
      "[CV 1/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 1/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.416, test=0.331) total time=   0.0s\n",
      "[CV 2/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 2/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.391, test=0.306) total time=   0.0s\n",
      "[CV 3/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 3/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.366, test=0.310) total time=   0.0s\n",
      "[CV 4/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 4/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.409, test=0.328) total time=   0.2s\n",
      "[CV 5/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 5/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.431, test=0.315) total time=   0.0s\n",
      "[CV 1/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 1/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.854, test=0.597) total time=   0.7s\n",
      "[CV 2/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 2/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.861, test=0.598) total time=   0.7s\n",
      "[CV 3/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 3/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.857, test=0.622) total time=   0.8s\n",
      "[CV 4/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 4/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.851, test=0.585) total time=   0.8s\n",
      "[CV 5/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 5/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.849, test=0.595) total time=   0.7s\n",
      "[CV 1/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 1/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.870, test=0.607) total time=   1.4s\n",
      "[CV 2/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 2/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.869, test=0.611) total time=   1.4s\n",
      "[CV 3/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 3/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.872, test=0.631) total time=   1.5s\n",
      "[CV 4/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 4/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.868, test=0.612) total time=   1.5s\n",
      "[CV 5/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 5/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.859, test=0.597) total time=   1.4s\n",
      "[CV 1/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 1/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.870, test=0.612) total time=   2.1s\n",
      "[CV 2/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 2/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.873, test=0.624) total time=   2.1s\n",
      "[CV 3/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 3/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.875, test=0.633) total time=   2.2s\n",
      "[CV 4/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 4/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.874, test=0.625) total time=   2.1s\n",
      "[CV 5/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 5/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.867, test=0.601) total time=   2.1s\n",
      "[CV 1/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 1/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.874, test=0.619) total time=   2.9s\n",
      "[CV 2/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 2/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.875, test=0.625) total time=   2.8s\n",
      "[CV 3/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 3/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.874, test=0.634) total time=   2.9s\n",
      "[CV 4/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 4/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.875, test=0.633) total time=   2.8s\n",
      "[CV 5/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 5/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.868, test=0.600) total time=   2.8s\n",
      "[CV 1/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 1/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.874, test=0.613) total time=   3.6s\n",
      "[CV 2/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 2/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.877, test=0.623) total time=   3.5s\n",
      "[CV 3/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 3/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.873, test=0.631) total time=   3.6s\n",
      "[CV 4/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 4/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.877, test=0.633) total time=   3.4s\n",
      "[CV 5/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 5/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.870, test=0.605) total time=   3.5s\n",
      "[CV 1/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 1/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.875, test=0.618) total time=   4.3s\n",
      "[CV 2/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 2/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.873, test=0.619) total time=   4.2s\n",
      "[CV 3/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 3/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.872, test=0.632) total time=   4.2s\n",
      "[CV 4/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 4/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.877, test=0.637) total time=   4.1s\n",
      "[CV 5/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 5/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.870, test=0.610) total time=   4.2s\n",
      "[CV 1/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 1/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.874, test=0.615) total time=   5.0s\n",
      "[CV 2/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 2/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.876, test=0.624) total time=   4.9s\n",
      "[CV 3/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 3/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.872, test=0.628) total time=   5.0s\n",
      "[CV 4/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 4/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.877, test=0.632) total time=   4.7s\n",
      "[CV 5/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 5/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.871, test=0.611) total time=   5.0s\n",
      "[CV 1/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 1/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.874, test=0.622) total time=   5.7s\n",
      "[CV 2/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 2/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.876, test=0.624) total time=   5.6s\n",
      "[CV 3/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 3/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.872, test=0.629) total time=   5.7s\n",
      "[CV 4/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 4/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.878, test=0.637) total time=   5.4s\n",
      "[CV 5/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 5/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.872, test=0.612) total time=   7.6s\n",
      "[CV 1/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 1/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.875, test=0.624) total time=   6.7s\n",
      "[CV 2/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 2/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.876, test=0.627) total time=   6.5s\n",
      "[CV 3/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 3/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.870, test=0.622) total time=   6.5s\n",
      "[CV 4/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 4/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.878, test=0.637) total time=   6.2s\n",
      "[CV 5/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 5/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.873, test=0.614) total time=   6.4s\n",
      "[CV 1/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 1/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.435, test=0.339) total time=   0.0s\n",
      "[CV 2/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 2/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.413, test=0.322) total time=   0.0s\n",
      "[CV 3/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 3/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.389, test=0.303) total time=   0.0s\n",
      "[CV 4/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 4/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.441, test=0.335) total time=   0.2s\n",
      "[CV 5/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 5/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.452, test=0.349) total time=   0.0s\n",
      "[CV 1/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 1/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.869, test=0.608) total time=   0.9s\n",
      "[CV 2/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 2/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.872, test=0.600) total time=   0.9s\n",
      "[CV 3/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 3/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.872, test=0.609) total time=   0.9s\n",
      "[CV 4/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 4/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.871, test=0.613) total time=   1.0s\n",
      "[CV 5/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 5/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.865, test=0.607) total time=   0.9s\n",
      "[CV 1/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 1/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.880, test=0.626) total time=   1.7s\n",
      "[CV 2/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 2/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.883, test=0.621) total time=   1.7s\n",
      "[CV 3/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 3/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.886, test=0.629) total time=   1.8s\n",
      "[CV 4/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 4/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.884, test=0.618) total time=   1.8s\n",
      "[CV 5/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 5/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.872, test=0.606) total time=   1.7s\n",
      "[CV 1/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 1/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.883, test=0.631) total time=   2.6s\n",
      "[CV 2/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 2/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.885, test=0.629) total time=   2.5s\n",
      "[CV 3/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 3/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.890, test=0.634) total time=   2.7s\n",
      "[CV 4/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 4/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.885, test=0.626) total time=   2.6s\n",
      "[CV 5/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 5/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.879, test=0.624) total time=   2.7s\n",
      "[CV 1/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 1/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.886, test=0.630) total time=   3.4s\n",
      "[CV 2/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 2/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.889, test=0.634) total time=   3.3s\n",
      "[CV 3/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 3/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.891, test=0.637) total time=   3.4s\n",
      "[CV 4/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 4/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.887, test=0.631) total time=   3.4s\n",
      "[CV 5/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 5/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.878, test=0.623) total time=   3.3s\n",
      "[CV 1/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 1/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.888, test=0.638) total time=   4.3s\n",
      "[CV 2/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 2/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.890, test=0.628) total time=   4.2s\n",
      "[CV 3/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 3/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.890, test=0.635) total time=   4.2s\n",
      "[CV 4/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 4/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.889, test=0.636) total time=   4.2s\n",
      "[CV 5/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 5/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.882, test=0.621) total time=   4.3s\n",
      "[CV 1/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 1/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.888, test=0.639) total time=   5.1s\n",
      "[CV 2/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 2/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.890, test=0.626) total time=   4.9s\n",
      "[CV 3/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 3/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.886, test=0.633) total time=   5.0s\n",
      "[CV 4/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 4/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.891, test=0.639) total time=   5.0s\n",
      "[CV 5/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 5/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.882, test=0.624) total time=   4.9s\n",
      "[CV 1/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 1/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.889, test=0.637) total time=   5.9s\n",
      "[CV 2/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 2/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.892, test=0.627) total time=   5.8s\n",
      "[CV 3/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 3/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.886, test=0.637) total time=   5.8s\n",
      "[CV 4/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 4/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.892, test=0.642) total time=   5.7s\n",
      "[CV 5/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 5/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.883, test=0.627) total time=   6.0s\n",
      "[CV 1/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 1/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.888, test=0.640) total time=   6.7s\n",
      "[CV 2/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 2/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.892, test=0.624) total time=   6.5s\n",
      "[CV 3/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 3/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.888, test=0.637) total time=   6.7s\n",
      "[CV 4/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 4/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.893, test=0.636) total time=   6.6s\n",
      "[CV 5/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 5/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.882, test=0.624) total time=   6.9s\n",
      "[CV 1/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 1/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.889, test=0.641) total time=   7.5s\n",
      "[CV 2/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 2/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.891, test=0.628) total time=   7.7s\n",
      "[CV 3/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 3/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.887, test=0.639) total time=   7.5s\n",
      "[CV 4/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 4/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.892, test=0.639) total time=   7.4s\n",
      "[CV 5/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 5/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.886, test=0.624) total time=   7.8s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 20\n",
      "n_resources: 58040\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5; 1/20] START rfc__max_depth=41, rfc__n_estimators=101...................\n",
      "[CV 1/5; 1/20] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.831, test=0.749) total time=   5.5s\n",
      "[CV 2/5; 1/20] START rfc__max_depth=41, rfc__n_estimators=101...................\n",
      "[CV 2/5; 1/20] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.833, test=0.763) total time=   5.5s\n",
      "[CV 3/5; 1/20] START rfc__max_depth=41, rfc__n_estimators=101...................\n",
      "[CV 3/5; 1/20] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.827, test=0.751) total time=   5.6s\n",
      "[CV 4/5; 1/20] START rfc__max_depth=41, rfc__n_estimators=101...................\n",
      "[CV 4/5; 1/20] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.827, test=0.748) total time=   5.6s\n",
      "[CV 5/5; 1/20] START rfc__max_depth=41, rfc__n_estimators=101...................\n",
      "[CV 5/5; 1/20] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.829, test=0.745) total time=   5.3s\n",
      "[CV 1/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 1/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.809, test=0.733) total time=  12.9s\n",
      "[CV 2/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 2/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.812, test=0.744) total time=  12.7s\n",
      "[CV 3/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 3/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.815, test=0.742) total time=  12.9s\n",
      "[CV 4/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 4/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.813, test=0.738) total time=  13.0s\n",
      "[CV 5/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 5/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.813, test=0.733) total time=  12.8s\n",
      "[CV 1/5; 3/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 1/5; 3/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.811, test=0.735) total time=  15.1s\n",
      "[CV 2/5; 3/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 2/5; 3/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.813, test=0.746) total time=  14.8s\n",
      "[CV 3/5; 3/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 3/5; 3/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.814, test=0.741) total time=  15.3s\n",
      "[CV 4/5; 3/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 4/5; 3/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.814, test=0.736) total time=  15.3s\n",
      "[CV 5/5; 3/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 5/5; 3/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.812, test=0.736) total time=  15.0s\n",
      "[CV 1/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 1/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.811, test=0.735) total time=  17.4s\n",
      "[CV 2/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 2/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.816, test=0.748) total time=  17.2s\n",
      "[CV 3/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 3/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.814, test=0.740) total time=  17.2s\n",
      "[CV 4/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 4/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.814, test=0.736) total time=  17.3s\n",
      "[CV 5/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 5/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.813, test=0.736) total time=  17.3s\n",
      "[CV 1/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 1/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.813, test=0.738) total time=  19.3s\n",
      "[CV 2/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 2/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.815, test=0.747) total time=  19.2s\n",
      "[CV 3/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 3/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.814, test=0.741) total time=  19.3s\n",
      "[CV 4/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 4/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.814, test=0.735) total time=  19.4s\n",
      "[CV 5/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 5/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.814, test=0.736) total time=  19.2s\n",
      "[CV 1/5; 6/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 1/5; 6/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.831, test=0.754) total time=   8.0s\n",
      "[CV 2/5; 6/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 2/5; 6/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.833, test=0.762) total time=   8.0s\n",
      "[CV 3/5; 6/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 3/5; 6/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.830, test=0.754) total time=   8.0s\n",
      "[CV 4/5; 6/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 4/5; 6/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.832, test=0.757) total time=   8.0s\n",
      "[CV 5/5; 6/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 5/5; 6/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.835, test=0.748) total time=   7.8s\n",
      "[CV 1/5; 7/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 1/5; 7/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.851, test=0.770) total time=   6.4s\n",
      "[CV 2/5; 7/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 2/5; 7/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.851, test=0.773) total time=   6.3s\n",
      "[CV 3/5; 7/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 3/5; 7/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.845, test=0.766) total time=   6.5s\n",
      "[CV 4/5; 7/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 4/5; 7/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.845, test=0.767) total time=   6.5s\n",
      "[CV 5/5; 7/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 5/5; 7/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.848, test=0.762) total time=   6.2s\n",
      "[CV 1/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 1/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.834, test=0.757) total time=  13.0s\n",
      "[CV 2/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 2/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.832, test=0.763) total time=  12.9s\n",
      "[CV 3/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 3/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.836, test=0.760) total time=  13.0s\n",
      "[CV 4/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 4/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.834, test=0.759) total time=  13.3s\n",
      "[CV 5/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 5/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.835, test=0.752) total time=  12.7s\n",
      "[CV 1/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=201...................\n",
      "[CV 1/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.834, test=0.757) total time=  10.5s\n",
      "[CV 2/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=201...................\n",
      "[CV 2/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.833, test=0.762) total time=  10.4s\n",
      "[CV 3/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=201...................\n",
      "[CV 3/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.833, test=0.757) total time=  10.6s\n",
      "[CV 4/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=201...................\n",
      "[CV 4/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.833, test=0.760) total time=  10.7s\n",
      "[CV 5/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=201...................\n",
      "[CV 5/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.834, test=0.751) total time=  10.3s\n",
      "[CV 1/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=351..................\n",
      "[CV 1/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.835, test=0.757) total time=  18.2s\n",
      "[CV 2/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=351..................\n",
      "[CV 2/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.834, test=0.763) total time=  17.8s\n",
      "[CV 3/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=351..................\n",
      "[CV 3/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.837, test=0.763) total time=  18.2s\n",
      "[CV 4/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=351..................\n",
      "[CV 4/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.835, test=0.761) total time=  18.2s\n",
      "[CV 5/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=351..................\n",
      "[CV 5/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.834, test=0.752) total time=  17.9s\n",
      "[CV 1/5; 11/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 1/5; 11/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.835, test=0.757) total time=  15.5s\n",
      "[CV 2/5; 11/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 2/5; 11/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.834, test=0.764) total time=  15.3s\n",
      "[CV 3/5; 11/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 3/5; 11/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.836, test=0.762) total time=  15.7s\n",
      "[CV 4/5; 11/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 4/5; 11/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.836, test=0.761) total time=  16.0s\n",
      "[CV 5/5; 11/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 5/5; 11/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.836, test=0.753) total time=  15.5s\n",
      "[CV 1/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 1/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.835, test=0.758) total time=  20.6s\n",
      "[CV 2/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 2/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.835, test=0.765) total time=  20.4s\n",
      "[CV 3/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 3/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.837, test=0.763) total time=  20.7s\n",
      "[CV 4/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 4/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.835, test=0.760) total time=  20.8s\n",
      "[CV 5/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 5/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.834, test=0.752) total time=  20.6s\n",
      "[CV 1/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 1/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.835, test=0.757) total time=  23.2s\n",
      "[CV 2/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 2/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.836, test=0.767) total time=  22.9s\n",
      "[CV 3/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 3/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.837, test=0.762) total time=  23.4s\n",
      "[CV 4/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 4/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.834, test=0.759) total time=  23.4s\n",
      "[CV 5/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 5/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.835, test=0.754) total time=  23.3s\n",
      "[CV 1/5; 14/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 1/5; 14/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.852, test=0.771) total time=   9.4s\n",
      "[CV 2/5; 14/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 2/5; 14/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.851, test=0.775) total time=   9.3s\n",
      "[CV 3/5; 14/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 3/5; 14/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.846, test=0.771) total time=   9.4s\n",
      "[CV 4/5; 14/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 4/5; 14/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.852, test=0.775) total time=   9.4s\n",
      "[CV 5/5; 14/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 5/5; 14/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.851, test=0.769) total time=   9.1s\n",
      "[CV 1/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 1/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.854, test=0.774) total time=  12.4s\n",
      "[CV 2/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 2/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.851, test=0.775) total time=  12.8s\n",
      "[CV 3/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 3/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.849, test=0.772) total time=  12.5s\n",
      "[CV 4/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 4/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.853, test=0.775) total time=  12.6s\n",
      "[CV 5/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 5/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.852, test=0.771) total time=  12.1s\n",
      "[CV 1/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 1/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.852, test=0.774) total time=  15.2s\n",
      "[CV 2/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 2/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.850, test=0.775) total time=  15.0s\n",
      "[CV 3/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 3/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.850, test=0.773) total time=  15.3s\n",
      "[CV 4/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 4/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.852, test=0.776) total time=  15.5s\n",
      "[CV 5/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 5/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.852, test=0.770) total time=  15.0s\n",
      "[CV 1/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 1/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.855, test=0.776) total time=  24.3s\n",
      "[CV 2/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 2/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.853, test=0.780) total time=  23.9s\n",
      "[CV 3/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 3/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.852, test=0.776) total time=  24.4s\n",
      "[CV 4/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 4/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.852, test=0.777) total time=  24.6s\n",
      "[CV 5/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 5/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.852, test=0.771) total time=  24.2s\n",
      "[CV 1/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 1/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.853, test=0.773) total time=  18.4s\n",
      "[CV 2/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 2/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.851, test=0.776) total time=  19.8s\n",
      "[CV 3/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 3/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.851, test=0.775) total time=  18.5s\n",
      "[CV 4/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 4/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.852, test=0.778) total time=  18.8s\n",
      "[CV 5/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 5/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.853, test=0.772) total time=  18.4s\n",
      "[CV 1/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 1/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.854, test=0.773) total time=  21.6s\n",
      "[CV 2/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 2/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.852, test=0.779) total time=  21.1s\n",
      "[CV 3/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 3/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.852, test=0.777) total time=  21.5s\n",
      "[CV 4/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 4/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.853, test=0.778) total time=  21.8s\n",
      "[CV 5/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 5/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.852, test=0.771) total time=  21.3s\n",
      "[CV 1/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 1/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.855, test=0.775) total time=  27.5s\n",
      "[CV 2/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 2/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.854, test=0.781) total time=  27.2s\n",
      "[CV 3/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 3/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.852, test=0.776) total time=  27.4s\n",
      "[CV 4/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 4/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.853, test=0.776) total time=  27.8s\n",
      "[CV 5/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 5/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.852, test=0.772) total time=  27.2s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 290200\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=301....................\n",
      "[CV 1/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.840, test=0.821) total time= 2.1min\n",
      "[CV 2/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=301....................\n",
      "[CV 2/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.838, test=0.820) total time= 2.1min\n",
      "[CV 3/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=301....................\n",
      "[CV 3/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.835, test=0.818) total time= 2.1min\n",
      "[CV 4/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=301....................\n",
      "[CV 4/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.835, test=0.821) total time= 2.1min\n",
      "[CV 5/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=301....................\n",
      "[CV 5/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.837, test=0.816) total time= 2.1min\n",
      "[CV 1/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 1/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.841, test=0.823) total time= 2.4min\n",
      "[CV 2/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 2/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.839, test=0.820) total time= 2.4min\n",
      "[CV 3/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 3/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.836, test=0.818) total time= 2.4min\n",
      "[CV 4/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 4/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.838, test=0.823) total time= 2.4min\n",
      "[CV 5/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 5/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.838, test=0.817) total time= 2.4min\n",
      "[CV 1/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 1/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.842, test=0.823) total time= 3.1min\n",
      "[CV 2/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 2/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.840, test=0.822) total time= 3.1min\n",
      "[CV 3/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 3/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.838, test=0.820) total time= 3.1min\n",
      "[CV 4/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 4/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.839, test=0.823) total time= 3.1min\n",
      "[CV 5/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 5/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.838, test=0.818) total time= 3.1min\n",
      "[CV 1/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 1/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.841, test=0.822) total time= 2.8min\n",
      "[CV 2/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 2/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.838, test=0.820) total time= 2.8min\n",
      "[CV 3/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 3/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.837, test=0.819) total time= 2.8min\n",
      "[CV 4/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 4/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.839, test=0.823) total time= 2.8min\n",
      "[CV 5/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 5/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.839, test=0.818) total time= 2.7min\n",
      "0.8209651272500491\n",
      "{'rfc__max_depth': 46, 'rfc__n_estimators': 451}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "\n",
    "rfcgrid = {\n",
    "    'rfc__max_depth' : list(range(1,50,5)),\n",
    "    'rfc__n_estimators' : list(range(1,500,50)),\n",
    "}\n",
    "\n",
    "f1 = make_scorer(f1_score, average='macro') \n",
    "\n",
    "imba_pipe_rfc = Pipeline([\n",
    "    ('sampling', RandomOverSampler(random_state=0)), \n",
    "    ('rfc', rfc)\n",
    "    ])\n",
    "\n",
    "\n",
    "rfcrs = HalvingGridSearchCV(estimator=imba_pipe_rfc, param_grid=rfcgrid, factor=5, cv=5, scoring=f1, verbose=10)\n",
    "\n",
    "rfcrs.fit(x_trainvec, y_train.to_numpy().ravel())\n",
    "\n",
    "print(rfcrs.best_score_)\n",
    "print(rfcrs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Train Accuracy Score : 0.8295165569759829\n",
      "RFC Test Accuracy Score : 0.7552358113509192\n",
      "RFC Train F1 Score : 0.8369057182728585\n",
      "RFC Test F1 Score : 0.4101705085267285\n",
      "RFC Confusion matrix:\n",
      "[[   99    20    28    19   109]\n",
      " [    7    37     7     1     3]\n",
      " [   13    40   186    96   130]\n",
      " [   19    45   233   870  1297]\n",
      " [  155   124   423  1824 12980]]\n",
      "RFC Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.34      0.35       293\n",
      "           2       0.67      0.14      0.23       266\n",
      "           3       0.40      0.21      0.28       877\n",
      "           4       0.35      0.31      0.33      2810\n",
      "           5       0.84      0.89      0.86     14519\n",
      "\n",
      "    accuracy                           0.76     18765\n",
      "   macro avg       0.52      0.38      0.41     18765\n",
      "weighted avg       0.73      0.76      0.74     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rfc_train_predictions = rfcrs.best_estimator_.predict(x_trainvec)\n",
    "rfc_test_predictions = rfcrs.best_estimator_.predict(x_testvec)\n",
    "\n",
    "print(\"RFC Train Accuracy Score :\",accuracy_score(y_pred=rfc_train_predictions, y_true=y_train.to_numpy().ravel()))\n",
    "print(\"RFC Test Accuracy Score :\",accuracy_score(y_pred=rfc_test_predictions, y_true= y_test.to_numpy().ravel()))\n",
    "\n",
    "print(\"RFC Train F1 Score :\",f1_score(y_pred=rfc_train_predictions, y_true=y_train.to_numpy().ravel(), average = 'macro'))\n",
    "print(\"RFC Test F1 Score :\",f1_score(y_pred=rfc_test_predictions, y_true=y_test.to_numpy().ravel(), average = 'macro'))\n",
    "\n",
    "print(\"RFC Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= rfc_test_predictions)))\n",
    "print(\"RFC Classification report:\\n\",classification_report(y_pred=rfc_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.738 total time=   0.1s\n",
      "[CV 2/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.743 total time=   0.1s\n",
      "[CV 3/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.738 total time=   0.1s\n",
      "[CV 4/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.743 total time=   0.1s\n",
      "[CV 5/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.739 total time=   0.1s\n",
      "[CV 1/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 1/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.738 total time=   0.1s\n",
      "[CV 2/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 2/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.743 total time=   0.1s\n",
      "[CV 3/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 3/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.738 total time=   0.1s\n",
      "[CV 4/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 4/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.743 total time=   0.1s\n",
      "[CV 5/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 5/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.739 total time=   0.1s\n",
      "[CV 1/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.735 total time=   0.1s\n",
      "[CV 2/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.739 total time=   0.1s\n",
      "[CV 3/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.736 total time=   0.1s\n",
      "[CV 4/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.739 total time=   0.1s\n",
      "[CV 5/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.736 total time=   0.1s\n",
      "[CV 1/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 1/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.735 total time=   0.1s\n",
      "[CV 2/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 2/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.739 total time=   0.1s\n",
      "[CV 3/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 3/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.736 total time=   0.1s\n",
      "[CV 4/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 4/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.739 total time=   0.1s\n",
      "[CV 5/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 5/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.736 total time=   0.1s\n",
      "[CV 1/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.733 total time=   0.1s\n",
      "[CV 2/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.737 total time=   0.1s\n",
      "[CV 3/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.733 total time=   0.1s\n",
      "[CV 4/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.736 total time=   0.1s\n",
      "[CV 5/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.733 total time=   0.1s\n",
      "[CV 1/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 1/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.733 total time=   0.1s\n",
      "[CV 2/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 2/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.737 total time=   0.1s\n",
      "[CV 3/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 3/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.733 total time=   0.1s\n",
      "[CV 4/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 4/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.736 total time=   0.1s\n",
      "[CV 5/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 5/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.733 total time=   0.1s\n",
      "[CV 1/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.730 total time=   0.1s\n",
      "[CV 2/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.734 total time=   0.1s\n",
      "[CV 3/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.731 total time=   0.1s\n",
      "[CV 4/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.734 total time=   0.1s\n",
      "[CV 5/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.732 total time=   0.1s\n",
      "[CV 1/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 1/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.730 total time=   0.1s\n",
      "[CV 2/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 2/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.734 total time=   0.1s\n",
      "[CV 3/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 3/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.731 total time=   0.1s\n",
      "[CV 4/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 4/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.734 total time=   0.1s\n",
      "[CV 5/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 5/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.732 total time=   0.1s\n",
      "[CV 1/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.729 total time=   0.1s\n",
      "[CV 2/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.732 total time=   0.1s\n",
      "[CV 3/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.729 total time=   0.1s\n",
      "[CV 4/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.732 total time=   0.1s\n",
      "[CV 5/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.729 total time=   0.1s\n",
      "[CV 1/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.729 total time=   0.1s\n",
      "[CV 2/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.732 total time=   0.1s\n",
      "[CV 3/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.729 total time=   0.1s\n",
      "[CV 4/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.732 total time=   0.1s\n",
      "[CV 5/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.729 total time=   0.1s\n",
      "[CV 1/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 1/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.726 total time=   0.1s\n",
      "[CV 2/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 2/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.730 total time=   0.1s\n",
      "[CV 3/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 3/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.727 total time=   0.1s\n",
      "[CV 4/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 4/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.731 total time=   0.1s\n",
      "[CV 5/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 5/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.727 total time=   0.1s\n",
      "[CV 1/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.726 total time=   0.1s\n",
      "[CV 2/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.730 total time=   0.1s\n",
      "[CV 3/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.727 total time=   0.1s\n",
      "[CV 4/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.731 total time=   0.1s\n",
      "[CV 5/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.727 total time=   0.1s\n",
      "[CV 1/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 1/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.724 total time=   0.1s\n",
      "[CV 2/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 2/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.728 total time=   0.1s\n",
      "[CV 3/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 3/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.725 total time=   0.1s\n",
      "[CV 4/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 4/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.728 total time=   0.1s\n",
      "[CV 5/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 5/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.726 total time=   0.1s\n",
      "[CV 1/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.724 total time=   0.1s\n",
      "[CV 2/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.728 total time=   0.1s\n",
      "[CV 3/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.725 total time=   0.1s\n",
      "[CV 4/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.728 total time=   0.1s\n",
      "[CV 5/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.726 total time=   0.1s\n",
      "[CV 1/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 1/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.722 total time=   0.1s\n",
      "[CV 2/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 2/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.726 total time=   0.1s\n",
      "[CV 3/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 3/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.724 total time=   0.1s\n",
      "[CV 4/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 4/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.726 total time=   0.1s\n",
      "[CV 5/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 5/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.724 total time=   0.1s\n",
      "[CV 1/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.722 total time=   0.1s\n",
      "[CV 2/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.726 total time=   0.1s\n",
      "[CV 3/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.724 total time=   0.1s\n",
      "[CV 4/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.726 total time=   0.1s\n",
      "[CV 5/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.724 total time=   0.1s\n",
      "[CV 1/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 1/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.720 total time=   0.1s\n",
      "[CV 2/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 2/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.724 total time=   0.1s\n",
      "[CV 3/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 3/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.721 total time=   0.1s\n",
      "[CV 4/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 4/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.725 total time=   0.1s\n",
      "[CV 5/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 5/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.722 total time=   0.1s\n",
      "[CV 1/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.720 total time=   0.1s\n",
      "[CV 2/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.724 total time=   0.1s\n",
      "[CV 3/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.721 total time=   0.1s\n",
      "[CV 4/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.725 total time=   0.1s\n",
      "[CV 5/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.722 total time=   0.1s\n",
      "[CV 1/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 1/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.719 total time=   0.1s\n",
      "[CV 2/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 2/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.723 total time=   0.1s\n",
      "[CV 3/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 3/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.720 total time=   0.1s\n",
      "[CV 4/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 4/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.722 total time=   0.1s\n",
      "[CV 5/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 5/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.721 total time=   0.1s\n",
      "[CV 1/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 1/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.719 total time=   0.1s\n",
      "[CV 2/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 2/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.723 total time=   0.1s\n",
      "[CV 3/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 3/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.720 total time=   0.1s\n",
      "[CV 4/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 4/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.722 total time=   0.1s\n",
      "[CV 5/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 5/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.721 total time=   0.1s\n",
      "0.7400735730255236\n",
      "{'mnbc__alpha': 0.1, 'mnbc__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "mnbc = MultinomialNB()\n",
    "\n",
    "mnbc.get_params()\n",
    "\n",
    "mnbc_grid = {\n",
    "    'mnbc__alpha' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "    'mnbc__fit_prior' : [True, False]\n",
    "}\n",
    "\n",
    "imba_pipe_mnbc = Pipeline([\n",
    "    ('sampling', RandomOverSampler(random_state=0)), \n",
    "    ('mnbc', mnbc)\n",
    "    ])\n",
    "\n",
    "f1 = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "mnbcgs = GridSearchCV(estimator=imba_pipe_mnbc, param_grid=mnbc_grid, cv=5, scoring=f1, verbose=10)\n",
    "\n",
    "mnbcgs.fit(x_trainvec, y_train.to_numpy().ravel())\n",
    "\n",
    "print(mnbcgs.best_score_)\n",
    "print(mnbcgs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNBC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNBC Model Train Accuracy Score : 0.7614899555494298\n",
      "MNBC Model Test Accuracy Score : 0.5992539301891819\n",
      "MNBC Model Train F1 Score : 0.7589434104347412\n",
      "MNBC Model Test F1 Score : 0.3278294100896285\n",
      "MNBC Confusion matrix:\n",
      "[[ 134   27   78  117  619]\n",
      " [  38   93   94  172  539]\n",
      " [  46   66  299  434  979]\n",
      " [  40   54  258  986 2649]\n",
      " [  35   26  148 1101 9733]]\n",
      "MNBC Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.14      0.46      0.21       293\n",
      "           2       0.10      0.35      0.15       266\n",
      "           3       0.16      0.34      0.22       877\n",
      "           4       0.25      0.35      0.29      2810\n",
      "           5       0.88      0.67      0.76     14519\n",
      "\n",
      "    accuracy                           0.60     18765\n",
      "   macro avg       0.31      0.43      0.33     18765\n",
      "weighted avg       0.73      0.60      0.65     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mnb_train_predictions = mnbcgs.best_estimator_.predict(x_trainvec)\n",
    "mnb_test_predictions = mnbcgs.best_estimator_.predict(x_testvec)\n",
    "\n",
    "print(\"MNBC Model Train Accuracy Score :\",accuracy_score(mnb_train_predictions, y_train.to_numpy().ravel()))\n",
    "print(\"MNBC Model Test Accuracy Score :\",accuracy_score(mnb_test_predictions, y_test.to_numpy().ravel()))\n",
    "\n",
    "print(\"MNBC Model Train F1 Score :\",f1_score(mnb_train_predictions, y_train.to_numpy().ravel(), average = 'macro'))\n",
    "print(\"MNBC Model Test F1 Score :\",f1_score(mnb_test_predictions, y_test.to_numpy().ravel(), average = 'macro'))\n",
    "\n",
    "print(\"MNBC Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= mnb_test_predictions)))\n",
    "print(\"MNBC Classification report:\\n\",classification_report(y_pred=mnb_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          mlp_1         mlp_2     mlp_3     mlp_4     mlp_5     rfc_1  \\\n",
      "0  9.440866e-07  2.052553e-02  0.001390  0.872574  0.105510  0.177120   \n",
      "1  8.284534e-12  1.081658e-17  0.000001  0.000219  0.999780  0.178567   \n",
      "2  2.259267e-08  4.059383e-09  0.000087  0.081596  0.918317  0.181827   \n",
      "3  1.164707e-07  5.190757e-10  0.000001  0.402942  0.597057  0.160321   \n",
      "4  1.406019e-08  1.165649e-08  0.025341  0.248463  0.726196  0.150885   \n",
      "\n",
      "      rfc_2     rfc_3     rfc_4     rfc_5    mnbc_1    mnbc_2    mnbc_3  \\\n",
      "0  0.161457  0.212371  0.234206  0.214846  0.112005  0.188914  0.256562   \n",
      "1  0.115013  0.161904  0.204422  0.340094  0.085507  0.049869  0.127573   \n",
      "2  0.147805  0.191284  0.223905  0.255180  0.100017  0.025532  0.202211   \n",
      "3  0.157804  0.181526  0.223349  0.277000  0.057670  0.146505  0.181559   \n",
      "4  0.132735  0.206625  0.249564  0.260191  0.030134  0.064654  0.164004   \n",
      "\n",
      "     mnbc_4    mnbc_5  \n",
      "0  0.274185  0.168334  \n",
      "1  0.128682  0.608368  \n",
      "2  0.252664  0.419576  \n",
      "3  0.241583  0.372683  \n",
      "4  0.355654  0.385553  \n"
     ]
    }
   ],
   "source": [
    "def get_predict_probas(data):\n",
    "    mlp_probas = best_model.predict(data)\n",
    "    rfc_probas = rfcrs.best_estimator_.predict_proba(data)\n",
    "    mnbc_probas = mnbcgs.best_estimator_.predict_proba(data)\n",
    "    mlp_probas_df = pd.DataFrame(mlp_probas,columns=['mlp_1','mlp_2','mlp_3','mlp_4','mlp_5'])\n",
    "    rfc_probas_df = pd.DataFrame(rfc_probas,columns=['rfc_1','rfc_2','rfc_3','rfc_4','rfc_5'])\n",
    "    mnbc_probas_df = pd.DataFrame(mnbc_probas,columns=['mnbc_1','mnbc_2','mnbc_3','mnbc_4','mnbc_5'])\n",
    "    return pd.concat([mlp_probas_df,rfc_probas_df,mnbc_probas_df],axis=1)\n",
    "\n",
    "x_trainvec_stack = get_predict_probas(x_trainvec)\n",
    "x_testvec_stack = get_predict_probas(x_testvec)\n",
    "\n",
    "print(x_trainvec_stack.head())\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Classifier(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 58042\n",
      "max_resources_: 290210\n",
      "aggressive_elimination: False\n",
      "factor: 5\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 10\n",
      "n_resources: 58042\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.965, test=0.962) total time=   6.3s\n",
      "[CV 2/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.963, test=0.963) total time=   6.3s\n",
      "[CV 3/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.964, test=0.964) total time=   5.7s\n",
      "[CV 4/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.963, test=0.964) total time=   6.5s\n",
      "[CV 5/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.963, test=0.963) total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.965, test=0.962) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.963, test=0.962) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.964, test=0.964) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.963, test=0.964) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.963, test=0.963) total time=   1.1s\n",
      "[CV 1/5] END sclf__C=10, sclf__solver=newton-cg;, score=(train=0.964, test=0.962) total time=   3.8s\n",
      "[CV 2/5] END sclf__C=10, sclf__solver=newton-cg;, score=(train=0.963, test=0.962) total time=   3.8s\n",
      "[CV 3/5] END sclf__C=10, sclf__solver=newton-cg;, score=(train=0.963, test=0.963) total time=   3.5s\n",
      "[CV 4/5] END sclf__C=10, sclf__solver=newton-cg;, score=(train=0.963, test=0.964) total time=   3.8s\n",
      "[CV 5/5] END sclf__C=10, sclf__solver=newton-cg;, score=(train=0.962, test=0.963) total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END sclf__C=10, sclf__solver=lbfgs;, score=(train=0.964, test=0.962) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END sclf__C=10, sclf__solver=lbfgs;, score=(train=0.963, test=0.962) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END sclf__C=10, sclf__solver=lbfgs;, score=(train=0.963, test=0.963) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END sclf__C=10, sclf__solver=lbfgs;, score=(train=0.962, test=0.963) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END sclf__C=10, sclf__solver=lbfgs;, score=(train=0.962, test=0.963) total time=   1.1s\n",
      "[CV 1/5] END sclf__C=1.0, sclf__solver=newton-cg;, score=(train=0.962, test=0.961) total time=   2.0s\n",
      "[CV 2/5] END sclf__C=1.0, sclf__solver=newton-cg;, score=(train=0.961, test=0.960) total time=   1.9s\n",
      "[CV 3/5] END sclf__C=1.0, sclf__solver=newton-cg;, score=(train=0.962, test=0.962) total time=   1.8s\n",
      "[CV 4/5] END sclf__C=1.0, sclf__solver=newton-cg;, score=(train=0.961, test=0.962) total time=   1.8s\n",
      "[CV 5/5] END sclf__C=1.0, sclf__solver=newton-cg;, score=(train=0.961, test=0.961) total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END sclf__C=1.0, sclf__solver=lbfgs;, score=(train=0.962, test=0.961) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END sclf__C=1.0, sclf__solver=lbfgs;, score=(train=0.961, test=0.960) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END sclf__C=1.0, sclf__solver=lbfgs;, score=(train=0.962, test=0.962) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END sclf__C=1.0, sclf__solver=lbfgs;, score=(train=0.961, test=0.962) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END sclf__C=1.0, sclf__solver=lbfgs;, score=(train=0.961, test=0.961) total time=   1.1s\n",
      "[CV 1/5] END sclf__C=0.1, sclf__solver=newton-cg;, score=(train=0.961, test=0.960) total time=   1.2s\n",
      "[CV 2/5] END sclf__C=0.1, sclf__solver=newton-cg;, score=(train=0.959, test=0.959) total time=   1.1s\n",
      "[CV 3/5] END sclf__C=0.1, sclf__solver=newton-cg;, score=(train=0.960, test=0.961) total time=   1.1s\n",
      "[CV 4/5] END sclf__C=0.1, sclf__solver=newton-cg;, score=(train=0.959, test=0.961) total time=   1.2s\n",
      "[CV 5/5] END sclf__C=0.1, sclf__solver=newton-cg;, score=(train=0.959, test=0.960) total time=   1.2s\n",
      "[CV 1/5] END sclf__C=0.1, sclf__solver=lbfgs;, score=(train=0.961, test=0.960) total time=   0.6s\n",
      "[CV 2/5] END sclf__C=0.1, sclf__solver=lbfgs;, score=(train=0.959, test=0.959) total time=   0.6s\n",
      "[CV 3/5] END sclf__C=0.1, sclf__solver=lbfgs;, score=(train=0.960, test=0.961) total time=   0.6s\n",
      "[CV 4/5] END sclf__C=0.1, sclf__solver=lbfgs;, score=(train=0.959, test=0.961) total time=   0.6s\n",
      "[CV 5/5] END sclf__C=0.1, sclf__solver=lbfgs;, score=(train=0.959, test=0.960) total time=   0.6s\n",
      "[CV 1/5] END sclf__C=0.01, sclf__solver=newton-cg;, score=(train=0.960, test=0.959) total time=   0.9s\n",
      "[CV 2/5] END sclf__C=0.01, sclf__solver=newton-cg;, score=(train=0.959, test=0.959) total time=   0.9s\n",
      "[CV 3/5] END sclf__C=0.01, sclf__solver=newton-cg;, score=(train=0.959, test=0.959) total time=   0.9s\n",
      "[CV 4/5] END sclf__C=0.01, sclf__solver=newton-cg;, score=(train=0.958, test=0.959) total time=   1.0s\n",
      "[CV 5/5] END sclf__C=0.01, sclf__solver=newton-cg;, score=(train=0.958, test=0.959) total time=   0.8s\n",
      "[CV 1/5] END sclf__C=0.01, sclf__solver=lbfgs;, score=(train=0.960, test=0.959) total time=   0.3s\n",
      "[CV 2/5] END sclf__C=0.01, sclf__solver=lbfgs;, score=(train=0.959, test=0.959) total time=   0.3s\n",
      "[CV 3/5] END sclf__C=0.01, sclf__solver=lbfgs;, score=(train=0.959, test=0.959) total time=   0.3s\n",
      "[CV 4/5] END sclf__C=0.01, sclf__solver=lbfgs;, score=(train=0.958, test=0.959) total time=   0.3s\n",
      "[CV 5/5] END sclf__C=0.01, sclf__solver=lbfgs;, score=(train=0.958, test=0.959) total time=   0.3s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 290210\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.964, test=0.963) total time=  30.3s\n",
      "[CV 2/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.963, test=0.965) total time=  30.9s\n",
      "[CV 3/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.964, test=0.964) total time=  28.9s\n",
      "[CV 4/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.964, test=0.964) total time=  26.2s\n",
      "[CV 5/5] END sclf__C=100, sclf__solver=newton-cg;, score=(train=0.964, test=0.963) total time=  29.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.964, test=0.963) total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.963, test=0.964) total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.963, test=0.964) total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.963, test=0.964) total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END sclf__C=100, sclf__solver=lbfgs;, score=(train=0.964, test=0.963) total time=   4.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(estimator=Pipeline(steps=[(&#x27;sampling&#x27;,\n",
       "                                               RandomOverSampler(random_state=0)),\n",
       "                                              (&#x27;sclf&#x27;,\n",
       "                                               LogisticRegression(random_state=0))]),\n",
       "                    factor=5,\n",
       "                    param_grid={&#x27;sclf__C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                                &#x27;sclf__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;]},\n",
       "                    scoring=make_scorer(f1_score, average=weighted), verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(estimator=Pipeline(steps=[(&#x27;sampling&#x27;,\n",
       "                                               RandomOverSampler(random_state=0)),\n",
       "                                              (&#x27;sclf&#x27;,\n",
       "                                               LogisticRegression(random_state=0))]),\n",
       "                    factor=5,\n",
       "                    param_grid={&#x27;sclf__C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                                &#x27;sclf__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;]},\n",
       "                    scoring=make_scorer(f1_score, average=weighted), verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;sampling&#x27;, RandomOverSampler(random_state=0)),\n",
       "                (&#x27;sclf&#x27;, LogisticRegression(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=0)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(estimator=Pipeline(steps=[('sampling',\n",
       "                                               RandomOverSampler(random_state=0)),\n",
       "                                              ('sclf',\n",
       "                                               LogisticRegression(random_state=0))]),\n",
       "                    factor=5,\n",
       "                    param_grid={'sclf__C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                                'sclf__solver': ['newton-cg', 'lbfgs']},\n",
       "                    scoring=make_scorer(f1_score, average=weighted), verbose=5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sclf = LogisticRegression(random_state=0)\n",
    "\n",
    "sclf_param_grid = {\n",
    "    'sclf__solver' : ['newton-cg', 'lbfgs'],\n",
    "    'sclf__C': [100, 10, 1.0, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "imba_pipe_stack = Pipeline([\n",
    "    ('sampling', RandomOverSampler(random_state=0)), \n",
    "    ('sclf', sclf)\n",
    "    ])\n",
    "\n",
    "\n",
    "sclfrs = HalvingGridSearchCV(estimator=imba_pipe_stack , param_grid=sclf_param_grid, factor=5, cv=5, scoring=f1, verbose=5)\n",
    "\n",
    "sclfrs.fit(x_trainvec_stack, y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# I probably shldv written a function for this...\n",
    "sclfrs_train_predictions = sclfrs.predict(x_trainvec_stack)\n",
    "sclfrs_test_predictions = sclfrs.predict(x_testvec_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Test Accuracy Score : 0.6490807354116707\n",
      "RFC Test Accuracy Score : 0.7552358113509192\n",
      "MNBC Model Test Accuracy Score : 0.5992539301891819\n",
      "Stacked Model Test Accuracy Score : 0.6858513189448441\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP Test Accuracy Score :\",accuracy_score(y_pred=mlp_test_predictions, y_true= y_test.to_numpy().ravel()))\n",
    "print(\"RFC Test Accuracy Score :\",accuracy_score(y_pred=rfc_test_predictions, y_true= y_test.to_numpy().ravel()))\n",
    "print(\"MNBC Model Test Accuracy Score :\",accuracy_score(mnb_test_predictions, y_test.to_numpy().ravel()))\n",
    "print(\"Stacked Model Test Accuracy Score :\",accuracy_score(sclfrs_test_predictions, y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Test F1 Score : 0.36164370916557304\n",
      "RFC Test F1 Score : 0.4101705085267285\n",
      "MNBC Model Test F1 Score : 0.3278294100896285\n",
      "Stacked Model Test F1 Score : 0.3777871514298516\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP Test F1 Score :\",f1_score(y_pred=mlp_test_predictions, y_true=y_test.to_numpy().ravel(), average = 'macro'))\n",
    "print(\"RFC Test F1 Score :\",f1_score(y_pred=rfc_test_predictions, y_true=y_test.to_numpy().ravel(), average = 'macro'))\n",
    "print(\"MNBC Model Test F1 Score :\",f1_score(mnb_test_predictions, y_test.to_numpy().ravel(), average = 'macro'))\n",
    "print(\"Stacked Model Test F1 Score :\",f1_score(sclfrs_test_predictions, y_test.to_numpy().ravel(),average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Confusion matrix:\n",
      "[[  112    31    54    58   205]\n",
      " [   34    56    53    51    97]\n",
      " [   45    73   262   312   607]\n",
      " [   28    41   216   936  2796]\n",
      " [   74    65   292  1453 10814]]\n",
      "RFC Confusion matrix:\n",
      "[[   99    20    28    19   109]\n",
      " [    7    37     7     1     3]\n",
      " [   13    40   186    96   130]\n",
      " [   19    45   233   870  1297]\n",
      " [  155   124   423  1824 12980]]\n",
      "MNBC Confusion matrix:\n",
      "[[ 134   27   78  117  619]\n",
      " [  38   93   94  172  539]\n",
      " [  46   66  299  434  979]\n",
      " [  40   54  258  986 2649]\n",
      " [  35   26  148 1101 9733]]\n",
      "Stacked Confusion matrix:\n",
      "[[  114    25    42    50   179]\n",
      " [   34    64    62    49    97]\n",
      " [   42    67   252   287   554]\n",
      " [   25    35   184   817  2066]\n",
      " [   78    75   337  1607 11623]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MLP Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= mlp_test_predictions)))\n",
    "print(\"RFC Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= rfc_test_predictions)))\n",
    "print(\"MNBC Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= mnb_test_predictions)))\n",
    "print(\"Stacked Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= sclfrs_test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.38      0.30       293\n",
      "           2       0.19      0.21      0.20       266\n",
      "           3       0.20      0.30      0.24       877\n",
      "           4       0.23      0.33      0.27      2810\n",
      "           5       0.85      0.74      0.79     14519\n",
      "\n",
      "    accuracy                           0.65     18765\n",
      "   macro avg       0.34      0.39      0.36     18765\n",
      "weighted avg       0.71      0.65      0.67     18765\n",
      "\n",
      "RFC Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.34      0.35       293\n",
      "           2       0.67      0.14      0.23       266\n",
      "           3       0.40      0.21      0.28       877\n",
      "           4       0.35      0.31      0.33      2810\n",
      "           5       0.84      0.89      0.86     14519\n",
      "\n",
      "    accuracy                           0.76     18765\n",
      "   macro avg       0.52      0.38      0.41     18765\n",
      "weighted avg       0.73      0.76      0.74     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MLP Classification report:\\n\",classification_report(y_pred=mlp_test_predictions,  y_true= y_test.to_numpy().ravel()))\n",
    "print(\"RFC Classification report:\\n\",classification_report(y_pred=rfc_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNBC Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.14      0.46      0.21       293\n",
      "           2       0.10      0.35      0.15       266\n",
      "           3       0.16      0.34      0.22       877\n",
      "           4       0.25      0.35      0.29      2810\n",
      "           5       0.88      0.67      0.76     14519\n",
      "\n",
      "    accuracy                           0.60     18765\n",
      "   macro avg       0.31      0.43      0.33     18765\n",
      "weighted avg       0.73      0.60      0.65     18765\n",
      "\n",
      "Stacked Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.39      0.32       293\n",
      "           2       0.21      0.24      0.22       266\n",
      "           3       0.21      0.29      0.24       877\n",
      "           4       0.26      0.29      0.28      2810\n",
      "           5       0.85      0.80      0.82     14519\n",
      "\n",
      "    accuracy                           0.69     18765\n",
      "   macro avg       0.36      0.40      0.38     18765\n",
      "weighted avg       0.71      0.69      0.70     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MNBC Classification report:\\n\",classification_report(y_pred=mnb_test_predictions,  y_true= y_test.to_numpy().ravel()))\n",
    "print(\"Stacked Classification report:\\n\",classification_report(y_pred=sclfrs_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11a3d9b85d5ef9eb303a3e0d0718105e342595a43d68d297ee0965f43b786655"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
