{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main reference:\n",
    "\n",
    "https://medium.com/swlh/natural-language-processing-nlp-analysis-with-amazon-review-data-part-i-data-engineering-6573b782e4dc\n",
    "https://melaniesoek0120.medium.com/natural-language-processing-nlp-amazon-review-data-part-ii-eda-data-preprocessing-and-model-3866dcbdbb77 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and DropNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93907\n",
      "   overall                                         reviewText\n",
      "0        5  This is awesome to listen to, A must-have for ...\n",
      "1        5                                               bien\n",
      "2        5  It was great to hear the old stuff again and I...\n",
      "3        4  well best of's are a bit poison normally but t...\n",
      "4        5  What can I say? This is Casting Crowns!!!This ...\n",
      "[2165, 54714]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer as ps\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Lim Jia Hui\\Desktop\\songsdata.csv\")\n",
    "print(len(df.reviewText))\n",
    "print(df.head())\n",
    "nanlist = []\n",
    "for text in range(len(df.reviewText)):\n",
    "    if type(df.reviewText[text])!= str:\n",
    "        nanlist.append(int(text))\n",
    "print(nanlist)\n",
    "df.drop(index=nanlist, axis=0,inplace=True)\n",
    "df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Labels to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for idx in range(df.shape[0]):\n",
    "    if df.loc[idx,'overall'] <= 3:\n",
    "        df.loc[idx,'overall'] = 0\n",
    "    if df.loc[idx,'overall'] > 3:\n",
    "        df.loc[idx,'overall'] = 1\n",
    "print(df['overall'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_list = stopwords.words('english')\n",
    "sw_list += list(string.punctuation)\n",
    "sw_list += [\"''\", '\"\"', '...', '``', '’', '“', '’', '”', '‘', '‘',\"'\", '©','said',\"'s\", \"also\",'one',\"n't\",'com', '-', '–', '—', '_',\"/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer, Stemmer, and Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['awesom', 'listen', 'must-hav', 'slayer', 'fan', '..', 'sadli', 'need', 'tripl', 'disc', 'set', '..', 'mani', 'hit'], ['bien'], ['great', 'hear', 'old', 'stuff', 'like', 'new', 'stuff', 'recommend', 'slayer', 'fan'], ['well', 'best', 'bite', 'poison', 'normal', 'bad', 'pretti', 'good', \"'d\", 'put', '90', 'hell', 'await', 'reign', 'blood', 'south', 'season', 'divin', 'coupl', 'musica', 'track', 'everyth', 'god', 'hate', '-at', 'point', 'best', 'mean', 'everi', 'cd', 'mainli', 'bad', 'dose', 'put', 'great', 'track', 'live', 'show', 'play', 'much', 'like,213', 'skeleton', 'societi', 'sex', 'murder', 'art', 'gemini', 'rare', 'track', 'final', 'six', 'bonu', 'track', 'christ', 'illus', 'mysteri', 'cover', 'song', 'unditstput', 'attitud', 'cd', 'would', 'greatest', 'hit', 'collect', 'know', 'put', 'coupl', 'live', 'track', 'too.al', 'could', 'much', 'wors', 'great', 'car'], ['say', 'cast', 'crown', 'good', 'bless', 'fill', 'cd']]\n"
     ]
    }
   ],
   "source": [
    "def Tokenizer(data):\n",
    "    tokens = nltk.word_tokenize(data)\n",
    "    tokenized_data= []\n",
    "    for i in tokens:\n",
    "        if i.lower() not in sw_list:\n",
    "            tokenized_data.append(i.lower())\n",
    "    return tokenized_data\n",
    "\n",
    "def Stemmer(data2):\n",
    "    stemmed_data =[]\n",
    "    for j in data2:\n",
    "        stemmed_data.append(ps().stem(j))\n",
    "    return stemmed_data\n",
    "\n",
    "def Lemmatizer(data3):\n",
    "    lemmatized_data = []\n",
    "    for k in data3:\n",
    "        lemmatized_data.append(WordNetLemmatizer().lemmatize(k, pos='v'))\n",
    "    return lemmatized_data\n",
    "\n",
    "\n",
    "\n",
    "lemmatized_reviews = list(map(Lemmatizer,(map(Stemmer, (map(Tokenizer, df['reviewText']))))))\n",
    "\n",
    "print(lemmatized_reviews[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Lemmatized Nan Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[293, 1792, 1942, 2652, 3560, 3857, 5025, 5122, 5568, 6552, 7846, 8136, 9464, 10069, 11448, 11803, 12422, 12825, 13354, 14932, 18283, 28588, 30450, 32356, 32601, 33455, 35223, 35698, 35703, 37831, 37910, 39228, 40752, 42037, 43383, 44559, 45716, 48627, 50097, 52295, 52380, 52690, 56502, 59520, 60623, 61150, 61165, 62528, 65639, 66416, 69224, 70043, 70892, 71015, 71677, 72711, 73298, 73509, 73897, 75327, 75406, 76099, 77468, 77836, 77867, 80751, 81848, 82071, 82843, 85562, 86105, 86398, 88067, 88161, 88665, 89174, 89212, 90531, 91580, 92817]\n",
      "80\n",
      "93905\n",
      "93825\n"
     ]
    }
   ],
   "source": [
    "nanlist2 = []\n",
    "for word in range(len(lemmatized_reviews)):\n",
    "    if len(lemmatized_reviews[word]) == 0:\n",
    "        nanlist2.append(word)\n",
    "print(nanlist2)\n",
    "print(len(nanlist2))\n",
    "print(len(lemmatized_reviews))\n",
    "for nan in nanlist2:\n",
    "    lemmatized_reviews.remove([])\n",
    "print(len(lemmatized_reviews))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal from original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=nanlist2, axis=0,inplace=True)\n",
    "df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test and Train-Val-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75060, 1)\n",
      "(18765, 1)\n",
      "(75060, 1)\n",
      "(18765, 1)\n",
      "(60048, 1)\n",
      "(15012, 1)\n",
      "(60048, 1)\n",
      "(15012, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(pd.DataFrame({'processed_reviews':lemmatized_reviews}), df['overall'].to_frame(name='overall'), test_size=0.2, random_state=0)\n",
    "\n",
    "x_train_train, x_val, y_train_train, y_val = train_test_split(x_train,y_train,test_size=0.2,stratify=y_train, random_state=0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(x_train_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train_train.shape)\n",
    "print(y_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional \"manual\" resampler with sklearn.utils.resample\n",
    "\n",
    "# from sklearn.utils import resample\n",
    "\n",
    "# xy_train = pd.concat([x_train,y_train], axis=1)\n",
    "# xy_train_train = pd.concat([x_train_train,y_train_train], axis=1)\n",
    "\n",
    "# def resampling(minority):\n",
    "#    resampled_minority = resample(minority, replace=True, n_samples= len(xy_train[xy_train.overall==5]), random_state=0)\n",
    "#    return resampled_minority\n",
    "\n",
    "# resampled_xy_train = xy_train[xy_train.overall==5]\n",
    "# resampled_xy_train_train = xy_train_train[xy_train_train.overall==5]\n",
    "\n",
    "# for i in range (1,5):\n",
    "#    resampled_xy_train = pd.concat([resampled_xy_train,resampling(xy_train[xy_train.overall==i])])\n",
    "\n",
    "# for i in range (1,5):\n",
    "#    resampled_xy_train_train = pd.concat([resampled_xy_train_train,resampling(xy_train_train[xy_train_train.overall==i])])\n",
    "\n",
    "# resampled_shuffled_xy_train = resampled_xy_train.sample(frac=1)\n",
    "# x_train = resampled_shuffled_xy_train['processed_reviews'].to_frame()\n",
    "# y_train = resampled_shuffled_xy_train['overall'].to_frame()\n",
    "\n",
    "# resampled_shuffled_xy_train_train = resampled_xy_train_train.sample(frac=1)\n",
    "# x_train_train = resampled_shuffled_xy_train_train['processed_reviews'].to_frame()\n",
    "# y_train_train = resampled_shuffled_xy_train_train['overall'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "x_train, y_train = RandomOverSampler(random_state=0).fit_resample(x_train,y_train)\n",
    "\n",
    "x_train_train, y_train_train = RandomOverSampler(random_state=0).fit_resample(x_train_train,y_train_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def dummy_token_and_pre(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy_token_and_pre, preprocessor=dummy_token_and_pre, token_pattern=None)\n",
    "\n",
    "tfidf_val = TfidfVectorizer(analyzer='word', tokenizer=dummy_token_and_pre, preprocessor=dummy_token_and_pre, token_pattern=None)\n",
    "\n",
    "x_trainvec = tfidf.fit_transform(x_train.processed_reviews).sorted_indices()\n",
    "x_testvec = tfidf.transform(x_test.processed_reviews).sorted_indices()\n",
    "\n",
    "x_train_trainvec = tfidf_val.fit_transform(x_train_train.processed_reviews).sorted_indices()\n",
    "x_valvec = tfidf_val.transform(x_val.processed_reviews).sorted_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pseudocode for mlp hyperparam tuning\n",
    "\n",
    "#obj()\n",
    "    #param = suggest()\n",
    "\n",
    "    #model = model()\n",
    "\n",
    "    #for epochs in range()\n",
    "    #            agg_f1 = []\n",
    "\n",
    "    #    for train_index, val_index in StratifiedKFold(n_splits=5).split(x_trainvec,y_train): \n",
    "\n",
    "    #        x_trainvec_resd, y_train_resd = RandomOverSampler(random_state=0).fit_resample(x_trainvec.iloc[train_index], y_train.iloc[train_index])    \n",
    "\n",
    "    #        model.fit(x=x_trainvec_resd, y=y_train_resd, epochs =(5^(rung)), verbose=0, batch_size= 100, random_state=0, callbacks=es)\n",
    "\n",
    "    #        agg_f1.append(f1_score(y_pred=model.predict(pd.DataFrame.sparse.from_spmatrix(x_trainvec).iloc[val_index]), y_true=y_train.iloc[val_index].to_numpy().ravel(), average = 'macro'))\n",
    "\n",
    "    #    intermediate_value = statistics.mean(agg_f1)\n",
    "\n",
    "\n",
    "\n",
    "#rant: The challenge in implementing cross-validation for a tf model is the use of a tf model with (a lack of)sklearn functionalities\n",
    "#      In this case, tf models have some hyperparams that need do be defined in .fit(), which clashes with sklearn functionalities \n",
    "#      as some sklearn functions have .fit() implicit in them. The important one here is cross_val_score(). Without this, one has to\n",
    "#      resort to manually implementing the (stratified)cross_val function. This is a further issue when the data is imbalanced.\n",
    "#      From googling it seems that the way to treat imbalanced data in cross-validation is to oversample the training folds\n",
    "#      for each cross-validation split. This can normally be combined into a sklearn/imblearn pipeline and then passed to the\n",
    "#      cross-validation function as seen in the random forest model. However, as mentioned this is a tf model with sklearn functionalities,\n",
    "#      hence one has to implement this part manually as well. This is a bigger conundrum that one might initially expect.\n",
    "#      As the method used is usually to slice out the training part of each cross-validation fold and then apply an oversampling function.\n",
    "#      However, slicing a sparse matrix with a 1d np array as input is something that googling doesnt show how to do.\n",
    "#      Now, you might think of transforming the sparse matrix into a pd df so that you could slice it with say iloc, but  \n",
    "#      because of an unknown reason while the oversampling function as mentioned previously is supposed to be able to take \n",
    "#      both pandas df and sparse matrix as inputs, the pandas df version of a sparse matrix is not a valid input. This is vile shenanigans \n",
    "#      and I am utterly repulsed by it. Yet, given all this there is still the option of moving the tf-idf vectorization into the \n",
    "#      cross-validation part so that the sparse matrix is only made post oversampling, or making your own cross-validation\n",
    "#      function with libraries using an updated version of pandas/scipy(both of which I will NOT do).\n",
    "#  \n",
    "\n",
    "#      Now one might be wondering why one should use a tf model anyways given its imperfect compatabiities(at least in cross-validation).  \n",
    "#      The answer is GPU. Sklearn does not offer GPU support for training its models. The increase in training speed given GPU support is  \n",
    "#      highly considerable, especially if you can parellelize your processes. However, given that cross-validation is such a pain to implement, \n",
    "#      one might ask whether its still worth using even  if you have to redo the tf-idf vectorization every split for every epoch \n",
    "#      for every set of hyperparameters. The answer is something I do not know and will not attempt to know. Hence, the question is then\n",
    "#      rephrased into whether the extra speed from using the GPU is worth the decrease in samples used for the training set as some samples need\n",
    "#      to be separated into a validation set. Admittedly, I personally  answered this question rather arbitrarily and perhaps personally biased to the\n",
    "#      supposed superiority of Optuna in flexibility and (maybe)speed over sklearn hyperparameter tuning.\n",
    "#      Hence, I can't exactly justify my choice here, and what I do here is best treated just as a proof of concept from a tired individual.\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:02:59,888]\u001b[0m A new study created in memory with name: no-name-fc10492e-9d28-4441-be9a-7601f179de4f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 14), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.4286 - accuracy: 0.8042 - tf_f1: 0.7412 - val_loss: 0.3354 - val_accuracy: 0.8586 - val_tf_f1: 0.8147\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2968 - accuracy: 0.8790 - tf_f1: 0.8377 - val_loss: 0.3104 - val_accuracy: 0.8702 - val_tf_f1: 0.8527\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2321 - accuracy: 0.9101 - tf_f1: 0.8643 - val_loss: 0.4210 - val_accuracy: 0.8354 - val_tf_f1: 0.8727\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.1849 - accuracy: 0.9310 - tf_f1: 0.8799 - val_loss: 0.4766 - val_accuracy: 0.8176 - val_tf_f1: 0.8859\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.1513 - accuracy: 0.9450 - tf_f1: 0.8911 - val_loss: 0.3739 - val_accuracy: 0.8776 - val_tf_f1: 0.8965\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.1213 - accuracy: 0.9574 - tf_f1: 0.9015 - val_loss: 0.3936 - val_accuracy: 0.8824 - val_tf_f1: 0.9060\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.1014 - accuracy: 0.9648 - tf_f1: 0.9100 - val_loss: 0.4107 - val_accuracy: 0.8826 - val_tf_f1: 0.9137\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.0886 - accuracy: 0.9685 - tf_f1: 0.9169 - val_loss: 0.4031 - val_accuracy: 0.8910 - val_tf_f1: 0.9199\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.0793 - accuracy: 0.9723 - tf_f1: 0.9226 - val_loss: 0.4002 - val_accuracy: 0.9120 - val_tf_f1: 0.9252\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.0732 - accuracy: 0.9737 - tf_f1: 0.9276 - val_loss: 0.4172 - val_accuracy: 0.9085 - val_tf_f1: 0.9297\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.0650 - accuracy: 0.9765 - tf_f1: 0.9317 - val_loss: 0.4321 - val_accuracy: 0.9030 - val_tf_f1: 0.9335\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.0606 - accuracy: 0.9781 - tf_f1: 0.9352 - val_loss: 0.4458 - val_accuracy: 0.9103 - val_tf_f1: 0.9368\n",
      "Epoch 13/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.0555 - accuracy: 0.9798 - tf_f1: 0.9383 - val_loss: 0.5278 - val_accuracy: 0.8832 - val_tf_f1: 0.9396\n",
      "Epoch 14/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.0536 - accuracy: 0.9798 - tf_f1: 0.9407 - val_loss: 0.5167 - val_accuracy: 0.8850 - val_tf_f1: 0.9419\n",
      "Epoch 15/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.0513 - accuracy: 0.9816 - tf_f1: 0.9429 - val_loss: 0.5622 - val_accuracy: 0.8776 - val_tf_f1: 0.9439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:05:46,857]\u001b[0m Trial 0 finished with value: 0.9439120292663574 and parameters: {'lr': 0.06300422227860877, 'units': 14}. Best is trial 0 with value: 0.9439120292663574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 43), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.6309 - accuracy: 0.7186 - tf_f1: 0.6726 - val_loss: 0.5524 - val_accuracy: 0.7127 - val_tf_f1: 0.7216\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.4974 - accuracy: 0.7865 - tf_f1: 0.7412 - val_loss: 0.5070 - val_accuracy: 0.7324 - val_tf_f1: 0.7558\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.4405 - accuracy: 0.8130 - tf_f1: 0.7670 - val_loss: 0.4256 - val_accuracy: 0.8038 - val_tf_f1: 0.7777\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.4060 - accuracy: 0.8321 - tf_f1: 0.7865 - val_loss: 0.4367 - val_accuracy: 0.8004 - val_tf_f1: 0.7940\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.3800 - accuracy: 0.8459 - tf_f1: 0.8001 - val_loss: 0.3991 - val_accuracy: 0.8245 - val_tf_f1: 0.8062\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.3584 - accuracy: 0.8574 - tf_f1: 0.8114 - val_loss: 0.3699 - val_accuracy: 0.8429 - val_tf_f1: 0.8164\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.3394 - accuracy: 0.8656 - tf_f1: 0.8207 - val_loss: 0.3758 - val_accuracy: 0.8385 - val_tf_f1: 0.8247\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.3224 - accuracy: 0.8736 - tf_f1: 0.8282 - val_loss: 0.4361 - val_accuracy: 0.8038 - val_tf_f1: 0.8313\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.3076 - accuracy: 0.8801 - tf_f1: 0.8341 - val_loss: 0.3828 - val_accuracy: 0.8323 - val_tf_f1: 0.8370\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2943 - accuracy: 0.8860 - tf_f1: 0.8398 - val_loss: 0.4150 - val_accuracy: 0.8160 - val_tf_f1: 0.8421\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2822 - accuracy: 0.8912 - tf_f1: 0.8444 - val_loss: 0.2938 - val_accuracy: 0.8812 - val_tf_f1: 0.8470\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2717 - accuracy: 0.8959 - tf_f1: 0.8494 - val_loss: 0.3842 - val_accuracy: 0.8331 - val_tf_f1: 0.8514\n",
      "Epoch 13/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2617 - accuracy: 0.9002 - tf_f1: 0.8534 - val_loss: 0.3477 - val_accuracy: 0.8509 - val_tf_f1: 0.8553\n",
      "Epoch 14/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2526 - accuracy: 0.9042 - tf_f1: 0.8572 - val_loss: 0.3749 - val_accuracy: 0.8369 - val_tf_f1: 0.8589\n",
      "Epoch 15/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2442 - accuracy: 0.9081 - tf_f1: 0.8605 - val_loss: 0.2927 - val_accuracy: 0.8806 - val_tf_f1: 0.8623\n",
      "Epoch 16/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2366 - accuracy: 0.9110 - tf_f1: 0.8640 - val_loss: 0.3662 - val_accuracy: 0.8435 - val_tf_f1: 0.8654\n",
      "Epoch 17/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2299 - accuracy: 0.9134 - tf_f1: 0.8668 - val_loss: 0.3170 - val_accuracy: 0.8700 - val_tf_f1: 0.8683\n",
      "Epoch 18/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2234 - accuracy: 0.9165 - tf_f1: 0.8697 - val_loss: 0.2879 - val_accuracy: 0.8853 - val_tf_f1: 0.8711\n",
      "Epoch 19/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2170 - accuracy: 0.9189 - tf_f1: 0.8725 - val_loss: 0.3118 - val_accuracy: 0.8730 - val_tf_f1: 0.8738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:09:21,382]\u001b[0m Trial 1 finished with value: 0.8737736940383911 and parameters: {'lr': 0.004417718564699547, 'units': 43}. Best is trial 0 with value: 0.9439120292663574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.4380 - accuracy: 0.8006 - tf_f1: 0.7372 - val_loss: 0.3869 - val_accuracy: 0.8281 - val_tf_f1: 0.8087\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3135 - accuracy: 0.8707 - tf_f1: 0.8308 - val_loss: 0.3599 - val_accuracy: 0.8519 - val_tf_f1: 0.8448\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 11s 5ms/step - loss: 0.2341 - accuracy: 0.9096 - tf_f1: 0.8574 - val_loss: 0.3545 - val_accuracy: 0.8652 - val_tf_f1: 0.8676\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1771 - accuracy: 0.9362 - tf_f1: 0.8768 - val_loss: 0.2982 - val_accuracy: 0.8993 - val_tf_f1: 0.8849\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 6ms/step - loss: 0.1284 - accuracy: 0.9576 - tf_f1: 0.8925 - val_loss: 0.3611 - val_accuracy: 0.8804 - val_tf_f1: 0.8989\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1008 - accuracy: 0.9675 - tf_f1: 0.9044 - val_loss: 0.3345 - val_accuracy: 0.9131 - val_tf_f1: 0.9097\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0794 - accuracy: 0.9750 - tf_f1: 0.9144 - val_loss: 0.3844 - val_accuracy: 0.8888 - val_tf_f1: 0.9183\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0652 - accuracy: 0.9791 - tf_f1: 0.9218 - val_loss: 0.3656 - val_accuracy: 0.9085 - val_tf_f1: 0.9252\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0567 - accuracy: 0.9818 - tf_f1: 0.9281 - val_loss: 0.3880 - val_accuracy: 0.9261 - val_tf_f1: 0.9310\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0511 - accuracy: 0.9839 - tf_f1: 0.9335 - val_loss: 0.4008 - val_accuracy: 0.9140 - val_tf_f1: 0.9358\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0450 - accuracy: 0.9857 - tf_f1: 0.9379 - val_loss: 0.4049 - val_accuracy: 0.9093 - val_tf_f1: 0.9398\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0438 - accuracy: 0.9862 - tf_f1: 0.9415 - val_loss: 0.4280 - val_accuracy: 0.9126 - val_tf_f1: 0.9432\n",
      "Epoch 13/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0414 - accuracy: 0.9869 - tf_f1: 0.9446 - val_loss: 0.4528 - val_accuracy: 0.9100 - val_tf_f1: 0.9460\n",
      "Epoch 14/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0380 - accuracy: 0.9880 - tf_f1: 0.9473 - val_loss: 0.4474 - val_accuracy: 0.9142 - val_tf_f1: 0.9485\n",
      "Epoch 15/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0373 - accuracy: 0.9881 - tf_f1: 0.9497 - val_loss: 0.4710 - val_accuracy: 0.9044 - val_tf_f1: 0.9507\n",
      "Epoch 16/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0354 - accuracy: 0.9887 - tf_f1: 0.9517 - val_loss: 0.4608 - val_accuracy: 0.9182 - val_tf_f1: 0.9526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:12:29,441]\u001b[0m Trial 2 finished with value: 0.952640175819397 and parameters: {'lr': 0.06337234363388337, 'units': 50}. Best is trial 2 with value: 0.952640175819397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape:0\", shape=(None, 20), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.5195 - accuracy: 0.7611 - tf_f1: 0.6716 - val_loss: 0.4390 - val_accuracy: 0.7962 - val_tf_f1: 0.7657\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3851 - accuracy: 0.8384 - tf_f1: 0.7917 - val_loss: 0.3955 - val_accuracy: 0.8286 - val_tf_f1: 0.8092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:12:53,836]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape:0\", shape=(None, 13), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.6754 - accuracy: 0.6862 - tf_f1: 0.4625 - val_loss: 0.6488 - val_accuracy: 0.6645 - val_tf_f1: 0.6455\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.5929 - accuracy: 0.7589 - tf_f1: 0.6777 - val_loss: 0.5651 - val_accuracy: 0.6901 - val_tf_f1: 0.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:13:18,351]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Reshape:0\", shape=(None, 11), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.4210 - accuracy: 0.8080 - tf_f1: 0.7635 - val_loss: 0.4636 - val_accuracy: 0.7832 - val_tf_f1: 0.8147\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2993 - accuracy: 0.8767 - tf_f1: 0.8325 - val_loss: 0.2403 - val_accuracy: 0.9155 - val_tf_f1: 0.8506\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2387 - accuracy: 0.9054 - tf_f1: 0.8632 - val_loss: 0.5453 - val_accuracy: 0.7945 - val_tf_f1: 0.8702\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1973 - accuracy: 0.9259 - tf_f1: 0.8763 - val_loss: 0.3394 - val_accuracy: 0.8827 - val_tf_f1: 0.8833\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1640 - accuracy: 0.9400 - tf_f1: 0.8893 - val_loss: 0.3711 - val_accuracy: 0.8722 - val_tf_f1: 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:14:18,028]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.5049 - accuracy: 0.7687 - tf_f1: 0.6988 - val_loss: 0.3893 - val_accuracy: 0.8329 - val_tf_f1: 0.7784\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3749 - accuracy: 0.8448 - tf_f1: 0.8033 - val_loss: 0.2704 - val_accuracy: 0.8956 - val_tf_f1: 0.8212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:14:42,471]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.5053 - accuracy: 0.7705 - tf_f1: 0.7012 - val_loss: 0.3164 - val_accuracy: 0.8758 - val_tf_f1: 0.7820\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3767 - accuracy: 0.8426 - tf_f1: 0.8077 - val_loss: 0.2598 - val_accuracy: 0.8995 - val_tf_f1: 0.8239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:15:06,996]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 14s 6ms/step - loss: 0.4259 - accuracy: 0.8041 - tf_f1: 0.7363 - val_loss: 0.4869 - val_accuracy: 0.7789 - val_tf_f1: 0.8090\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2955 - accuracy: 0.8776 - tf_f1: 0.8297 - val_loss: 0.2670 - val_accuracy: 0.8992 - val_tf_f1: 0.8478\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2138 - accuracy: 0.9191 - tf_f1: 0.8622 - val_loss: 0.2748 - val_accuracy: 0.9059 - val_tf_f1: 0.8742\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1535 - accuracy: 0.9467 - tf_f1: 0.8844 - val_loss: 0.2974 - val_accuracy: 0.9300 - val_tf_f1: 0.8932\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1121 - accuracy: 0.9628 - tf_f1: 0.9009 - val_loss: 0.3358 - val_accuracy: 0.9087 - val_tf_f1: 0.9072\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0858 - accuracy: 0.9726 - tf_f1: 0.9127 - val_loss: 0.3820 - val_accuracy: 0.9003 - val_tf_f1: 0.9174\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0725 - accuracy: 0.9768 - tf_f1: 0.9216 - val_loss: 0.6110 - val_accuracy: 0.8373 - val_tf_f1: 0.9246\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0600 - accuracy: 0.9806 - tf_f1: 0.9274 - val_loss: 0.4038 - val_accuracy: 0.9139 - val_tf_f1: 0.9304\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0524 - accuracy: 0.9838 - tf_f1: 0.9332 - val_loss: 0.4214 - val_accuracy: 0.9071 - val_tf_f1: 0.9357\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0478 - accuracy: 0.9852 - tf_f1: 0.9380 - val_loss: 0.4238 - val_accuracy: 0.9017 - val_tf_f1: 0.9400\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0444 - accuracy: 0.9860 - tf_f1: 0.9418 - val_loss: 0.4497 - val_accuracy: 0.8981 - val_tf_f1: 0.9435\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0415 - accuracy: 0.9867 - tf_f1: 0.9450 - val_loss: 0.4457 - val_accuracy: 0.9206 - val_tf_f1: 0.9465\n",
      "Epoch 13/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0385 - accuracy: 0.9878 - tf_f1: 0.9479 - val_loss: 0.4734 - val_accuracy: 0.9017 - val_tf_f1: 0.9492\n",
      "Epoch 14/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0363 - accuracy: 0.9884 - tf_f1: 0.9503 - val_loss: 0.4778 - val_accuracy: 0.9161 - val_tf_f1: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:17:53,641]\u001b[0m Trial 8 finished with value: 0.9514711499214172 and parameters: {'lr': 0.08499532870913261, 'units': 47}. Best is trial 2 with value: 0.952640175819397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Reshape:0\", shape=(None, 15), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4308 - accuracy: 0.8027 - tf_f1: 0.7310 - val_loss: 0.4913 - val_accuracy: 0.7646 - val_tf_f1: 0.8056\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3030 - accuracy: 0.8749 - tf_f1: 0.8258 - val_loss: 0.4010 - val_accuracy: 0.8327 - val_tf_f1: 0.8419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:18:18,223]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4418 - accuracy: 0.7970 - tf_f1: 0.7212 - val_loss: 0.4069 - val_accuracy: 0.8237 - val_tf_f1: 0.8044\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3073 - accuracy: 0.8745 - tf_f1: 0.8280 - val_loss: 0.5663 - val_accuracy: 0.7546 - val_tf_f1: 0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:18:42,803]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.4321 - accuracy: 0.8007 - tf_f1: 0.7329 - val_loss: 0.2724 - val_accuracy: 0.8894 - val_tf_f1: 0.8133\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3000 - accuracy: 0.8762 - tf_f1: 0.8377 - val_loss: 0.3075 - val_accuracy: 0.8768 - val_tf_f1: 0.8523\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2272 - accuracy: 0.9131 - tf_f1: 0.8645 - val_loss: 0.3811 - val_accuracy: 0.8501 - val_tf_f1: 0.8735\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1683 - accuracy: 0.9405 - tf_f1: 0.8819 - val_loss: 0.3075 - val_accuracy: 0.8978 - val_tf_f1: 0.8899\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1204 - accuracy: 0.9601 - tf_f1: 0.8972 - val_loss: 0.3847 - val_accuracy: 0.8705 - val_tf_f1: 0.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:19:42,860]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4178 - accuracy: 0.8097 - tf_f1: 0.7470 - val_loss: 0.2667 - val_accuracy: 0.8992 - val_tf_f1: 0.8233\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2848 - accuracy: 0.8847 - tf_f1: 0.8468 - val_loss: 0.3145 - val_accuracy: 0.8803 - val_tf_f1: 0.8611\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2047 - accuracy: 0.9228 - tf_f1: 0.8732 - val_loss: 0.3829 - val_accuracy: 0.8569 - val_tf_f1: 0.8823\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1509 - accuracy: 0.9465 - tf_f1: 0.8902 - val_loss: 0.3940 - val_accuracy: 0.8748 - val_tf_f1: 0.8974\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1036 - accuracy: 0.9657 - tf_f1: 0.9041 - val_loss: 0.3872 - val_accuracy: 0.8891 - val_tf_f1: 0.9100\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0797 - accuracy: 0.9738 - tf_f1: 0.9152 - val_loss: 0.3619 - val_accuracy: 0.9083 - val_tf_f1: 0.9198\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0677 - accuracy: 0.9780 - tf_f1: 0.9239 - val_loss: 0.4004 - val_accuracy: 0.9175 - val_tf_f1: 0.9276\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0564 - accuracy: 0.9821 - tf_f1: 0.9309 - val_loss: 0.4716 - val_accuracy: 0.8778 - val_tf_f1: 0.9335\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0520 - accuracy: 0.9836 - tf_f1: 0.9359 - val_loss: 0.4463 - val_accuracy: 0.9020 - val_tf_f1: 0.9382\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0486 - accuracy: 0.9843 - tf_f1: 0.9402 - val_loss: 0.4581 - val_accuracy: 0.9163 - val_tf_f1: 0.9422\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0434 - accuracy: 0.9864 - tf_f1: 0.9440 - val_loss: 0.4778 - val_accuracy: 0.9165 - val_tf_f1: 0.9457\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0396 - accuracy: 0.9874 - tf_f1: 0.9472 - val_loss: 0.5017 - val_accuracy: 0.8983 - val_tf_f1: 0.9486\n",
      "Epoch 13/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0375 - accuracy: 0.9884 - tf_f1: 0.9498 - val_loss: 0.4705 - val_accuracy: 0.9154 - val_tf_f1: 0.9511\n",
      "Epoch 14/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0362 - accuracy: 0.9887 - tf_f1: 0.9522 - val_loss: 0.4762 - val_accuracy: 0.9119 - val_tf_f1: 0.9533\n",
      "Epoch 15/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0361 - accuracy: 0.9884 - tf_f1: 0.9542 - val_loss: 0.5075 - val_accuracy: 0.8936 - val_tf_f1: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:22:41,038]\u001b[0m Trial 12 finished with value: 0.9550701975822449 and parameters: {'lr': 0.09787840285677056, 'units': 50}. Best is trial 12 with value: 0.9550701975822449.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape:0\", shape=(None, 41), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4148 - accuracy: 0.8115 - tf_f1: 0.7546 - val_loss: 0.4737 - val_accuracy: 0.7837 - val_tf_f1: 0.8160\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2892 - accuracy: 0.8817 - tf_f1: 0.8354 - val_loss: 0.2978 - val_accuracy: 0.8840 - val_tf_f1: 0.8522\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2090 - accuracy: 0.9208 - tf_f1: 0.8655 - val_loss: 0.2514 - val_accuracy: 0.9168 - val_tf_f1: 0.8774\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1504 - accuracy: 0.9464 - tf_f1: 0.8874 - val_loss: 0.3387 - val_accuracy: 0.8899 - val_tf_f1: 0.8951\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1125 - accuracy: 0.9618 - tf_f1: 0.9018 - val_loss: 0.3329 - val_accuracy: 0.9086 - val_tf_f1: 0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:23:41,483]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_14/dense_28/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_14/dense_28/embedding_lookup_sparse/Reshape:0\", shape=(None, 24), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_14/dense_28/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4427 - accuracy: 0.7965 - tf_f1: 0.7377 - val_loss: 0.3612 - val_accuracy: 0.8434 - val_tf_f1: 0.8070\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3146 - accuracy: 0.8700 - tf_f1: 0.8294 - val_loss: 0.2682 - val_accuracy: 0.8948 - val_tf_f1: 0.8455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:24:06,261]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_15/dense_30/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_15/dense_30/embedding_lookup_sparse/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_15/dense_30/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4298 - accuracy: 0.8033 - tf_f1: 0.7450 - val_loss: 0.5543 - val_accuracy: 0.7418 - val_tf_f1: 0.8059\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2956 - accuracy: 0.8785 - tf_f1: 0.8261 - val_loss: 0.3952 - val_accuracy: 0.8349 - val_tf_f1: 0.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:24:30,802]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4560 - accuracy: 0.7911 - tf_f1: 0.7193 - val_loss: 0.5034 - val_accuracy: 0.7593 - val_tf_f1: 0.7934\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3271 - accuracy: 0.8638 - tf_f1: 0.8144 - val_loss: 0.3170 - val_accuracy: 0.8695 - val_tf_f1: 0.8329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:24:55,351]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Reshape:0\", shape=(None, 26), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4214 - accuracy: 0.8085 - tf_f1: 0.7568 - val_loss: 0.3010 - val_accuracy: 0.8796 - val_tf_f1: 0.8215\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2922 - accuracy: 0.8797 - tf_f1: 0.8434 - val_loss: 0.3897 - val_accuracy: 0.8419 - val_tf_f1: 0.8560\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2191 - accuracy: 0.9159 - tf_f1: 0.8669 - val_loss: 0.2950 - val_accuracy: 0.8999 - val_tf_f1: 0.8771\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1678 - accuracy: 0.9389 - tf_f1: 0.8858 - val_loss: 0.2994 - val_accuracy: 0.9063 - val_tf_f1: 0.8933\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1253 - accuracy: 0.9567 - tf_f1: 0.9001 - val_loss: 0.3254 - val_accuracy: 0.9207 - val_tf_f1: 0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:25:56,525]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4559 - accuracy: 0.7946 - tf_f1: 0.7425 - val_loss: 0.2868 - val_accuracy: 0.8900 - val_tf_f1: 0.8087\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3280 - accuracy: 0.8631 - tf_f1: 0.8310 - val_loss: 0.3149 - val_accuracy: 0.8680 - val_tf_f1: 0.8441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:26:21,177]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_19/dense_38/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_19/dense_38/embedding_lookup_sparse/Reshape:0\", shape=(None, 35), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_19/dense_38/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4158 - accuracy: 0.8104 - tf_f1: 0.7449 - val_loss: 0.3479 - val_accuracy: 0.8572 - val_tf_f1: 0.8206\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2845 - accuracy: 0.8840 - tf_f1: 0.8428 - val_loss: 0.4875 - val_accuracy: 0.8008 - val_tf_f1: 0.8554\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2043 - accuracy: 0.9233 - tf_f1: 0.8666 - val_loss: 0.3577 - val_accuracy: 0.8701 - val_tf_f1: 0.8773\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1490 - accuracy: 0.9477 - tf_f1: 0.8864 - val_loss: 0.4940 - val_accuracy: 0.8341 - val_tf_f1: 0.8936\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1194 - accuracy: 0.9585 - tf_f1: 0.8993 - val_loss: 0.3413 - val_accuracy: 0.9109 - val_tf_f1: 0.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:27:21,566]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_20/dense_40/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_20/dense_40/embedding_lookup_sparse/Reshape:0\", shape=(None, 38), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_20/dense_40/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4374 - accuracy: 0.7992 - tf_f1: 0.7281 - val_loss: 0.4121 - val_accuracy: 0.8177 - val_tf_f1: 0.8069\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3084 - accuracy: 0.8730 - tf_f1: 0.8289 - val_loss: 0.4340 - val_accuracy: 0.8133 - val_tf_f1: 0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:27:46,079]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_21/dense_42/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_21/dense_42/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_21/dense_42/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4162 - accuracy: 0.8094 - tf_f1: 0.7572 - val_loss: 0.2393 - val_accuracy: 0.9101 - val_tf_f1: 0.8247\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2879 - accuracy: 0.8832 - tf_f1: 0.8482 - val_loss: 0.5931 - val_accuracy: 0.7563 - val_tf_f1: 0.8572\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2043 - accuracy: 0.9239 - tf_f1: 0.8669 - val_loss: 0.2811 - val_accuracy: 0.9073 - val_tf_f1: 0.8784\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1461 - accuracy: 0.9497 - tf_f1: 0.8884 - val_loss: 0.3274 - val_accuracy: 0.9289 - val_tf_f1: 0.8969\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1077 - accuracy: 0.9642 - tf_f1: 0.9042 - val_loss: 0.4124 - val_accuracy: 0.8786 - val_tf_f1: 0.9100\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0807 - accuracy: 0.9741 - tf_f1: 0.9149 - val_loss: 0.3617 - val_accuracy: 0.9127 - val_tf_f1: 0.9197\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0659 - accuracy: 0.9788 - tf_f1: 0.9239 - val_loss: 0.3651 - val_accuracy: 0.9011 - val_tf_f1: 0.9275\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0558 - accuracy: 0.9825 - tf_f1: 0.9306 - val_loss: 0.4024 - val_accuracy: 0.9055 - val_tf_f1: 0.9336\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0507 - accuracy: 0.9840 - tf_f1: 0.9361 - val_loss: 0.4000 - val_accuracy: 0.9125 - val_tf_f1: 0.9385\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0487 - accuracy: 0.9843 - tf_f1: 0.9406 - val_loss: 0.4581 - val_accuracy: 0.9188 - val_tf_f1: 0.9425\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0430 - accuracy: 0.9864 - tf_f1: 0.9443 - val_loss: 0.4435 - val_accuracy: 0.9245 - val_tf_f1: 0.9460\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0394 - accuracy: 0.9874 - tf_f1: 0.9476 - val_loss: 0.4622 - val_accuracy: 0.8974 - val_tf_f1: 0.9489\n",
      "Epoch 13/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0385 - accuracy: 0.9878 - tf_f1: 0.9501 - val_loss: 0.4611 - val_accuracy: 0.9171 - val_tf_f1: 0.9514\n",
      "Epoch 14/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0366 - accuracy: 0.9883 - tf_f1: 0.9525 - val_loss: 0.4855 - val_accuracy: 0.9010 - val_tf_f1: 0.9535\n",
      "Epoch 15/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0336 - accuracy: 0.9892 - tf_f1: 0.9544 - val_loss: 0.5308 - val_accuracy: 0.8956 - val_tf_f1: 0.9553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:30:45,472]\u001b[0m Trial 21 finished with value: 0.955277681350708 and parameters: {'lr': 0.08625143054872278, 'units': 47}. Best is trial 21 with value: 0.955277681350708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_22/dense_44/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_22/dense_44/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_22/dense_44/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4281 - accuracy: 0.8055 - tf_f1: 0.7475 - val_loss: 0.2624 - val_accuracy: 0.8938 - val_tf_f1: 0.8184\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3027 - accuracy: 0.8750 - tf_f1: 0.8409 - val_loss: 0.3118 - val_accuracy: 0.8722 - val_tf_f1: 0.8540\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2304 - accuracy: 0.9112 - tf_f1: 0.8651 - val_loss: 0.2655 - val_accuracy: 0.9073 - val_tf_f1: 0.8752\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1751 - accuracy: 0.9362 - tf_f1: 0.8839 - val_loss: 0.3073 - val_accuracy: 0.9015 - val_tf_f1: 0.8913\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1345 - accuracy: 0.9532 - tf_f1: 0.8979 - val_loss: 0.4018 - val_accuracy: 0.8584 - val_tf_f1: 0.9030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:31:45,952]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_23/dense_46/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_23/dense_46/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_23/dense_46/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4142 - accuracy: 0.8106 - tf_f1: 0.7461 - val_loss: 0.5443 - val_accuracy: 0.7609 - val_tf_f1: 0.8142\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2843 - accuracy: 0.8839 - tf_f1: 0.8329 - val_loss: 0.2840 - val_accuracy: 0.8908 - val_tf_f1: 0.8520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:32:10,720]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_24/dense_48/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_24/dense_48/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_24/dense_48/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4186 - accuracy: 0.8101 - tf_f1: 0.7386 - val_loss: 0.3315 - val_accuracy: 0.8675 - val_tf_f1: 0.8197\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2928 - accuracy: 0.8802 - tf_f1: 0.8424 - val_loss: 0.2655 - val_accuracy: 0.8965 - val_tf_f1: 0.8571\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2154 - accuracy: 0.9188 - tf_f1: 0.8698 - val_loss: 0.2890 - val_accuracy: 0.8939 - val_tf_f1: 0.8797\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1518 - accuracy: 0.9473 - tf_f1: 0.8889 - val_loss: 0.2966 - val_accuracy: 0.9185 - val_tf_f1: 0.8970\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1103 - accuracy: 0.9636 - tf_f1: 0.9041 - val_loss: 0.3062 - val_accuracy: 0.9249 - val_tf_f1: 0.9103\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0825 - accuracy: 0.9733 - tf_f1: 0.9157 - val_loss: 0.3923 - val_accuracy: 0.8882 - val_tf_f1: 0.9202\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0676 - accuracy: 0.9788 - tf_f1: 0.9241 - val_loss: 0.3766 - val_accuracy: 0.9087 - val_tf_f1: 0.9277\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0549 - accuracy: 0.9826 - tf_f1: 0.9309 - val_loss: 0.3980 - val_accuracy: 0.9007 - val_tf_f1: 0.9338\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0496 - accuracy: 0.9845 - tf_f1: 0.9363 - val_loss: 0.4041 - val_accuracy: 0.9135 - val_tf_f1: 0.9387\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0465 - accuracy: 0.9854 - tf_f1: 0.9408 - val_loss: 0.4165 - val_accuracy: 0.9103 - val_tf_f1: 0.9428\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0425 - accuracy: 0.9865 - tf_f1: 0.9445 - val_loss: 0.5221 - val_accuracy: 0.8720 - val_tf_f1: 0.9460\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0407 - accuracy: 0.9872 - tf_f1: 0.9472 - val_loss: 0.4459 - val_accuracy: 0.9085 - val_tf_f1: 0.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:34:34,843]\u001b[0m Trial 24 finished with value: 0.948631227016449 and parameters: {'lr': 0.0813893200643732, 'units': 50}. Best is trial 21 with value: 0.955277681350708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_25/dense_50/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_25/dense_50/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_25/dense_50/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4164 - accuracy: 0.8110 - tf_f1: 0.7534 - val_loss: 0.2539 - val_accuracy: 0.9054 - val_tf_f1: 0.8250\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2856 - accuracy: 0.8836 - tf_f1: 0.8483 - val_loss: 0.8834 - val_accuracy: 0.6484 - val_tf_f1: 0.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:34:59,495]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_26/dense_52/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_26/dense_52/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_26/dense_52/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4388 - accuracy: 0.7974 - tf_f1: 0.7376 - val_loss: 0.3677 - val_accuracy: 0.8415 - val_tf_f1: 0.8070\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3024 - accuracy: 0.8768 - tf_f1: 0.8305 - val_loss: 0.2247 - val_accuracy: 0.9182 - val_tf_f1: 0.8491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:35:24,117]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_27/dense_54/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_27/dense_54/embedding_lookup_sparse/Reshape:0\", shape=(None, 30), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_27/dense_54/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4268 - accuracy: 0.8050 - tf_f1: 0.7419 - val_loss: 0.2922 - val_accuracy: 0.8832 - val_tf_f1: 0.8170\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3025 - accuracy: 0.8761 - tf_f1: 0.8401 - val_loss: 0.2408 - val_accuracy: 0.9127 - val_tf_f1: 0.8550\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2277 - accuracy: 0.9130 - tf_f1: 0.8675 - val_loss: 0.3287 - val_accuracy: 0.8841 - val_tf_f1: 0.8769\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1758 - accuracy: 0.9358 - tf_f1: 0.8847 - val_loss: 0.3105 - val_accuracy: 0.8975 - val_tf_f1: 0.8920\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 13s 6ms/step - loss: 0.1327 - accuracy: 0.9536 - tf_f1: 0.8984 - val_loss: 0.3182 - val_accuracy: 0.9055 - val_tf_f1: 0.9042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:36:25,862]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_28/dense_56/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_28/dense_56/embedding_lookup_sparse/Reshape:0\", shape=(None, 41), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_28/dense_56/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4248 - accuracy: 0.8058 - tf_f1: 0.7411 - val_loss: 0.3055 - val_accuracy: 0.8809 - val_tf_f1: 0.8189\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2944 - accuracy: 0.8786 - tf_f1: 0.8412 - val_loss: 0.2341 - val_accuracy: 0.9199 - val_tf_f1: 0.8570\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2170 - accuracy: 0.9179 - tf_f1: 0.8701 - val_loss: 0.2524 - val_accuracy: 0.9119 - val_tf_f1: 0.8803\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1569 - accuracy: 0.9453 - tf_f1: 0.8895 - val_loss: 0.4409 - val_accuracy: 0.8491 - val_tf_f1: 0.8962\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1102 - accuracy: 0.9644 - tf_f1: 0.9024 - val_loss: 0.4107 - val_accuracy: 0.8679 - val_tf_f1: 0.9082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:37:26,214]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_29/dense_58/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_29/dense_58/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_29/dense_58/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4297 - accuracy: 0.8029 - tf_f1: 0.7453 - val_loss: 0.4142 - val_accuracy: 0.8136 - val_tf_f1: 0.8110\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3039 - accuracy: 0.8737 - tf_f1: 0.8315 - val_loss: 0.3260 - val_accuracy: 0.8685 - val_tf_f1: 0.8472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:37:50,946]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_30/dense_60/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_30/dense_60/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_30/dense_60/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 14s 6ms/step - loss: 0.4200 - accuracy: 0.8077 - tf_f1: 0.7487 - val_loss: 0.3053 - val_accuracy: 0.8700 - val_tf_f1: 0.8191\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2978 - accuracy: 0.8767 - tf_f1: 0.8409 - val_loss: 0.6762 - val_accuracy: 0.7057 - val_tf_f1: 0.8488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:38:16,915]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_31/dense_62/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_31/dense_62/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_31/dense_62/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4205 - accuracy: 0.8079 - tf_f1: 0.7459 - val_loss: 0.2362 - val_accuracy: 0.9081 - val_tf_f1: 0.8218\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2940 - accuracy: 0.8795 - tf_f1: 0.8448 - val_loss: 0.2357 - val_accuracy: 0.9169 - val_tf_f1: 0.8596\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2175 - accuracy: 0.9176 - tf_f1: 0.8723 - val_loss: 0.2509 - val_accuracy: 0.9200 - val_tf_f1: 0.8820\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1525 - accuracy: 0.9462 - tf_f1: 0.8911 - val_loss: 0.2785 - val_accuracy: 0.9245 - val_tf_f1: 0.8989\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1154 - accuracy: 0.9608 - tf_f1: 0.9057 - val_loss: 0.3542 - val_accuracy: 0.8917 - val_tf_f1: 0.9111\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0851 - accuracy: 0.9728 - tf_f1: 0.9160 - val_loss: 0.3719 - val_accuracy: 0.9035 - val_tf_f1: 0.9205\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0647 - accuracy: 0.9791 - tf_f1: 0.9245 - val_loss: 0.3892 - val_accuracy: 0.9065 - val_tf_f1: 0.9281\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0574 - accuracy: 0.9815 - tf_f1: 0.9312 - val_loss: 0.4117 - val_accuracy: 0.9112 - val_tf_f1: 0.9341\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0499 - accuracy: 0.9840 - tf_f1: 0.9366 - val_loss: 0.4588 - val_accuracy: 0.8983 - val_tf_f1: 0.9389\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0478 - accuracy: 0.9849 - tf_f1: 0.9409 - val_loss: 0.5404 - val_accuracy: 0.8628 - val_tf_f1: 0.9425\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0443 - accuracy: 0.9856 - tf_f1: 0.9440 - val_loss: 0.4445 - val_accuracy: 0.9130 - val_tf_f1: 0.9456\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0407 - accuracy: 0.9873 - tf_f1: 0.9471 - val_loss: 0.4924 - val_accuracy: 0.8972 - val_tf_f1: 0.9485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:40:40,693]\u001b[0m Trial 31 finished with value: 0.948452889919281 and parameters: {'lr': 0.0847470464260091, 'units': 47}. Best is trial 21 with value: 0.955277681350708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_32/dense_64/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_32/dense_64/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_32/dense_64/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4207 - accuracy: 0.8075 - tf_f1: 0.7449 - val_loss: 0.2327 - val_accuracy: 0.9103 - val_tf_f1: 0.8222\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2968 - accuracy: 0.8795 - tf_f1: 0.8450 - val_loss: 0.2296 - val_accuracy: 0.9207 - val_tf_f1: 0.8602\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2193 - accuracy: 0.9168 - tf_f1: 0.8726 - val_loss: 0.3758 - val_accuracy: 0.8592 - val_tf_f1: 0.8810\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1509 - accuracy: 0.9475 - tf_f1: 0.8894 - val_loss: 0.3398 - val_accuracy: 0.8934 - val_tf_f1: 0.8970\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1087 - accuracy: 0.9638 - tf_f1: 0.9038 - val_loss: 0.3814 - val_accuracy: 0.8890 - val_tf_f1: 0.9096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:41:41,251]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_33/dense_66/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_33/dense_66/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_33/dense_66/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4265 - accuracy: 0.8047 - tf_f1: 0.7489 - val_loss: 0.2894 - val_accuracy: 0.8814 - val_tf_f1: 0.8172\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2981 - accuracy: 0.8770 - tf_f1: 0.8396 - val_loss: 0.4500 - val_accuracy: 0.8048 - val_tf_f1: 0.8515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:42:06,004]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_34/dense_68/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_34/dense_68/embedding_lookup_sparse/Reshape:0\", shape=(None, 42), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_34/dense_68/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4219 - accuracy: 0.8083 - tf_f1: 0.7595 - val_loss: 0.2827 - val_accuracy: 0.8838 - val_tf_f1: 0.8207\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2953 - accuracy: 0.8789 - tf_f1: 0.8427 - val_loss: 0.3417 - val_accuracy: 0.8615 - val_tf_f1: 0.8561\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2178 - accuracy: 0.9175 - tf_f1: 0.8675 - val_loss: 0.3387 - val_accuracy: 0.8738 - val_tf_f1: 0.8774\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1551 - accuracy: 0.9454 - tf_f1: 0.8862 - val_loss: 0.2826 - val_accuracy: 0.9136 - val_tf_f1: 0.8944\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1098 - accuracy: 0.9636 - tf_f1: 0.9018 - val_loss: 0.4783 - val_accuracy: 0.8478 - val_tf_f1: 0.9073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:43:06,417]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_35/dense_70/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_35/dense_70/embedding_lookup_sparse/Reshape:0\", shape=(None, 38), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_35/dense_70/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4212 - accuracy: 0.8063 - tf_f1: 0.7388 - val_loss: 0.4973 - val_accuracy: 0.7517 - val_tf_f1: 0.8088\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2888 - accuracy: 0.8825 - tf_f1: 0.8293 - val_loss: 0.3653 - val_accuracy: 0.8506 - val_tf_f1: 0.8472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:43:31,184]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_36/dense_72/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_36/dense_72/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_36/dense_72/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4227 - accuracy: 0.8079 - tf_f1: 0.7544 - val_loss: 0.2933 - val_accuracy: 0.8814 - val_tf_f1: 0.8208\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2902 - accuracy: 0.8819 - tf_f1: 0.8431 - val_loss: 0.2727 - val_accuracy: 0.8942 - val_tf_f1: 0.8585\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2052 - accuracy: 0.9238 - tf_f1: 0.8716 - val_loss: 0.2537 - val_accuracy: 0.9178 - val_tf_f1: 0.8824\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1458 - accuracy: 0.9495 - tf_f1: 0.8918 - val_loss: 0.2827 - val_accuracy: 0.9141 - val_tf_f1: 0.8998\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1064 - accuracy: 0.9649 - tf_f1: 0.9067 - val_loss: 0.4033 - val_accuracy: 0.8774 - val_tf_f1: 0.9121\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0803 - accuracy: 0.9740 - tf_f1: 0.9170 - val_loss: 0.3441 - val_accuracy: 0.9105 - val_tf_f1: 0.9215\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0631 - accuracy: 0.9802 - tf_f1: 0.9255 - val_loss: 0.3871 - val_accuracy: 0.9027 - val_tf_f1: 0.9291\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0557 - accuracy: 0.9821 - tf_f1: 0.9321 - val_loss: 0.3995 - val_accuracy: 0.9122 - val_tf_f1: 0.9350\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0489 - accuracy: 0.9843 - tf_f1: 0.9376 - val_loss: 0.4511 - val_accuracy: 0.8920 - val_tf_f1: 0.9397\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0447 - accuracy: 0.9858 - tf_f1: 0.9416 - val_loss: 0.4489 - val_accuracy: 0.9112 - val_tf_f1: 0.9436\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0424 - accuracy: 0.9868 - tf_f1: 0.9453 - val_loss: 0.4890 - val_accuracy: 0.9171 - val_tf_f1: 0.9469\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0409 - accuracy: 0.9873 - tf_f1: 0.9484 - val_loss: 0.4529 - val_accuracy: 0.9101 - val_tf_f1: 0.9498\n",
      "Epoch 13/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0377 - accuracy: 0.9880 - tf_f1: 0.9510 - val_loss: 0.4749 - val_accuracy: 0.9075 - val_tf_f1: 0.9522\n",
      "Epoch 14/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0385 - accuracy: 0.9877 - tf_f1: 0.9532 - val_loss: 0.4756 - val_accuracy: 0.9242 - val_tf_f1: 0.9542\n",
      "Epoch 15/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0372 - accuracy: 0.9881 - tf_f1: 0.9552 - val_loss: 0.4743 - val_accuracy: 0.9125 - val_tf_f1: 0.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:46:30,193]\u001b[0m Trial 36 finished with value: 0.9560930132865906 and parameters: {'lr': 0.08679299688055687, 'units': 45}. Best is trial 36 with value: 0.9560930132865906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_37/dense_74/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_37/dense_74/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_37/dense_74/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4182 - accuracy: 0.8091 - tf_f1: 0.7595 - val_loss: 0.2170 - val_accuracy: 0.9212 - val_tf_f1: 0.8245\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2924 - accuracy: 0.8798 - tf_f1: 0.8477 - val_loss: 0.5512 - val_accuracy: 0.7588 - val_tf_f1: 0.8563\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2035 - accuracy: 0.9245 - tf_f1: 0.8663 - val_loss: 0.4106 - val_accuracy: 0.8411 - val_tf_f1: 0.8766\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1504 - accuracy: 0.9472 - tf_f1: 0.8853 - val_loss: 0.2940 - val_accuracy: 0.9119 - val_tf_f1: 0.8937\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1093 - accuracy: 0.9635 - tf_f1: 0.9011 - val_loss: 0.4180 - val_accuracy: 0.8738 - val_tf_f1: 0.9070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:47:30,638]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_38/dense_76/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_38/dense_76/embedding_lookup_sparse/Reshape:0\", shape=(None, 39), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_38/dense_76/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4364 - accuracy: 0.7979 - tf_f1: 0.7353 - val_loss: 0.6089 - val_accuracy: 0.7076 - val_tf_f1: 0.7983\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3047 - accuracy: 0.8741 - tf_f1: 0.8175 - val_loss: 0.3197 - val_accuracy: 0.8689 - val_tf_f1: 0.8378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:47:55,334]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_39/dense_78/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_39/dense_78/embedding_lookup_sparse/Reshape:0\", shape=(None, 33), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_39/dense_78/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4277 - accuracy: 0.8043 - tf_f1: 0.7457 - val_loss: 0.3687 - val_accuracy: 0.8409 - val_tf_f1: 0.8138\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2972 - accuracy: 0.8770 - tf_f1: 0.8359 - val_loss: 0.4017 - val_accuracy: 0.8328 - val_tf_f1: 0.8497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:48:20,014]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_40/dense_80/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_40/dense_80/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_40/dense_80/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4180 - accuracy: 0.8098 - tf_f1: 0.7665 - val_loss: 0.4088 - val_accuracy: 0.8149 - val_tf_f1: 0.8185\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2878 - accuracy: 0.8827 - tf_f1: 0.8392 - val_loss: 0.2502 - val_accuracy: 0.9067 - val_tf_f1: 0.8557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:48:45,569]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_41/dense_82/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_41/dense_82/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_41/dense_82/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4185 - accuracy: 0.8098 - tf_f1: 0.7381 - val_loss: 0.4235 - val_accuracy: 0.8142 - val_tf_f1: 0.8166\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2855 - accuracy: 0.8849 - tf_f1: 0.8384 - val_loss: 0.4800 - val_accuracy: 0.8034 - val_tf_f1: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:49:10,321]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_42/dense_84/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_42/dense_84/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_42/dense_84/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4250 - accuracy: 0.8050 - tf_f1: 0.7474 - val_loss: 0.6480 - val_accuracy: 0.7022 - val_tf_f1: 0.8039\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2918 - accuracy: 0.8806 - tf_f1: 0.8231 - val_loss: 0.3257 - val_accuracy: 0.8704 - val_tf_f1: 0.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:49:34,921]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_43/dense_86/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_43/dense_86/embedding_lookup_sparse/Reshape:0\", shape=(None, 42), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_43/dense_86/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4189 - accuracy: 0.8085 - tf_f1: 0.7566 - val_loss: 0.3372 - val_accuracy: 0.8644 - val_tf_f1: 0.8199\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2921 - accuracy: 0.8809 - tf_f1: 0.8417 - val_loss: 0.3579 - val_accuracy: 0.8563 - val_tf_f1: 0.8557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:49:59,547]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_44/dense_88/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_44/dense_88/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_44/dense_88/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4265 - accuracy: 0.8048 - tf_f1: 0.7471 - val_loss: 0.4623 - val_accuracy: 0.7896 - val_tf_f1: 0.8107\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2956 - accuracy: 0.8785 - tf_f1: 0.8310 - val_loss: 0.2779 - val_accuracy: 0.8943 - val_tf_f1: 0.8490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:50:24,248]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_45/dense_90/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_45/dense_90/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_45/dense_90/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.5351 - accuracy: 0.7619 - tf_f1: 0.7243 - val_loss: 0.4753 - val_accuracy: 0.7647 - val_tf_f1: 0.7679\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.4077 - accuracy: 0.8291 - tf_f1: 0.7886 - val_loss: 0.3764 - val_accuracy: 0.8399 - val_tf_f1: 0.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:50:48,974]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_46/dense_92/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_46/dense_92/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_46/dense_92/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4239 - accuracy: 0.8054 - tf_f1: 0.7415 - val_loss: 0.5274 - val_accuracy: 0.7573 - val_tf_f1: 0.8088\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2909 - accuracy: 0.8831 - tf_f1: 0.8298 - val_loss: 0.3195 - val_accuracy: 0.8755 - val_tf_f1: 0.8486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:51:13,587]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_47/dense_94/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_47/dense_94/embedding_lookup_sparse/Reshape:0\", shape=(None, 20), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_47/dense_94/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4432 - accuracy: 0.7970 - tf_f1: 0.7228 - val_loss: 0.2745 - val_accuracy: 0.8930 - val_tf_f1: 0.8098\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3126 - accuracy: 0.8726 - tf_f1: 0.8348 - val_loss: 0.2464 - val_accuracy: 0.9067 - val_tf_f1: 0.8505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:51:38,264]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_48/dense_96/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_48/dense_96/embedding_lookup_sparse/Reshape:0\", shape=(None, 43), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_48/dense_96/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4245 - accuracy: 0.8055 - tf_f1: 0.7440 - val_loss: 0.6523 - val_accuracy: 0.7077 - val_tf_f1: 0.8053\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2923 - accuracy: 0.8794 - tf_f1: 0.8236 - val_loss: 0.2977 - val_accuracy: 0.8871 - val_tf_f1: 0.8440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:52:02,936]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_49/dense_98/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_49/dense_98/embedding_lookup_sparse/Reshape:0\", shape=(None, 29), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_49/dense_98/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4652 - accuracy: 0.7883 - tf_f1: 0.6995 - val_loss: 0.2965 - val_accuracy: 0.8826 - val_tf_f1: 0.7985\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3386 - accuracy: 0.8596 - tf_f1: 0.8236 - val_loss: 0.3847 - val_accuracy: 0.8384 - val_tf_f1: 0.8371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:52:27,709]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_50/dense_100/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_50/dense_100/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_50/dense_100/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4158 - accuracy: 0.8104 - tf_f1: 0.7491 - val_loss: 0.6071 - val_accuracy: 0.7242 - val_tf_f1: 0.8112\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2850 - accuracy: 0.8844 - tf_f1: 0.8300 - val_loss: 0.3929 - val_accuracy: 0.8437 - val_tf_f1: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:52:52,345]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_51/dense_102/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_51/dense_102/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_51/dense_102/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4246 - accuracy: 0.8051 - tf_f1: 0.7367 - val_loss: 0.3971 - val_accuracy: 0.8253 - val_tf_f1: 0.8130\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2888 - accuracy: 0.8820 - tf_f1: 0.8354 - val_loss: 0.3028 - val_accuracy: 0.8790 - val_tf_f1: 0.8524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:53:17,062]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_52/dense_104/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_52/dense_104/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_52/dense_104/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4182 - accuracy: 0.8104 - tf_f1: 0.7581 - val_loss: 0.4085 - val_accuracy: 0.8161 - val_tf_f1: 0.8176\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2890 - accuracy: 0.8821 - tf_f1: 0.8384 - val_loss: 0.3349 - val_accuracy: 0.8690 - val_tf_f1: 0.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:53:41,596]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_53/dense_106/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_53/dense_106/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_53/dense_106/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4192 - accuracy: 0.8080 - tf_f1: 0.7489 - val_loss: 0.2748 - val_accuracy: 0.8893 - val_tf_f1: 0.8208\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2896 - accuracy: 0.8811 - tf_f1: 0.8436 - val_loss: 0.2912 - val_accuracy: 0.8875 - val_tf_f1: 0.8581\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2060 - accuracy: 0.9224 - tf_f1: 0.8708 - val_loss: 0.2675 - val_accuracy: 0.9102 - val_tf_f1: 0.8816\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1511 - accuracy: 0.9469 - tf_f1: 0.8907 - val_loss: 0.3829 - val_accuracy: 0.8695 - val_tf_f1: 0.8978\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1066 - accuracy: 0.9655 - tf_f1: 0.9043 - val_loss: 0.4258 - val_accuracy: 0.8660 - val_tf_f1: 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:54:41,795]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_54/dense_108/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_54/dense_108/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_54/dense_108/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4142 - accuracy: 0.8125 - tf_f1: 0.7437 - val_loss: 0.5530 - val_accuracy: 0.7518 - val_tf_f1: 0.8139\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2799 - accuracy: 0.8865 - tf_f1: 0.8335 - val_loss: 0.3601 - val_accuracy: 0.8608 - val_tf_f1: 0.8517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:55:06,396]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_55/dense_110/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_55/dense_110/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_55/dense_110/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4267 - accuracy: 0.8036 - tf_f1: 0.7388 - val_loss: 0.3451 - val_accuracy: 0.8559 - val_tf_f1: 0.8145\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2935 - accuracy: 0.8791 - tf_f1: 0.8373 - val_loss: 0.4236 - val_accuracy: 0.8255 - val_tf_f1: 0.8511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:55:31,143]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_56/dense_112/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_56/dense_112/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_56/dense_112/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4233 - accuracy: 0.8058 - tf_f1: 0.7573 - val_loss: 0.4316 - val_accuracy: 0.8062 - val_tf_f1: 0.8134\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2919 - accuracy: 0.8807 - tf_f1: 0.8343 - val_loss: 0.2432 - val_accuracy: 0.9143 - val_tf_f1: 0.8523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:55:55,799]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_57/dense_114/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_57/dense_114/embedding_lookup_sparse/Reshape:0\", shape=(None, 43), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_57/dense_114/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4228 - accuracy: 0.8071 - tf_f1: 0.7527 - val_loss: 0.5855 - val_accuracy: 0.7204 - val_tf_f1: 0.8072\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2907 - accuracy: 0.8814 - tf_f1: 0.8268 - val_loss: 0.2740 - val_accuracy: 0.8968 - val_tf_f1: 0.8465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:56:20,454]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_58/dense_116/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_58/dense_116/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_58/dense_116/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.4277 - accuracy: 0.8042 - tf_f1: 0.7440 - val_loss: 0.3023 - val_accuracy: 0.8724 - val_tf_f1: 0.8163\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2984 - accuracy: 0.8770 - tf_f1: 0.8391 - val_loss: 0.3163 - val_accuracy: 0.8740 - val_tf_f1: 0.8534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:56:44,975]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_59/dense_118/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_59/dense_118/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_59/dense_118/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4184 - accuracy: 0.8064 - tf_f1: 0.7524 - val_loss: 0.3318 - val_accuracy: 0.8618 - val_tf_f1: 0.8185\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2909 - accuracy: 0.8821 - tf_f1: 0.8407 - val_loss: 0.2398 - val_accuracy: 0.9142 - val_tf_f1: 0.8574\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2180 - accuracy: 0.9161 - tf_f1: 0.8702 - val_loss: 0.4971 - val_accuracy: 0.8211 - val_tf_f1: 0.8780\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1545 - accuracy: 0.9448 - tf_f1: 0.8860 - val_loss: 0.3083 - val_accuracy: 0.9073 - val_tf_f1: 0.8939\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1167 - accuracy: 0.9607 - tf_f1: 0.9009 - val_loss: 0.3269 - val_accuracy: 0.9011 - val_tf_f1: 0.9069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:57:45,581]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_60/dense_120/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_60/dense_120/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_60/dense_120/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4241 - accuracy: 0.8052 - tf_f1: 0.7373 - val_loss: 0.5570 - val_accuracy: 0.7409 - val_tf_f1: 0.8065\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2998 - accuracy: 0.8769 - tf_f1: 0.8262 - val_loss: 0.3558 - val_accuracy: 0.8579 - val_tf_f1: 0.8439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:58:10,235]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_61/dense_122/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_61/dense_122/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_61/dense_122/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4188 - accuracy: 0.8078 - tf_f1: 0.7528 - val_loss: 0.3256 - val_accuracy: 0.8625 - val_tf_f1: 0.8193\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2881 - accuracy: 0.8822 - tf_f1: 0.8409 - val_loss: 0.2354 - val_accuracy: 0.9223 - val_tf_f1: 0.8581\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2105 - accuracy: 0.9204 - tf_f1: 0.8715 - val_loss: 0.3783 - val_accuracy: 0.8540 - val_tf_f1: 0.8806\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1537 - accuracy: 0.9464 - tf_f1: 0.8888 - val_loss: 0.3208 - val_accuracy: 0.8924 - val_tf_f1: 0.8963\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1182 - accuracy: 0.9600 - tf_f1: 0.9028 - val_loss: 0.3833 - val_accuracy: 0.8858 - val_tf_f1: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:59:10,448]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_62/dense_124/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_62/dense_124/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_62/dense_124/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4230 - accuracy: 0.8087 - tf_f1: 0.7505 - val_loss: 0.2694 - val_accuracy: 0.8936 - val_tf_f1: 0.8215\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2930 - accuracy: 0.8791 - tf_f1: 0.8444 - val_loss: 0.4493 - val_accuracy: 0.8167 - val_tf_f1: 0.8555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 01:59:35,776]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_63/dense_126/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_63/dense_126/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_63/dense_126/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4182 - accuracy: 0.8092 - tf_f1: 0.7382 - val_loss: 0.2899 - val_accuracy: 0.8844 - val_tf_f1: 0.8215\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2882 - accuracy: 0.8812 - tf_f1: 0.8442 - val_loss: 0.3786 - val_accuracy: 0.8475 - val_tf_f1: 0.8571\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2057 - accuracy: 0.9228 - tf_f1: 0.8690 - val_loss: 0.2781 - val_accuracy: 0.9025 - val_tf_f1: 0.8800\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1488 - accuracy: 0.9477 - tf_f1: 0.8894 - val_loss: 0.6043 - val_accuracy: 0.7948 - val_tf_f1: 0.8955\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1051 - accuracy: 0.9660 - tf_f1: 0.9012 - val_loss: 0.3966 - val_accuracy: 0.8760 - val_tf_f1: 0.9074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:00:36,143]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_64/dense_128/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_64/dense_128/embedding_lookup_sparse/Reshape:0\", shape=(None, 41), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_64/dense_128/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4172 - accuracy: 0.8107 - tf_f1: 0.7625 - val_loss: 0.2237 - val_accuracy: 0.9163 - val_tf_f1: 0.8255\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2919 - accuracy: 0.8810 - tf_f1: 0.8480 - val_loss: 0.3536 - val_accuracy: 0.8572 - val_tf_f1: 0.8602\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2152 - accuracy: 0.9177 - tf_f1: 0.8706 - val_loss: 0.3085 - val_accuracy: 0.8904 - val_tf_f1: 0.8804\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1525 - accuracy: 0.9465 - tf_f1: 0.8894 - val_loss: 0.3250 - val_accuracy: 0.8946 - val_tf_f1: 0.8969\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1136 - accuracy: 0.9618 - tf_f1: 0.9035 - val_loss: 0.3720 - val_accuracy: 0.8863 - val_tf_f1: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:01:36,974]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_65/dense_130/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_65/dense_130/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_65/dense_130/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 6ms/step - loss: 0.4210 - accuracy: 0.8053 - tf_f1: 0.7434 - val_loss: 0.4321 - val_accuracy: 0.8126 - val_tf_f1: 0.8133\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2934 - accuracy: 0.8803 - tf_f1: 0.8344 - val_loss: 0.3222 - val_accuracy: 0.8774 - val_tf_f1: 0.8512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:02:02,405]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_66/dense_132/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_66/dense_132/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_66/dense_132/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4266 - accuracy: 0.8046 - tf_f1: 0.7439 - val_loss: 0.3265 - val_accuracy: 0.8654 - val_tf_f1: 0.8154\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2940 - accuracy: 0.8783 - tf_f1: 0.8384 - val_loss: 0.2339 - val_accuracy: 0.9159 - val_tf_f1: 0.8546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:02:27,345]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_67/dense_134/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_67/dense_134/embedding_lookup_sparse/Reshape:0\", shape=(None, 18), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_67/dense_134/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4260 - accuracy: 0.8058 - tf_f1: 0.7598 - val_loss: 0.4335 - val_accuracy: 0.8080 - val_tf_f1: 0.8136\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2980 - accuracy: 0.8774 - tf_f1: 0.8337 - val_loss: 0.5362 - val_accuracy: 0.7749 - val_tf_f1: 0.8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:02:52,404]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_68/dense_136/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_68/dense_136/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_68/dense_136/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4176 - accuracy: 0.8109 - tf_f1: 0.7634 - val_loss: 0.2071 - val_accuracy: 0.9257 - val_tf_f1: 0.8264\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2912 - accuracy: 0.8803 - tf_f1: 0.8490 - val_loss: 0.2430 - val_accuracy: 0.9099 - val_tf_f1: 0.8626\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2153 - accuracy: 0.9186 - tf_f1: 0.8746 - val_loss: 0.5850 - val_accuracy: 0.7793 - val_tf_f1: 0.8811\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1564 - accuracy: 0.9444 - tf_f1: 0.8876 - val_loss: 0.3165 - val_accuracy: 0.9040 - val_tf_f1: 0.8953\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1088 - accuracy: 0.9643 - tf_f1: 0.9025 - val_loss: 0.3223 - val_accuracy: 0.9091 - val_tf_f1: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:03:53,061]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_69/dense_138/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_69/dense_138/embedding_lookup_sparse/Reshape:0\", shape=(None, 13), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_69/dense_138/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4330 - accuracy: 0.8011 - tf_f1: 0.7260 - val_loss: 0.3260 - val_accuracy: 0.8616 - val_tf_f1: 0.8111\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3003 - accuracy: 0.8769 - tf_f1: 0.8350 - val_loss: 0.3079 - val_accuracy: 0.8786 - val_tf_f1: 0.8508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:04:17,943]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_70/dense_140/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_70/dense_140/embedding_lookup_sparse/Reshape:0\", shape=(None, 43), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_70/dense_140/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4342 - accuracy: 0.8026 - tf_f1: 0.7391 - val_loss: 0.3050 - val_accuracy: 0.8815 - val_tf_f1: 0.8146\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3047 - accuracy: 0.8749 - tf_f1: 0.8381 - val_loss: 0.6255 - val_accuracy: 0.7284 - val_tf_f1: 0.8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:04:42,714]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_71/dense_142/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_71/dense_142/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_71/dense_142/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4343 - accuracy: 0.8010 - tf_f1: 0.7420 - val_loss: 0.2756 - val_accuracy: 0.8886 - val_tf_f1: 0.8140\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3122 - accuracy: 0.8722 - tf_f1: 0.8375 - val_loss: 0.3312 - val_accuracy: 0.8606 - val_tf_f1: 0.8499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:05:07,625]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_72/dense_144/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_72/dense_144/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_72/dense_144/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4413 - accuracy: 0.7980 - tf_f1: 0.7321 - val_loss: 0.3331 - val_accuracy: 0.8605 - val_tf_f1: 0.8089\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3131 - accuracy: 0.8697 - tf_f1: 0.8315 - val_loss: 0.3605 - val_accuracy: 0.8502 - val_tf_f1: 0.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:05:32,441]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_73/dense_146/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_73/dense_146/embedding_lookup_sparse/Reshape:0\", shape=(None, 28), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_73/dense_146/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4755 - accuracy: 0.7780 - tf_f1: 0.6920 - val_loss: 0.5481 - val_accuracy: 0.7311 - val_tf_f1: 0.7795\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3421 - accuracy: 0.8580 - tf_f1: 0.8023 - val_loss: 0.3249 - val_accuracy: 0.8664 - val_tf_f1: 0.8229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:05:57,372]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_74/dense_148/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_74/dense_148/embedding_lookup_sparse/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_74/dense_148/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4530 - accuracy: 0.7917 - tf_f1: 0.7310 - val_loss: 0.3966 - val_accuracy: 0.8248 - val_tf_f1: 0.8008\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3231 - accuracy: 0.8665 - tf_f1: 0.8237 - val_loss: 0.4673 - val_accuracy: 0.7968 - val_tf_f1: 0.8374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:06:22,293]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_75/dense_150/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_75/dense_150/embedding_lookup_sparse/Reshape:0\", shape=(None, 24), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_75/dense_150/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4347 - accuracy: 0.8025 - tf_f1: 0.7538 - val_loss: 0.2648 - val_accuracy: 0.8936 - val_tf_f1: 0.8165\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3238 - accuracy: 0.8669 - tf_f1: 0.8372 - val_loss: 0.2453 - val_accuracy: 0.9047 - val_tf_f1: 0.8502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:06:47,248]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_76/dense_152/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_76/dense_152/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_76/dense_152/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4197 - accuracy: 0.8090 - tf_f1: 0.7502 - val_loss: 0.3947 - val_accuracy: 0.8304 - val_tf_f1: 0.8171\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2859 - accuracy: 0.8850 - tf_f1: 0.8392 - val_loss: 0.4281 - val_accuracy: 0.8254 - val_tf_f1: 0.8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:07:11,959]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_77/dense_154/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_77/dense_154/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_77/dense_154/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4189 - accuracy: 0.8083 - tf_f1: 0.7342 - val_loss: 0.3075 - val_accuracy: 0.8770 - val_tf_f1: 0.8194\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2896 - accuracy: 0.8817 - tf_f1: 0.8428 - val_loss: 0.3380 - val_accuracy: 0.8664 - val_tf_f1: 0.8568\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2102 - accuracy: 0.9217 - tf_f1: 0.8689 - val_loss: 0.3052 - val_accuracy: 0.8911 - val_tf_f1: 0.8796\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1448 - accuracy: 0.9507 - tf_f1: 0.8891 - val_loss: 0.3206 - val_accuracy: 0.8952 - val_tf_f1: 0.8972\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1067 - accuracy: 0.9652 - tf_f1: 0.9041 - val_loss: 0.3253 - val_accuracy: 0.9272 - val_tf_f1: 0.9105\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0835 - accuracy: 0.9731 - tf_f1: 0.9159 - val_loss: 0.4060 - val_accuracy: 0.8808 - val_tf_f1: 0.9203\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0631 - accuracy: 0.9805 - tf_f1: 0.9242 - val_loss: 0.4029 - val_accuracy: 0.8987 - val_tf_f1: 0.9278\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0564 - accuracy: 0.9822 - tf_f1: 0.9309 - val_loss: 0.3839 - val_accuracy: 0.9194 - val_tf_f1: 0.9339\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0501 - accuracy: 0.9838 - tf_f1: 0.9365 - val_loss: 0.4279 - val_accuracy: 0.8985 - val_tf_f1: 0.9388\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0477 - accuracy: 0.9847 - tf_f1: 0.9408 - val_loss: 0.4373 - val_accuracy: 0.9281 - val_tf_f1: 0.9428\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0453 - accuracy: 0.9857 - tf_f1: 0.9446 - val_loss: 0.4380 - val_accuracy: 0.9125 - val_tf_f1: 0.9462\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0401 - accuracy: 0.9878 - tf_f1: 0.9478 - val_loss: 0.4584 - val_accuracy: 0.9049 - val_tf_f1: 0.9491\n",
      "Epoch 13/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0384 - accuracy: 0.9880 - tf_f1: 0.9504 - val_loss: 0.4918 - val_accuracy: 0.8928 - val_tf_f1: 0.9515\n",
      "Epoch 14/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0382 - accuracy: 0.9883 - tf_f1: 0.9525 - val_loss: 0.4845 - val_accuracy: 0.9057 - val_tf_f1: 0.9535\n",
      "Epoch 15/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0375 - accuracy: 0.9881 - tf_f1: 0.9544 - val_loss: 0.4780 - val_accuracy: 0.9142 - val_tf_f1: 0.9553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:10:12,376]\u001b[0m Trial 77 finished with value: 0.9553421139717102 and parameters: {'lr': 0.07729220041249463, 'units': 48}. Best is trial 36 with value: 0.9560930132865906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_78/dense_156/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_78/dense_156/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_78/dense_156/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4200 - accuracy: 0.8098 - tf_f1: 0.7459 - val_loss: 0.4330 - val_accuracy: 0.8078 - val_tf_f1: 0.8162\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2865 - accuracy: 0.8835 - tf_f1: 0.8367 - val_loss: 0.3493 - val_accuracy: 0.8611 - val_tf_f1: 0.8533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:10:37,250]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_79/dense_158/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_79/dense_158/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_79/dense_158/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4197 - accuracy: 0.8099 - tf_f1: 0.7605 - val_loss: 0.4633 - val_accuracy: 0.7982 - val_tf_f1: 0.8160\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2909 - accuracy: 0.8808 - tf_f1: 0.8358 - val_loss: 0.4674 - val_accuracy: 0.8109 - val_tf_f1: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:11:02,088]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_80/dense_160/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_80/dense_160/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_80/dense_160/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4305 - accuracy: 0.8018 - tf_f1: 0.7509 - val_loss: 0.3563 - val_accuracy: 0.8431 - val_tf_f1: 0.8127\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2951 - accuracy: 0.8799 - tf_f1: 0.8354 - val_loss: 0.6408 - val_accuracy: 0.7202 - val_tf_f1: 0.8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:11:26,746]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_81/dense_162/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_81/dense_162/embedding_lookup_sparse/Reshape:0\", shape=(None, 15), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_81/dense_162/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4440 - accuracy: 0.7928 - tf_f1: 0.7062 - val_loss: 0.4156 - val_accuracy: 0.8190 - val_tf_f1: 0.8004\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3099 - accuracy: 0.8719 - tf_f1: 0.8238 - val_loss: 0.4610 - val_accuracy: 0.8044 - val_tf_f1: 0.8395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:11:51,595]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_82/dense_164/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_82/dense_164/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_82/dense_164/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4221 - accuracy: 0.8061 - tf_f1: 0.7395 - val_loss: 0.3868 - val_accuracy: 0.8349 - val_tf_f1: 0.8152\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2865 - accuracy: 0.8844 - tf_f1: 0.8384 - val_loss: 0.2984 - val_accuracy: 0.8922 - val_tf_f1: 0.8554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:12:16,359]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_83/dense_166/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_83/dense_166/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_83/dense_166/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4238 - accuracy: 0.8055 - tf_f1: 0.7296 - val_loss: 0.3419 - val_accuracy: 0.8549 - val_tf_f1: 0.8151\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2902 - accuracy: 0.8813 - tf_f1: 0.8383 - val_loss: 0.2888 - val_accuracy: 0.8891 - val_tf_f1: 0.8546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:12:41,162]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_84/dense_168/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_84/dense_168/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_84/dense_168/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 6ms/step - loss: 0.4338 - accuracy: 0.8007 - tf_f1: 0.7392 - val_loss: 0.4030 - val_accuracy: 0.8225 - val_tf_f1: 0.8094\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3035 - accuracy: 0.8750 - tf_f1: 0.8317 - val_loss: 0.3274 - val_accuracy: 0.8704 - val_tf_f1: 0.8473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:13:06,517]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_85/dense_170/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_85/dense_170/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_85/dense_170/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4221 - accuracy: 0.8051 - tf_f1: 0.7479 - val_loss: 0.3225 - val_accuracy: 0.8642 - val_tf_f1: 0.8166\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2943 - accuracy: 0.8799 - tf_f1: 0.8396 - val_loss: 0.3078 - val_accuracy: 0.8828 - val_tf_f1: 0.8546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:13:31,447]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_86/dense_172/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_86/dense_172/embedding_lookup_sparse/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_86/dense_172/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4435 - accuracy: 0.7949 - tf_f1: 0.7203 - val_loss: 0.4468 - val_accuracy: 0.7954 - val_tf_f1: 0.8010\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3122 - accuracy: 0.8702 - tf_f1: 0.8236 - val_loss: 0.3319 - val_accuracy: 0.8657 - val_tf_f1: 0.8402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:13:56,196]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_87/dense_174/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_87/dense_174/embedding_lookup_sparse/Reshape:0\", shape=(None, 42), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_87/dense_174/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4230 - accuracy: 0.8045 - tf_f1: 0.7470 - val_loss: 0.3388 - val_accuracy: 0.8582 - val_tf_f1: 0.8158\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2932 - accuracy: 0.8800 - tf_f1: 0.8384 - val_loss: 0.2476 - val_accuracy: 0.9097 - val_tf_f1: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:14:20,907]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_88/dense_176/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_88/dense_176/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_88/dense_176/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4206 - accuracy: 0.8060 - tf_f1: 0.7474 - val_loss: 0.3953 - val_accuracy: 0.8273 - val_tf_f1: 0.8151\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2873 - accuracy: 0.8820 - tf_f1: 0.8367 - val_loss: 0.6085 - val_accuracy: 0.7448 - val_tf_f1: 0.8488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:14:45,548]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_89/dense_178/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_89/dense_178/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_89/dense_178/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4222 - accuracy: 0.8070 - tf_f1: 0.7460 - val_loss: 0.3499 - val_accuracy: 0.8521 - val_tf_f1: 0.8176\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2852 - accuracy: 0.8850 - tf_f1: 0.8406 - val_loss: 0.3092 - val_accuracy: 0.8785 - val_tf_f1: 0.8567\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2140 - accuracy: 0.9188 - tf_f1: 0.8684 - val_loss: 0.2601 - val_accuracy: 0.9132 - val_tf_f1: 0.8795\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1522 - accuracy: 0.9468 - tf_f1: 0.8889 - val_loss: 0.3098 - val_accuracy: 0.9055 - val_tf_f1: 0.8968\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1110 - accuracy: 0.9635 - tf_f1: 0.9037 - val_loss: 0.3247 - val_accuracy: 0.9157 - val_tf_f1: 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:15:45,818]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_90/dense_180/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_90/dense_180/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_90/dense_180/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4211 - accuracy: 0.8082 - tf_f1: 0.7487 - val_loss: 0.3855 - val_accuracy: 0.8351 - val_tf_f1: 0.8166\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2928 - accuracy: 0.8813 - tf_f1: 0.8380 - val_loss: 0.5818 - val_accuracy: 0.7665 - val_tf_f1: 0.8504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:16:10,485]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_91/dense_182/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_91/dense_182/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_91/dense_182/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.6928 - accuracy: 0.5430 - tf_f1: 0.5016 - val_loss: 0.6921 - val_accuracy: 0.6252 - val_tf_f1: 0.5183\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.6919 - accuracy: 0.6161 - tf_f1: 0.5693 - val_loss: 0.6917 - val_accuracy: 0.5901 - val_tf_f1: 0.5890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:16:35,306]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_92/dense_184/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_92/dense_184/embedding_lookup_sparse/Reshape:0\", shape=(None, 44), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_92/dense_184/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4174 - accuracy: 0.8092 - tf_f1: 0.7515 - val_loss: 0.2903 - val_accuracy: 0.8810 - val_tf_f1: 0.8212\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2877 - accuracy: 0.8826 - tf_f1: 0.8441 - val_loss: 0.5003 - val_accuracy: 0.7948 - val_tf_f1: 0.8557\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2052 - accuracy: 0.9232 - tf_f1: 0.8666 - val_loss: 0.3307 - val_accuracy: 0.8762 - val_tf_f1: 0.8774\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1450 - accuracy: 0.9491 - tf_f1: 0.8868 - val_loss: 0.3003 - val_accuracy: 0.9190 - val_tf_f1: 0.8954\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1045 - accuracy: 0.9660 - tf_f1: 0.9030 - val_loss: 0.4437 - val_accuracy: 0.8570 - val_tf_f1: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:17:35,731]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_93/dense_186/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_93/dense_186/embedding_lookup_sparse/Reshape:0\", shape=(None, 46), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_93/dense_186/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.5074 - accuracy: 0.7664 - tf_f1: 0.6616 - val_loss: 0.4620 - val_accuracy: 0.7813 - val_tf_f1: 0.7672\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3727 - accuracy: 0.8439 - tf_f1: 0.7934 - val_loss: 0.4198 - val_accuracy: 0.8133 - val_tf_f1: 0.8114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:18:00,419]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_94/dense_188/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_94/dense_188/embedding_lookup_sparse/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_94/dense_188/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.6019 - accuracy: 0.7316 - tf_f1: 0.5789 - val_loss: 0.4816 - val_accuracy: 0.7743 - val_tf_f1: 0.7143\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.4594 - accuracy: 0.8022 - tf_f1: 0.7468 - val_loss: 0.4110 - val_accuracy: 0.8149 - val_tf_f1: 0.7683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:18:25,306]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_95/dense_190/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_95/dense_190/embedding_lookup_sparse/Reshape:0\", shape=(None, 35), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_95/dense_190/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4227 - accuracy: 0.8079 - tf_f1: 0.7592 - val_loss: 0.4388 - val_accuracy: 0.8020 - val_tf_f1: 0.8153\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2960 - accuracy: 0.8783 - tf_f1: 0.8351 - val_loss: 0.2691 - val_accuracy: 0.8979 - val_tf_f1: 0.8515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:18:50,147]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_96/dense_192/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_96/dense_192/embedding_lookup_sparse/Reshape:0\", shape=(None, 47), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_96/dense_192/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4194 - accuracy: 0.8094 - tf_f1: 0.7581 - val_loss: 0.3890 - val_accuracy: 0.8283 - val_tf_f1: 0.8180\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2847 - accuracy: 0.8839 - tf_f1: 0.8388 - val_loss: 0.4225 - val_accuracy: 0.8209 - val_tf_f1: 0.8535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:19:14,912]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_97/dense_194/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_97/dense_194/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_97/dense_194/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4186 - accuracy: 0.8077 - tf_f1: 0.7537 - val_loss: 0.2300 - val_accuracy: 0.9123 - val_tf_f1: 0.8233\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2824 - accuracy: 0.8856 - tf_f1: 0.8477 - val_loss: 0.4175 - val_accuracy: 0.8346 - val_tf_f1: 0.8602\n",
      "Epoch 3/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2041 - accuracy: 0.9248 - tf_f1: 0.8713 - val_loss: 0.3358 - val_accuracy: 0.8795 - val_tf_f1: 0.8816\n",
      "Epoch 4/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.1403 - accuracy: 0.9519 - tf_f1: 0.8907 - val_loss: 0.3242 - val_accuracy: 0.8977 - val_tf_f1: 0.8988\n",
      "Epoch 5/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0993 - accuracy: 0.9678 - tf_f1: 0.9058 - val_loss: 0.3778 - val_accuracy: 0.8847 - val_tf_f1: 0.9117\n",
      "Epoch 6/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0740 - accuracy: 0.9770 - tf_f1: 0.9168 - val_loss: 0.4297 - val_accuracy: 0.8682 - val_tf_f1: 0.9212\n",
      "Epoch 7/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0592 - accuracy: 0.9814 - tf_f1: 0.9249 - val_loss: 0.3850 - val_accuracy: 0.9087 - val_tf_f1: 0.9287\n",
      "Epoch 8/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0519 - accuracy: 0.9843 - tf_f1: 0.9319 - val_loss: 0.4750 - val_accuracy: 0.8729 - val_tf_f1: 0.9346\n",
      "Epoch 9/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0456 - accuracy: 0.9854 - tf_f1: 0.9369 - val_loss: 0.4436 - val_accuracy: 0.8935 - val_tf_f1: 0.9392\n",
      "Epoch 10/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0441 - accuracy: 0.9860 - tf_f1: 0.9412 - val_loss: 0.4684 - val_accuracy: 0.8823 - val_tf_f1: 0.9430\n",
      "Epoch 11/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0404 - accuracy: 0.9872 - tf_f1: 0.9446 - val_loss: 0.4377 - val_accuracy: 0.9215 - val_tf_f1: 0.9463\n",
      "Epoch 12/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0377 - accuracy: 0.9881 - tf_f1: 0.9479 - val_loss: 0.4483 - val_accuracy: 0.9151 - val_tf_f1: 0.9493\n",
      "Epoch 13/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0361 - accuracy: 0.9885 - tf_f1: 0.9506 - val_loss: 0.4722 - val_accuracy: 0.9215 - val_tf_f1: 0.9519\n",
      "Epoch 14/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0342 - accuracy: 0.9892 - tf_f1: 0.9530 - val_loss: 0.4599 - val_accuracy: 0.9141 - val_tf_f1: 0.9541\n",
      "Epoch 15/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.0337 - accuracy: 0.9892 - tf_f1: 0.9551 - val_loss: 0.4769 - val_accuracy: 0.9068 - val_tf_f1: 0.9559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:22:15,109]\u001b[0m Trial 97 finished with value: 0.9559414386749268 and parameters: {'lr': 0.08337494780099554, 'units': 49}. Best is trial 36 with value: 0.9560930132865906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_98/dense_196/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_98/dense_196/embedding_lookup_sparse/Reshape:0\", shape=(None, 49), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_98/dense_196/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4229 - accuracy: 0.8081 - tf_f1: 0.7581 - val_loss: 0.4675 - val_accuracy: 0.7906 - val_tf_f1: 0.8138\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.3001 - accuracy: 0.8767 - tf_f1: 0.8330 - val_loss: 0.3057 - val_accuracy: 0.8780 - val_tf_f1: 0.8490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:22:39,872]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_99/dense_198/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_99/dense_198/embedding_lookup_sparse/Reshape:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_99/dense_198/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214/2214 [==============================] - 13s 5ms/step - loss: 0.4195 - accuracy: 0.8093 - tf_f1: 0.7576 - val_loss: 0.6123 - val_accuracy: 0.7229 - val_tf_f1: 0.8102\n",
      "Epoch 2/50\n",
      "2214/2214 [==============================] - 12s 5ms/step - loss: 0.2896 - accuracy: 0.8814 - tf_f1: 0.8280 - val_loss: 0.3406 - val_accuracy: 0.8662 - val_tf_f1: 0.8468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-26 02:23:04,810]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 completed rungs: {}\n",
      "Trial 1 completed rungs: {'completed_rung_0': 0.7558432817459106, 'completed_rung_1': 0.8062049150466919, 'completed_rung_2': 0.8683011531829834}\n",
      "Trial 2 completed rungs: {'completed_rung_0': 0.8448481559753418, 'completed_rung_1': 0.8989165425300598}\n",
      "Trial 3 completed rungs: {'completed_rung_0': 0.8091752529144287}\n",
      "Trial 4 completed rungs: {'completed_rung_0': 0.7012574076652527}\n",
      "Trial 5 completed rungs: {'completed_rung_0': 0.85057133436203, 'completed_rung_1': 0.8944485187530518}\n",
      "Trial 6 completed rungs: {'completed_rung_0': 0.8212453722953796}\n",
      "Trial 7 completed rungs: {'completed_rung_0': 0.823862612247467}\n",
      "Trial 8 completed rungs: {'completed_rung_0': 0.8477990627288818, 'completed_rung_1': 0.9071922898292542}\n",
      "Trial 9 completed rungs: {'completed_rung_0': 0.8419150710105896}\n",
      "Trial 10 completed rungs: {'completed_rung_0': 0.8410026431083679}\n",
      "Trial 11 completed rungs: {'completed_rung_0': 0.8522742390632629, 'completed_rung_1': 0.9031714797019958}\n",
      "Trial 12 completed rungs: {'completed_rung_0': 0.8610753417015076, 'completed_rung_1': 0.9100297093391418}\n",
      "Trial 13 completed rungs: {'completed_rung_0': 0.8522431254386902, 'completed_rung_1': 0.9080107808113098}\n",
      "Trial 14 completed rungs: {'completed_rung_0': 0.8455250859260559}\n",
      "Trial 15 completed rungs: {'completed_rung_0': 0.8430473804473877}\n",
      "Trial 16 completed rungs: {'completed_rung_0': 0.8328664898872375}\n",
      "Trial 17 completed rungs: {'completed_rung_0': 0.856026291847229, 'completed_rung_1': 0.9060472249984741}\n",
      "Trial 18 completed rungs: {'completed_rung_0': 0.8441364169120789}\n",
      "Trial 19 completed rungs: {'completed_rung_0': 0.8554323315620422, 'completed_rung_1': 0.9056192636489868}\n",
      "Trial 20 completed rungs: {'completed_rung_0': 0.843367338180542}\n",
      "Trial 21 completed rungs: {'completed_rung_0': 0.8572131991386414, 'completed_rung_1': 0.9099606871604919}\n",
      "Trial 22 completed rungs: {'completed_rung_0': 0.8539544343948364, 'completed_rung_1': 0.9029904007911682}\n",
      "Trial 23 completed rungs: {'completed_rung_0': 0.8520236015319824}\n",
      "Trial 24 completed rungs: {'completed_rung_0': 0.8571493625640869, 'completed_rung_1': 0.9103367924690247}\n",
      "Trial 25 completed rungs: {'completed_rung_0': 0.8538817167282104}\n",
      "Trial 26 completed rungs: {'completed_rung_0': 0.8490564227104187}\n",
      "Trial 27 completed rungs: {'completed_rung_0': 0.8549841046333313, 'completed_rung_1': 0.9041610956192017}\n",
      "Trial 28 completed rungs: {'completed_rung_0': 0.8569885492324829, 'completed_rung_1': 0.9081577062606812}\n",
      "Trial 29 completed rungs: {'completed_rung_0': 0.8471636176109314}\n",
      "Trial 30 completed rungs: {'completed_rung_0': 0.8488075137138367}\n",
      "Trial 31 completed rungs: {'completed_rung_0': 0.8595948815345764, 'completed_rung_1': 0.9110634922981262}\n",
      "Trial 32 completed rungs: {'completed_rung_0': 0.8601844906806946, 'completed_rung_1': 0.9095563292503357}\n",
      "Trial 33 completed rungs: {'completed_rung_0': 0.8515416383743286}\n",
      "Trial 34 completed rungs: {'completed_rung_0': 0.8560798168182373, 'completed_rung_1': 0.9072799682617188}\n",
      "Trial 35 completed rungs: {'completed_rung_0': 0.8471580147743225}\n",
      "Trial 36 completed rungs: {'completed_rung_0': 0.8585039973258972, 'completed_rung_1': 0.9121124148368835}\n",
      "Trial 37 completed rungs: {'completed_rung_0': 0.8563417196273804, 'completed_rung_1': 0.9070460796356201}\n",
      "Trial 38 completed rungs: {'completed_rung_0': 0.8377843499183655}\n",
      "Trial 39 completed rungs: {'completed_rung_0': 0.8496741056442261}\n",
      "Trial 40 completed rungs: {'completed_rung_0': 0.8557087182998657}\n",
      "Trial 41 completed rungs: {'completed_rung_0': 0.852512776851654}\n",
      "Trial 42 completed rungs: {'completed_rung_0': 0.8430497646331787}\n",
      "Trial 43 completed rungs: {'completed_rung_0': 0.8557113409042358}\n",
      "Trial 44 completed rungs: {'completed_rung_0': 0.8490493297576904}\n",
      "Trial 45 completed rungs: {'completed_rung_0': 0.8047789931297302}\n",
      "Trial 46 completed rungs: {'completed_rung_0': 0.8485658168792725}\n",
      "Trial 47 completed rungs: {'completed_rung_0': 0.8504849076271057}\n",
      "Trial 48 completed rungs: {'completed_rung_0': 0.8439832329750061}\n",
      "Trial 49 completed rungs: {'completed_rung_0': 0.8371244668960571}\n",
      "Trial 50 completed rungs: {'completed_rung_0': 0.848070502281189}\n",
      "Trial 51 completed rungs: {'completed_rung_0': 0.8523777723312378}\n",
      "Trial 52 completed rungs: {'completed_rung_0': 0.8538537621498108}\n",
      "Trial 53 completed rungs: {'completed_rung_0': 0.8581415414810181, 'completed_rung_1': 0.9098985195159912}\n",
      "Trial 54 completed rungs: {'completed_rung_0': 0.8516779541969299}\n",
      "Trial 55 completed rungs: {'completed_rung_0': 0.8510533571243286}\n",
      "Trial 56 completed rungs: {'completed_rung_0': 0.8522910475730896}\n",
      "Trial 57 completed rungs: {'completed_rung_0': 0.8464818000793457}\n",
      "Trial 58 completed rungs: {'completed_rung_0': 0.8533634543418884}\n",
      "Trial 59 completed rungs: {'completed_rung_0': 0.8574239015579224, 'completed_rung_1': 0.9069309234619141}\n",
      "Trial 60 completed rungs: {'completed_rung_0': 0.8438630104064941}\n",
      "Trial 61 completed rungs: {'completed_rung_0': 0.8580775260925293, 'completed_rung_1': 0.9083892703056335}\n",
      "Trial 62 completed rungs: {'completed_rung_0': 0.8555357456207275}\n",
      "Trial 63 completed rungs: {'completed_rung_0': 0.8571482300758362, 'completed_rung_1': 0.9073755145072937}\n",
      "Trial 64 completed rungs: {'completed_rung_0': 0.8602226972579956, 'completed_rung_1': 0.9091442227363586}\n",
      "Trial 65 completed rungs: {'completed_rung_0': 0.8511661887168884}\n",
      "Trial 66 completed rungs: {'completed_rung_0': 0.8545699715614319}\n",
      "Trial 67 completed rungs: {'completed_rung_0': 0.8462572693824768}\n",
      "Trial 68 completed rungs: {'completed_rung_0': 0.8626132011413574, 'completed_rung_1': 0.9087153077125549}\n",
      "Trial 69 completed rungs: {'completed_rung_0': 0.8507749438285828}\n",
      "Trial 70 completed rungs: {'completed_rung_0': 0.847098708152771}\n",
      "Trial 71 completed rungs: {'completed_rung_0': 0.8498879075050354}\n",
      "Trial 72 completed rungs: {'completed_rung_0': 0.8454464673995972}\n",
      "Trial 73 completed rungs: {'completed_rung_0': 0.8229252696037292}\n",
      "Trial 74 completed rungs: {'completed_rung_0': 0.8373847007751465}\n",
      "Trial 75 completed rungs: {'completed_rung_0': 0.8502259254455566}\n",
      "Trial 76 completed rungs: {'completed_rung_0': 0.8540144562721252}\n",
      "Trial 77 completed rungs: {'completed_rung_0': 0.8567667007446289, 'completed_rung_1': 0.9105123281478882}\n",
      "Trial 78 completed rungs: {'completed_rung_0': 0.8532944917678833}\n",
      "Trial 79 completed rungs: {'completed_rung_0': 0.8499714732170105}\n",
      "Trial 80 completed rungs: {'completed_rung_0': 0.8463326096534729}\n",
      "Trial 81 completed rungs: {'completed_rung_0': 0.8395234942436218}\n",
      "Trial 82 completed rungs: {'completed_rung_0': 0.8553800582885742}\n",
      "Trial 83 completed rungs: {'completed_rung_0': 0.8546204566955566}\n",
      "Trial 84 completed rungs: {'completed_rung_0': 0.8472918272018433}\n",
      "Trial 85 completed rungs: {'completed_rung_0': 0.8545990586280823}\n",
      "Trial 86 completed rungs: {'completed_rung_0': 0.8402065634727478}\n",
      "Trial 87 completed rungs: {'completed_rung_0': 0.8549669981002808}\n",
      "Trial 88 completed rungs: {'completed_rung_0': 0.8487865328788757}\n",
      "Trial 89 completed rungs: {'completed_rung_0': 0.8566648960113525, 'completed_rung_1': 0.9098978042602539}\n",
      "Trial 90 completed rungs: {'completed_rung_0': 0.8503830432891846}\n",
      "Trial 91 completed rungs: {'completed_rung_0': 0.5890201926231384}\n",
      "Trial 92 completed rungs: {'completed_rung_0': 0.8556927442550659, 'completed_rung_1': 0.9086669683456421}\n",
      "Trial 93 completed rungs: {'completed_rung_0': 0.8113522529602051}\n",
      "Trial 94 completed rungs: {'completed_rung_0': 0.7683344483375549}\n",
      "Trial 95 completed rungs: {'completed_rung_0': 0.8515174984931946}\n",
      "Trial 96 completed rungs: {'completed_rung_0': 0.8535009026527405}\n",
      "Trial 97 completed rungs: {'completed_rung_0': 0.8601975440979004, 'completed_rung_1': 0.9116714000701904}\n",
      "Trial 98 completed rungs: {'completed_rung_0': 0.849000096321106}\n",
      "Trial 99 completed rungs: {'completed_rung_0': 0.8467583060264587}\n",
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  89\n",
      "  Number of complete trials:  11\n",
      "Best trial:\n",
      "  Value:  0.9560930132865906\n",
      "  Params: \n",
      "    lr: 0.08679299688055687\n",
      "    units: 45\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.optimizer_v2.gradient_descent import SGD\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import statistics\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from keras.utils import to_categorical\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
    "\n",
    "tf_x_train_trainvec = convert_sparse_matrix_to_sparse_tensor(x_train_trainvec)\n",
    "\n",
    "tf_x_valvec = convert_sparse_matrix_to_sparse_tensor(x_valvec)\n",
    "\n",
    "def create_model(trial, X):\n",
    "    lr = trial.suggest_uniform('lr', 0.00001, 0.1)\n",
    "    units = trial.suggest_int('units', 10, 50)\n",
    "    input_dim = X\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, input_dim=input_dim, activation = 'relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = SGD(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "    \n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                    optimizer=optimizer, \n",
    "                    metrics=['accuracy', F1Score(num_classes=1, average= 'micro',threshold=0.5, name='tf_f1')])\n",
    "    return model\n",
    "            \n",
    "\n",
    "def objective_mlp(trial):\n",
    "\n",
    "    model = create_model(trial, x_train_trainvec.shape[1])\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_tf_f1', mode='max', min_delta=0.01, patience=3, verbose=1), TFKerasPruningCallback(trial,'val_tf_f1')]\n",
    "\n",
    "    fit_model = model.fit(x=tf_x_train_trainvec, y=tf.convert_to_tensor(y_train_train), epochs =50, verbose=1, batch_size= 50, callbacks=callbacks, validation_data=(tf_x_valvec,tf.convert_to_tensor(y_val)))\n",
    "\n",
    "    return fit_model.history['val_tf_f1'][-1]\n",
    "\n",
    "def show_result(study):\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    trial_idx = 0\n",
    "    for frozen_trial in study.get_trials(deepcopy=False):\n",
    "\n",
    "        print(\"Trial {} completed rungs: {}\".format(trial_idx, frozen_trial.system_attrs))\n",
    "        trial_idx +=1\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",sampler= TPESampler(),  pruner=SuccessiveHalvingPruner()\n",
    ")\n",
    "study.optimize(objective_mlp, n_trials=100)\n",
    "\n",
    "show_result(study)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lim Jia Hui\\Desktop\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_100/dense_200/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_100/dense_200/embedding_lookup_sparse/Reshape:0\", shape=(None, 45), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_100/dense_200/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.4135 - accuracy: 0.8137 - tf_f1: 0.7529\n",
      "Epoch 2/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.2905 - accuracy: 0.8826 - tf_f1: 0.8317\n",
      "Epoch 3/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.2106 - accuracy: 0.9215 - tf_f1: 0.8605\n",
      "Epoch 4/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.1491 - accuracy: 0.9487 - tf_f1: 0.8819\n",
      "Epoch 5/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.1114 - accuracy: 0.9625 - tf_f1: 0.8983\n",
      "Epoch 6/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0910 - accuracy: 0.9698 - tf_f1: 0.9107\n",
      "Epoch 7/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0789 - accuracy: 0.9736 - tf_f1: 0.9200\n",
      "Epoch 8/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0638 - accuracy: 0.9790 - tf_f1: 0.9276\n",
      "Epoch 9/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0603 - accuracy: 0.9806 - tf_f1: 0.9337\n",
      "Epoch 10/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0548 - accuracy: 0.9818 - tf_f1: 0.9388\n",
      "Epoch 11/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0526 - accuracy: 0.9828 - tf_f1: 0.9429\n",
      "Epoch 12/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0481 - accuracy: 0.9840 - tf_f1: 0.9465\n",
      "Epoch 13/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0458 - accuracy: 0.9853 - tf_f1: 0.9495\n",
      "Epoch 14/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0447 - accuracy: 0.9851 - tf_f1: 0.9522\n",
      "Epoch 15/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0425 - accuracy: 0.9861 - tf_f1: 0.9545\n",
      "Epoch 16/50\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 0.0421 - accuracy: 0.9864 - tf_f1: 0.9565\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_model = create_model(study.best_trial, x_trainvec.shape[1])\n",
    "\n",
    "tf_x_trainvec = convert_sparse_matrix_to_sparse_tensor(x_trainvec)\n",
    "tf_x_testvec = convert_sparse_matrix_to_sparse_tensor(x_testvec)\n",
    "\n",
    "best_model.fit(x=tf_x_trainvec, y=tf.convert_to_tensor(y_train), epochs =50, verbose=1, batch_size= 50, callbacks=EarlyStopping(monitor='tf_f1', mode='max', min_delta=0.01, patience=3, verbose=1))\n",
    "\n",
    "mlp_train_predictions = best_model.predict(x_trainvec)\n",
    "mlp_test_predictions = best_model.predict(x_testvec)\n",
    "\n",
    "mlp_train_predictions[mlp_train_predictions <= 0.5] = 0\n",
    "mlp_train_predictions[mlp_train_predictions > 0.5] = 1\n",
    "\n",
    "mlp_test_predictions[mlp_test_predictions <= 0.5] = 0\n",
    "mlp_test_predictions[mlp_test_predictions > 0.5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Train Accuracy Score : 0.9879339512152803\n",
      "MLP Test Accuracy Score : 0.9096722621902478\n",
      "MLP Train F1 Score : 0.9879072867835121\n",
      "MLP Test F1 Score : 0.9510158078779297\n",
      "MLP Confusion matrix:\n",
      "[[  616   875]\n",
      " [  820 16454]]\n",
      "MLP Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.43      0.42      1436\n",
      "           1       0.95      0.95      0.95     17329\n",
      "\n",
      "    accuracy                           0.91     18765\n",
      "   macro avg       0.68      0.69      0.69     18765\n",
      "weighted avg       0.91      0.91      0.91     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP Train Accuracy Score :\",accuracy_score(y_pred=mlp_train_predictions, y_true=y_train.to_numpy().ravel()))\n",
    "print(\"MLP Test Accuracy Score :\",accuracy_score(y_pred=mlp_test_predictions, y_true= y_test.to_numpy().ravel()))\n",
    "\n",
    "print(\"MLP Train F1 Score :\",f1_score(y_pred=mlp_train_predictions, y_true=y_train.to_numpy().ravel(), average = 'binary'))\n",
    "print(\"MLP Test F1 Score :\",f1_score(y_pred=mlp_test_predictions, y_true=y_test.to_numpy().ravel(), average = 'binary'))\n",
    "\n",
    "print(\"MLP Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= mlp_test_predictions)))\n",
    "print(\"MLP Classification report:\\n\",classification_report(y_pred=mlp_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 5532\n",
      "max_resources_: 138322\n",
      "aggressive_elimination: False\n",
      "factor: 5\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 100\n",
      "n_resources: 5532\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 1/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.072, test=0.056) total time=   0.9s\n",
      "[CV 2/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 2/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.666, test=0.689) total time=   0.4s\n",
      "[CV 3/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 3/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.664, test=0.645) total time=   0.4s\n",
      "[CV 4/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 4/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.666, test=0.684) total time=   0.0s\n",
      "[CV 5/5; 1/100] START rfc__max_depth=1, rfc__n_estimators=1.....................\n",
      "[CV 5/5; 1/100] END rfc__max_depth=1, rfc__n_estimators=1;, score=(train=0.000, test=0.000) total time=   0.0s\n",
      "[CV 1/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 1/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.710, test=0.717) total time=   0.0s\n",
      "[CV 2/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 2/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.697, test=0.693) total time=   0.0s\n",
      "[CV 3/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 3/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.677, test=0.664) total time=   0.1s\n",
      "[CV 4/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 4/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.562, test=0.529) total time=   0.0s\n",
      "[CV 5/5; 2/100] START rfc__max_depth=1, rfc__n_estimators=51....................\n",
      "[CV 5/5; 2/100] END rfc__max_depth=1, rfc__n_estimators=51;, score=(train=0.613, test=0.570) total time=   0.1s\n",
      "[CV 1/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 1/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.713, test=0.713) total time=   0.1s\n",
      "[CV 2/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 2/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.710, test=0.708) total time=   0.1s\n",
      "[CV 3/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 3/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.709, test=0.676) total time=   0.1s\n",
      "[CV 4/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 4/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.705, test=0.703) total time=   0.1s\n",
      "[CV 5/5; 3/100] START rfc__max_depth=1, rfc__n_estimators=101...................\n",
      "[CV 5/5; 3/100] END rfc__max_depth=1, rfc__n_estimators=101;, score=(train=0.703, test=0.675) total time=   0.1s\n",
      "[CV 1/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 1/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.709, test=0.711) total time=   0.2s\n",
      "[CV 2/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 2/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.704, test=0.700) total time=   0.2s\n",
      "[CV 3/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 3/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.706, test=0.690) total time=   0.2s\n",
      "[CV 4/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 4/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.722, test=0.730) total time=   0.2s\n",
      "[CV 5/5; 4/100] START rfc__max_depth=1, rfc__n_estimators=151...................\n",
      "[CV 5/5; 4/100] END rfc__max_depth=1, rfc__n_estimators=151;, score=(train=0.721, test=0.691) total time=   0.2s\n",
      "[CV 1/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 1/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.713, test=0.719) total time=   0.3s\n",
      "[CV 2/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 2/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.710, test=0.716) total time=   0.3s\n",
      "[CV 3/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 3/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.705, test=0.714) total time=   0.3s\n",
      "[CV 4/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 4/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.721, test=0.727) total time=   0.3s\n",
      "[CV 5/5; 5/100] START rfc__max_depth=1, rfc__n_estimators=201...................\n",
      "[CV 5/5; 5/100] END rfc__max_depth=1, rfc__n_estimators=201;, score=(train=0.725, test=0.703) total time=   0.3s\n",
      "[CV 1/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 1/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.717, test=0.726) total time=   0.4s\n",
      "[CV 2/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 2/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.710, test=0.716) total time=   0.4s\n",
      "[CV 3/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 3/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.704, test=0.707) total time=   0.4s\n",
      "[CV 4/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 4/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.725, test=0.733) total time=   0.4s\n",
      "[CV 5/5; 6/100] START rfc__max_depth=1, rfc__n_estimators=251...................\n",
      "[CV 5/5; 6/100] END rfc__max_depth=1, rfc__n_estimators=251;, score=(train=0.722, test=0.714) total time=   0.4s\n",
      "[CV 1/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 1/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.719, test=0.726) total time=   0.4s\n",
      "[CV 2/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 2/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.716, test=0.721) total time=   0.4s\n",
      "[CV 3/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 3/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.709, test=0.701) total time=   0.4s\n",
      "[CV 4/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 4/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.727, test=0.730) total time=   0.4s\n",
      "[CV 5/5; 7/100] START rfc__max_depth=1, rfc__n_estimators=301...................\n",
      "[CV 5/5; 7/100] END rfc__max_depth=1, rfc__n_estimators=301;, score=(train=0.725, test=0.712) total time=   0.4s\n",
      "[CV 1/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 1/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.722, test=0.728) total time=   0.5s\n",
      "[CV 2/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 2/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.714, test=0.719) total time=   0.5s\n",
      "[CV 3/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 3/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.715, test=0.715) total time=   0.5s\n",
      "[CV 4/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 4/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.726, test=0.735) total time=   0.5s\n",
      "[CV 5/5; 8/100] START rfc__max_depth=1, rfc__n_estimators=351...................\n",
      "[CV 5/5; 8/100] END rfc__max_depth=1, rfc__n_estimators=351;, score=(train=0.731, test=0.716) total time=   0.5s\n",
      "[CV 1/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 1/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.720, test=0.724) total time=   0.5s\n",
      "[CV 2/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 2/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.717, test=0.720) total time=   0.5s\n",
      "[CV 3/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 3/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.713, test=0.714) total time=   0.5s\n",
      "[CV 4/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 4/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.720, test=0.736) total time=   0.5s\n",
      "[CV 5/5; 9/100] START rfc__max_depth=1, rfc__n_estimators=401...................\n",
      "[CV 5/5; 9/100] END rfc__max_depth=1, rfc__n_estimators=401;, score=(train=0.728, test=0.720) total time=   0.5s\n",
      "[CV 1/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 1/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.725, test=0.730) total time=   0.6s\n",
      "[CV 2/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 2/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.718, test=0.724) total time=   0.6s\n",
      "[CV 3/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 3/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.715, test=0.711) total time=   0.6s\n",
      "[CV 4/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 4/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.722, test=0.733) total time=   0.6s\n",
      "[CV 5/5; 10/100] START rfc__max_depth=1, rfc__n_estimators=451..................\n",
      "[CV 5/5; 10/100] END rfc__max_depth=1, rfc__n_estimators=451;, score=(train=0.727, test=0.713) total time=   0.6s\n",
      "[CV 1/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 1/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.669, test=0.689) total time=   0.0s\n",
      "[CV 2/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 2/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.673, test=0.687) total time=   0.0s\n",
      "[CV 3/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 3/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.669, test=0.647) total time=   0.0s\n",
      "[CV 4/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 4/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.376, test=0.360) total time=   0.0s\n",
      "[CV 5/5; 11/100] START rfc__max_depth=6, rfc__n_estimators=1....................\n",
      "[CV 5/5; 11/100] END rfc__max_depth=6, rfc__n_estimators=1;, score=(train=0.672, test=0.666) total time=   0.0s\n",
      "[CV 1/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 1/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.760, test=0.731) total time=   0.1s\n",
      "[CV 2/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 2/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.749, test=0.715) total time=   0.1s\n",
      "[CV 3/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 3/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.736, test=0.715) total time=   0.1s\n",
      "[CV 4/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 4/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.739, test=0.713) total time=   0.1s\n",
      "[CV 5/5; 12/100] START rfc__max_depth=6, rfc__n_estimators=51...................\n",
      "[CV 5/5; 12/100] END rfc__max_depth=6, rfc__n_estimators=51;, score=(train=0.752, test=0.728) total time=   0.1s\n",
      "[CV 1/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 1/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.758, test=0.728) total time=   0.2s\n",
      "[CV 2/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 2/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.753, test=0.722) total time=   0.2s\n",
      "[CV 3/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 3/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.747, test=0.731) total time=   0.2s\n",
      "[CV 4/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 4/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.756, test=0.739) total time=   0.2s\n",
      "[CV 5/5; 13/100] START rfc__max_depth=6, rfc__n_estimators=101..................\n",
      "[CV 5/5; 13/100] END rfc__max_depth=6, rfc__n_estimators=101;, score=(train=0.768, test=0.745) total time=   0.2s\n",
      "[CV 1/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 1/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.759, test=0.723) total time=   0.3s\n",
      "[CV 2/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 2/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.754, test=0.724) total time=   0.3s\n",
      "[CV 3/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 3/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.747, test=0.738) total time=   0.3s\n",
      "[CV 4/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 4/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.757, test=0.742) total time=   0.3s\n",
      "[CV 5/5; 14/100] START rfc__max_depth=6, rfc__n_estimators=151..................\n",
      "[CV 5/5; 14/100] END rfc__max_depth=6, rfc__n_estimators=151;, score=(train=0.764, test=0.738) total time=   0.3s\n",
      "[CV 1/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 1/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.754, test=0.730) total time=   0.4s\n",
      "[CV 2/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 2/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.753, test=0.719) total time=   0.4s\n",
      "[CV 3/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 3/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.748, test=0.735) total time=   0.4s\n",
      "[CV 4/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 4/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.758, test=0.746) total time=   0.4s\n",
      "[CV 5/5; 15/100] START rfc__max_depth=6, rfc__n_estimators=201..................\n",
      "[CV 5/5; 15/100] END rfc__max_depth=6, rfc__n_estimators=201;, score=(train=0.762, test=0.736) total time=   0.4s\n",
      "[CV 1/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 1/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.755, test=0.727) total time=   0.5s\n",
      "[CV 2/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 2/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.745, test=0.719) total time=   0.5s\n",
      "[CV 3/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 3/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.749, test=0.727) total time=   0.5s\n",
      "[CV 4/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 4/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.755, test=0.743) total time=   0.5s\n",
      "[CV 5/5; 16/100] START rfc__max_depth=6, rfc__n_estimators=251..................\n",
      "[CV 5/5; 16/100] END rfc__max_depth=6, rfc__n_estimators=251;, score=(train=0.761, test=0.734) total time=   0.5s\n",
      "[CV 1/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 1/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.756, test=0.728) total time=   0.6s\n",
      "[CV 2/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 2/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.745, test=0.721) total time=   0.6s\n",
      "[CV 3/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 3/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.751, test=0.723) total time=   0.6s\n",
      "[CV 4/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 4/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.753, test=0.745) total time=   0.6s\n",
      "[CV 5/5; 17/100] START rfc__max_depth=6, rfc__n_estimators=301..................\n",
      "[CV 5/5; 17/100] END rfc__max_depth=6, rfc__n_estimators=301;, score=(train=0.759, test=0.731) total time=   0.6s\n",
      "[CV 1/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 1/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.754, test=0.731) total time=   0.7s\n",
      "[CV 2/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 2/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.747, test=0.724) total time=   0.7s\n",
      "[CV 3/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 3/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.750, test=0.728) total time=   0.7s\n",
      "[CV 4/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 4/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.752, test=0.743) total time=   0.8s\n",
      "[CV 5/5; 18/100] START rfc__max_depth=6, rfc__n_estimators=351..................\n",
      "[CV 5/5; 18/100] END rfc__max_depth=6, rfc__n_estimators=351;, score=(train=0.761, test=0.729) total time=   0.7s\n",
      "[CV 1/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 1/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.752, test=0.727) total time=   0.8s\n",
      "[CV 2/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 2/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.747, test=0.728) total time=   0.8s\n",
      "[CV 3/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 3/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.748, test=0.723) total time=   0.8s\n",
      "[CV 4/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 4/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.753, test=0.742) total time=   0.8s\n",
      "[CV 5/5; 19/100] START rfc__max_depth=6, rfc__n_estimators=401..................\n",
      "[CV 5/5; 19/100] END rfc__max_depth=6, rfc__n_estimators=401;, score=(train=0.760, test=0.723) total time=   0.8s\n",
      "[CV 1/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 1/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.754, test=0.725) total time=   0.9s\n",
      "[CV 2/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 2/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.749, test=0.732) total time=   0.9s\n",
      "[CV 3/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 3/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.751, test=0.726) total time=   0.9s\n",
      "[CV 4/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 4/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.752, test=0.739) total time=   0.9s\n",
      "[CV 5/5; 20/100] START rfc__max_depth=6, rfc__n_estimators=451..................\n",
      "[CV 5/5; 20/100] END rfc__max_depth=6, rfc__n_estimators=451;, score=(train=0.759, test=0.728) total time=   0.9s\n",
      "[CV 1/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 1/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.678, test=0.694) total time=   0.0s\n",
      "[CV 2/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 2/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.683, test=0.692) total time=   0.0s\n",
      "[CV 3/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 3/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.674, test=0.655) total time=   0.0s\n",
      "[CV 4/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 4/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.416, test=0.389) total time=   0.0s\n",
      "[CV 5/5; 21/100] START rfc__max_depth=11, rfc__n_estimators=1...................\n",
      "[CV 5/5; 21/100] END rfc__max_depth=11, rfc__n_estimators=1;, score=(train=0.681, test=0.672) total time=   0.0s\n",
      "[CV 1/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 1/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.787, test=0.732) total time=   0.1s\n",
      "[CV 2/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 2/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.784, test=0.728) total time=   0.1s\n",
      "[CV 3/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 3/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.770, test=0.721) total time=   0.1s\n",
      "[CV 4/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 4/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.788, test=0.732) total time=   0.1s\n",
      "[CV 5/5; 22/100] START rfc__max_depth=11, rfc__n_estimators=51..................\n",
      "[CV 5/5; 22/100] END rfc__max_depth=11, rfc__n_estimators=51;, score=(train=0.788, test=0.739) total time=   0.1s\n",
      "[CV 1/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 1/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.795, test=0.737) total time=   0.3s\n",
      "[CV 2/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 2/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.791, test=0.723) total time=   0.3s\n",
      "[CV 3/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 3/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.786, test=0.737) total time=   0.3s\n",
      "[CV 4/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 4/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.796, test=0.739) total time=   0.3s\n",
      "[CV 5/5; 23/100] START rfc__max_depth=11, rfc__n_estimators=101.................\n",
      "[CV 5/5; 23/100] END rfc__max_depth=11, rfc__n_estimators=101;, score=(train=0.799, test=0.741) total time=   0.3s\n",
      "[CV 1/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 1/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.796, test=0.740) total time=   0.4s\n",
      "[CV 2/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 2/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.790, test=0.725) total time=   0.4s\n",
      "[CV 3/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 3/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.789, test=0.738) total time=   0.5s\n",
      "[CV 4/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 4/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.793, test=0.745) total time=   0.4s\n",
      "[CV 5/5; 24/100] START rfc__max_depth=11, rfc__n_estimators=151.................\n",
      "[CV 5/5; 24/100] END rfc__max_depth=11, rfc__n_estimators=151;, score=(train=0.800, test=0.742) total time=   0.4s\n",
      "[CV 1/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 1/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.796, test=0.734) total time=   0.6s\n",
      "[CV 2/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 2/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.791, test=0.729) total time=   0.6s\n",
      "[CV 3/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 3/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.797, test=0.742) total time=   0.6s\n",
      "[CV 4/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 4/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.799, test=0.741) total time=   0.6s\n",
      "[CV 5/5; 25/100] START rfc__max_depth=11, rfc__n_estimators=201.................\n",
      "[CV 5/5; 25/100] END rfc__max_depth=11, rfc__n_estimators=201;, score=(train=0.799, test=0.740) total time=   0.6s\n",
      "[CV 1/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 1/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.796, test=0.733) total time=   0.8s\n",
      "[CV 2/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 2/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.788, test=0.724) total time=   0.8s\n",
      "[CV 3/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 3/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.797, test=0.742) total time=   0.8s\n",
      "[CV 4/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 4/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.800, test=0.747) total time=   0.8s\n",
      "[CV 5/5; 26/100] START rfc__max_depth=11, rfc__n_estimators=251.................\n",
      "[CV 5/5; 26/100] END rfc__max_depth=11, rfc__n_estimators=251;, score=(train=0.799, test=0.745) total time=   0.8s\n",
      "[CV 1/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 1/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.796, test=0.735) total time=   0.9s\n",
      "[CV 2/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 2/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.788, test=0.724) total time=   0.9s\n",
      "[CV 3/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 3/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.799, test=0.742) total time=   1.0s\n",
      "[CV 4/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 4/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.799, test=0.751) total time=   0.9s\n",
      "[CV 5/5; 27/100] START rfc__max_depth=11, rfc__n_estimators=301.................\n",
      "[CV 5/5; 27/100] END rfc__max_depth=11, rfc__n_estimators=301;, score=(train=0.800, test=0.742) total time=   1.0s\n",
      "[CV 1/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 1/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.798, test=0.735) total time=   1.2s\n",
      "[CV 2/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 2/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.790, test=0.724) total time=   1.1s\n",
      "[CV 3/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 3/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.800, test=0.739) total time=   1.2s\n",
      "[CV 4/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 4/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.801, test=0.748) total time=   1.1s\n",
      "[CV 5/5; 28/100] START rfc__max_depth=11, rfc__n_estimators=351.................\n",
      "[CV 5/5; 28/100] END rfc__max_depth=11, rfc__n_estimators=351;, score=(train=0.799, test=0.742) total time=   1.2s\n",
      "[CV 1/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 1/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.799, test=0.737) total time=   1.4s\n",
      "[CV 2/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 2/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.793, test=0.726) total time=   1.3s\n",
      "[CV 3/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 3/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.800, test=0.740) total time=   1.3s\n",
      "[CV 4/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 4/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.801, test=0.751) total time=   1.2s\n",
      "[CV 5/5; 29/100] START rfc__max_depth=11, rfc__n_estimators=401.................\n",
      "[CV 5/5; 29/100] END rfc__max_depth=11, rfc__n_estimators=401;, score=(train=0.803, test=0.745) total time=   1.2s\n",
      "[CV 1/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 1/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.798, test=0.736) total time=   1.4s\n",
      "[CV 2/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 2/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.792, test=0.729) total time=   1.4s\n",
      "[CV 3/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 3/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.800, test=0.742) total time=   1.4s\n",
      "[CV 4/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 4/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.801, test=0.752) total time=   1.4s\n",
      "[CV 5/5; 30/100] START rfc__max_depth=11, rfc__n_estimators=451.................\n",
      "[CV 5/5; 30/100] END rfc__max_depth=11, rfc__n_estimators=451;, score=(train=0.802, test=0.743) total time=   1.4s\n",
      "[CV 1/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 1/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.697, test=0.703) total time=   0.0s\n",
      "[CV 2/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 2/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.696, test=0.703) total time=   0.0s\n",
      "[CV 3/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 3/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.678, test=0.655) total time=   0.0s\n",
      "[CV 4/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 4/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.425, test=0.386) total time=   0.0s\n",
      "[CV 5/5; 31/100] START rfc__max_depth=16, rfc__n_estimators=1...................\n",
      "[CV 5/5; 31/100] END rfc__max_depth=16, rfc__n_estimators=1;, score=(train=0.692, test=0.672) total time=   0.0s\n",
      "[CV 1/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 1/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.822, test=0.741) total time=   0.2s\n",
      "[CV 2/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 2/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.810, test=0.729) total time=   0.2s\n",
      "[CV 3/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 3/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.812, test=0.731) total time=   0.2s\n",
      "[CV 4/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 4/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.833, test=0.751) total time=   0.2s\n",
      "[CV 5/5; 32/100] START rfc__max_depth=16, rfc__n_estimators=51..................\n",
      "[CV 5/5; 32/100] END rfc__max_depth=16, rfc__n_estimators=51;, score=(train=0.818, test=0.742) total time=   0.2s\n",
      "[CV 1/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 1/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.828, test=0.740) total time=   0.4s\n",
      "[CV 2/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 2/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.819, test=0.732) total time=   0.4s\n",
      "[CV 3/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 3/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.828, test=0.743) total time=   0.4s\n",
      "[CV 4/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 4/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.837, test=0.763) total time=   0.4s\n",
      "[CV 5/5; 33/100] START rfc__max_depth=16, rfc__n_estimators=101.................\n",
      "[CV 5/5; 33/100] END rfc__max_depth=16, rfc__n_estimators=101;, score=(train=0.827, test=0.742) total time=   0.4s\n",
      "[CV 1/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 1/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.830, test=0.735) total time=   0.6s\n",
      "[CV 2/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 2/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.823, test=0.731) total time=   0.6s\n",
      "[CV 3/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 3/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.835, test=0.750) total time=   0.6s\n",
      "[CV 4/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 4/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.834, test=0.766) total time=   0.6s\n",
      "[CV 5/5; 34/100] START rfc__max_depth=16, rfc__n_estimators=151.................\n",
      "[CV 5/5; 34/100] END rfc__max_depth=16, rfc__n_estimators=151;, score=(train=0.836, test=0.752) total time=   0.6s\n",
      "[CV 1/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 1/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.835, test=0.738) total time=   0.9s\n",
      "[CV 2/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 2/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.825, test=0.728) total time=   0.8s\n",
      "[CV 3/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 3/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.836, test=0.756) total time=   0.9s\n",
      "[CV 4/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 4/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.835, test=0.764) total time=   0.8s\n",
      "[CV 5/5; 35/100] START rfc__max_depth=16, rfc__n_estimators=201.................\n",
      "[CV 5/5; 35/100] END rfc__max_depth=16, rfc__n_estimators=201;, score=(train=0.841, test=0.754) total time=   0.8s\n",
      "[CV 1/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 1/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.836, test=0.738) total time=   1.1s\n",
      "[CV 2/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 2/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.824, test=0.729) total time=   1.1s\n",
      "[CV 3/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 3/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.836, test=0.751) total time=   1.1s\n",
      "[CV 4/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 4/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.837, test=0.759) total time=   1.1s\n",
      "[CV 5/5; 36/100] START rfc__max_depth=16, rfc__n_estimators=251.................\n",
      "[CV 5/5; 36/100] END rfc__max_depth=16, rfc__n_estimators=251;, score=(train=0.838, test=0.748) total time=   1.0s\n",
      "[CV 1/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 1/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.835, test=0.741) total time=   1.3s\n",
      "[CV 2/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 2/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.826, test=0.731) total time=   1.3s\n",
      "[CV 3/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 3/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.839, test=0.752) total time=   1.3s\n",
      "[CV 4/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 4/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.840, test=0.762) total time=   1.3s\n",
      "[CV 5/5; 37/100] START rfc__max_depth=16, rfc__n_estimators=301.................\n",
      "[CV 5/5; 37/100] END rfc__max_depth=16, rfc__n_estimators=301;, score=(train=0.837, test=0.753) total time=   1.2s\n",
      "[CV 1/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 1/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.834, test=0.741) total time=   1.5s\n",
      "[CV 2/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 2/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.828, test=0.732) total time=   1.5s\n",
      "[CV 3/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 3/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.838, test=0.760) total time=   1.5s\n",
      "[CV 4/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 4/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.838, test=0.757) total time=   1.5s\n",
      "[CV 5/5; 38/100] START rfc__max_depth=16, rfc__n_estimators=351.................\n",
      "[CV 5/5; 38/100] END rfc__max_depth=16, rfc__n_estimators=351;, score=(train=0.840, test=0.753) total time=   1.5s\n",
      "[CV 1/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 1/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.834, test=0.738) total time=   1.7s\n",
      "[CV 2/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 2/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.828, test=0.733) total time=   1.7s\n",
      "[CV 3/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 3/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.838, test=0.756) total time=   1.7s\n",
      "[CV 4/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 4/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.838, test=0.755) total time=   1.7s\n",
      "[CV 5/5; 39/100] START rfc__max_depth=16, rfc__n_estimators=401.................\n",
      "[CV 5/5; 39/100] END rfc__max_depth=16, rfc__n_estimators=401;, score=(train=0.842, test=0.754) total time=   1.7s\n",
      "[CV 1/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 1/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.832, test=0.742) total time=   2.0s\n",
      "[CV 2/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 2/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.828, test=0.734) total time=   1.9s\n",
      "[CV 3/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 3/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.838, test=0.753) total time=   1.9s\n",
      "[CV 4/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 4/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.837, test=0.757) total time=   1.9s\n",
      "[CV 5/5; 40/100] START rfc__max_depth=16, rfc__n_estimators=451.................\n",
      "[CV 5/5; 40/100] END rfc__max_depth=16, rfc__n_estimators=451;, score=(train=0.841, test=0.752) total time=   1.9s\n",
      "[CV 1/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 1/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.696, test=0.686) total time=   0.0s\n",
      "[CV 2/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 2/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.692, test=0.691) total time=   0.0s\n",
      "[CV 3/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 3/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.676, test=0.648) total time=   0.0s\n",
      "[CV 4/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 4/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.464, test=0.413) total time=   0.0s\n",
      "[CV 5/5; 41/100] START rfc__max_depth=21, rfc__n_estimators=1...................\n",
      "[CV 5/5; 41/100] END rfc__max_depth=21, rfc__n_estimators=1;, score=(train=0.696, test=0.675) total time=   0.0s\n",
      "[CV 1/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 1/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.847, test=0.743) total time=   0.3s\n",
      "[CV 2/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 2/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.834, test=0.745) total time=   0.2s\n",
      "[CV 3/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 3/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.848, test=0.761) total time=   0.2s\n",
      "[CV 4/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 4/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.853, test=0.760) total time=   0.2s\n",
      "[CV 5/5; 42/100] START rfc__max_depth=21, rfc__n_estimators=51..................\n",
      "[CV 5/5; 42/100] END rfc__max_depth=21, rfc__n_estimators=51;, score=(train=0.849, test=0.751) total time=   0.2s\n",
      "[CV 1/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 1/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.851, test=0.740) total time=   0.5s\n",
      "[CV 2/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 2/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.845, test=0.738) total time=   0.5s\n",
      "[CV 3/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 3/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.867, test=0.769) total time=   0.5s\n",
      "[CV 4/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 4/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.859, test=0.759) total time=   0.5s\n",
      "[CV 5/5; 43/100] START rfc__max_depth=21, rfc__n_estimators=101.................\n",
      "[CV 5/5; 43/100] END rfc__max_depth=21, rfc__n_estimators=101;, score=(train=0.861, test=0.753) total time=   0.5s\n",
      "[CV 1/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 1/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.859, test=0.743) total time=   0.8s\n",
      "[CV 2/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 2/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.846, test=0.750) total time=   0.8s\n",
      "[CV 3/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 3/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.864, test=0.767) total time=   0.9s\n",
      "[CV 4/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 4/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.860, test=0.768) total time=   0.8s\n",
      "[CV 5/5; 44/100] START rfc__max_depth=21, rfc__n_estimators=151.................\n",
      "[CV 5/5; 44/100] END rfc__max_depth=21, rfc__n_estimators=151;, score=(train=0.863, test=0.756) total time=   0.8s\n",
      "[CV 1/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 1/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.859, test=0.741) total time=   1.2s\n",
      "[CV 2/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 2/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.848, test=0.743) total time=   1.1s\n",
      "[CV 3/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 3/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.865, test=0.762) total time=   1.1s\n",
      "[CV 4/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 4/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.859, test=0.772) total time=   1.1s\n",
      "[CV 5/5; 45/100] START rfc__max_depth=21, rfc__n_estimators=201.................\n",
      "[CV 5/5; 45/100] END rfc__max_depth=21, rfc__n_estimators=201;, score=(train=0.865, test=0.761) total time=   1.1s\n",
      "[CV 1/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 1/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.863, test=0.746) total time=   1.4s\n",
      "[CV 2/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 2/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.849, test=0.745) total time=   1.4s\n",
      "[CV 3/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 3/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.867, test=0.763) total time=   1.4s\n",
      "[CV 4/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 4/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.861, test=0.772) total time=   1.4s\n",
      "[CV 5/5; 46/100] START rfc__max_depth=21, rfc__n_estimators=251.................\n",
      "[CV 5/5; 46/100] END rfc__max_depth=21, rfc__n_estimators=251;, score=(train=0.867, test=0.760) total time=   1.4s\n",
      "[CV 1/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 1/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.860, test=0.746) total time=   1.7s\n",
      "[CV 2/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 2/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.849, test=0.745) total time=   1.7s\n",
      "[CV 3/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 3/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.868, test=0.765) total time=   1.7s\n",
      "[CV 4/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 4/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.861, test=0.769) total time=   1.7s\n",
      "[CV 5/5; 47/100] START rfc__max_depth=21, rfc__n_estimators=301.................\n",
      "[CV 5/5; 47/100] END rfc__max_depth=21, rfc__n_estimators=301;, score=(train=0.868, test=0.765) total time=   1.7s\n",
      "[CV 1/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 1/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.862, test=0.751) total time=   2.0s\n",
      "[CV 2/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 2/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.850, test=0.743) total time=   2.0s\n",
      "[CV 3/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 3/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.869, test=0.764) total time=   2.0s\n",
      "[CV 4/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 4/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.862, test=0.770) total time=   2.0s\n",
      "[CV 5/5; 48/100] START rfc__max_depth=21, rfc__n_estimators=351.................\n",
      "[CV 5/5; 48/100] END rfc__max_depth=21, rfc__n_estimators=351;, score=(train=0.868, test=0.766) total time=   1.9s\n",
      "[CV 1/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 1/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.861, test=0.749) total time=   2.3s\n",
      "[CV 2/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 2/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.852, test=0.746) total time=   2.3s\n",
      "[CV 3/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 3/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.869, test=0.767) total time=   2.3s\n",
      "[CV 4/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 4/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.860, test=0.771) total time=   2.3s\n",
      "[CV 5/5; 49/100] START rfc__max_depth=21, rfc__n_estimators=401.................\n",
      "[CV 5/5; 49/100] END rfc__max_depth=21, rfc__n_estimators=401;, score=(train=0.869, test=0.764) total time=   2.3s\n",
      "[CV 1/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 1/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.861, test=0.746) total time=   2.5s\n",
      "[CV 2/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 2/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.852, test=0.741) total time=   2.6s\n",
      "[CV 3/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 3/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.871, test=0.765) total time=   2.5s\n",
      "[CV 4/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 4/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.862, test=0.778) total time=   2.5s\n",
      "[CV 5/5; 50/100] START rfc__max_depth=21, rfc__n_estimators=451.................\n",
      "[CV 5/5; 50/100] END rfc__max_depth=21, rfc__n_estimators=451;, score=(train=0.871, test=0.765) total time=   2.5s\n",
      "[CV 1/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 1/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.701, test=0.684) total time=   0.0s\n",
      "[CV 2/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 2/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.702, test=0.682) total time=   0.0s\n",
      "[CV 3/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 3/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.688, test=0.647) total time=   0.0s\n",
      "[CV 4/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 4/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.484, test=0.421) total time=   0.0s\n",
      "[CV 5/5; 51/100] START rfc__max_depth=26, rfc__n_estimators=1...................\n",
      "[CV 5/5; 51/100] END rfc__max_depth=26, rfc__n_estimators=1;, score=(train=0.483, test=0.375) total time=   0.0s\n",
      "[CV 1/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 1/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.870, test=0.748) total time=   0.3s\n",
      "[CV 2/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 2/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.852, test=0.745) total time=   0.3s\n",
      "[CV 3/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 3/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.867, test=0.758) total time=   0.3s\n",
      "[CV 4/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 4/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.872, test=0.763) total time=   0.3s\n",
      "[CV 5/5; 52/100] START rfc__max_depth=26, rfc__n_estimators=51..................\n",
      "[CV 5/5; 52/100] END rfc__max_depth=26, rfc__n_estimators=51;, score=(train=0.877, test=0.758) total time=   0.3s\n",
      "[CV 1/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 1/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.874, test=0.752) total time=   0.7s\n",
      "[CV 2/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 2/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.864, test=0.749) total time=   0.7s\n",
      "[CV 3/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 3/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.882, test=0.766) total time=   0.7s\n",
      "[CV 4/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 4/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.878, test=0.782) total time=   0.7s\n",
      "[CV 5/5; 53/100] START rfc__max_depth=26, rfc__n_estimators=101.................\n",
      "[CV 5/5; 53/100] END rfc__max_depth=26, rfc__n_estimators=101;, score=(train=0.881, test=0.761) total time=   0.7s\n",
      "[CV 1/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 1/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.877, test=0.754) total time=   1.1s\n",
      "[CV 2/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 2/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.867, test=0.748) total time=   1.1s\n",
      "[CV 3/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 3/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.885, test=0.773) total time=   1.1s\n",
      "[CV 4/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 4/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.877, test=0.780) total time=   1.1s\n",
      "[CV 5/5; 54/100] START rfc__max_depth=26, rfc__n_estimators=151.................\n",
      "[CV 5/5; 54/100] END rfc__max_depth=26, rfc__n_estimators=151;, score=(train=0.887, test=0.766) total time=   1.0s\n",
      "[CV 1/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 1/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.880, test=0.759) total time=   1.4s\n",
      "[CV 2/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 2/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.868, test=0.751) total time=   1.4s\n",
      "[CV 3/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 3/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.887, test=0.772) total time=   1.4s\n",
      "[CV 4/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 4/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.878, test=0.786) total time=   1.4s\n",
      "[CV 5/5; 55/100] START rfc__max_depth=26, rfc__n_estimators=201.................\n",
      "[CV 5/5; 55/100] END rfc__max_depth=26, rfc__n_estimators=201;, score=(train=0.888, test=0.767) total time=   1.4s\n",
      "[CV 1/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 1/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.882, test=0.759) total time=   1.8s\n",
      "[CV 2/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 2/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.866, test=0.749) total time=   1.8s\n",
      "[CV 3/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 3/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.884, test=0.771) total time=   1.8s\n",
      "[CV 4/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 4/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.879, test=0.789) total time=   1.8s\n",
      "[CV 5/5; 56/100] START rfc__max_depth=26, rfc__n_estimators=251.................\n",
      "[CV 5/5; 56/100] END rfc__max_depth=26, rfc__n_estimators=251;, score=(train=0.887, test=0.768) total time=   1.8s\n",
      "[CV 1/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 1/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.882, test=0.759) total time=   2.2s\n",
      "[CV 2/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 2/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.869, test=0.747) total time=   2.2s\n",
      "[CV 3/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 3/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.885, test=0.770) total time=   2.1s\n",
      "[CV 4/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 4/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.878, test=0.782) total time=   2.1s\n",
      "[CV 5/5; 57/100] START rfc__max_depth=26, rfc__n_estimators=301.................\n",
      "[CV 5/5; 57/100] END rfc__max_depth=26, rfc__n_estimators=301;, score=(train=0.887, test=0.764) total time=   2.1s\n",
      "[CV 1/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 1/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.881, test=0.757) total time=   2.5s\n",
      "[CV 2/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 2/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.871, test=0.753) total time=   2.5s\n",
      "[CV 3/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 3/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.886, test=0.772) total time=   2.5s\n",
      "[CV 4/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 4/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.876, test=0.785) total time=   2.5s\n",
      "[CV 5/5; 58/100] START rfc__max_depth=26, rfc__n_estimators=351.................\n",
      "[CV 5/5; 58/100] END rfc__max_depth=26, rfc__n_estimators=351;, score=(train=0.888, test=0.773) total time=   2.5s\n",
      "[CV 1/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 1/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.880, test=0.761) total time=   2.9s\n",
      "[CV 2/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 2/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.870, test=0.752) total time=   2.9s\n",
      "[CV 3/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 3/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.888, test=0.776) total time=   2.9s\n",
      "[CV 4/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 4/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.878, test=0.782) total time=   2.8s\n",
      "[CV 5/5; 59/100] START rfc__max_depth=26, rfc__n_estimators=401.................\n",
      "[CV 5/5; 59/100] END rfc__max_depth=26, rfc__n_estimators=401;, score=(train=0.888, test=0.767) total time=   2.8s\n",
      "[CV 1/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 1/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.881, test=0.756) total time=   3.2s\n",
      "[CV 2/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 2/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.870, test=0.754) total time=   3.2s\n",
      "[CV 3/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 3/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.888, test=0.775) total time=   3.2s\n",
      "[CV 4/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 4/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.879, test=0.785) total time=   3.2s\n",
      "[CV 5/5; 60/100] START rfc__max_depth=26, rfc__n_estimators=451.................\n",
      "[CV 5/5; 60/100] END rfc__max_depth=26, rfc__n_estimators=451;, score=(train=0.889, test=0.766) total time=   3.2s\n",
      "[CV 1/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 1/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.708, test=0.678) total time=   0.0s\n",
      "[CV 2/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 2/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.707, test=0.686) total time=   0.0s\n",
      "[CV 3/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 3/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.711, test=0.664) total time=   0.0s\n",
      "[CV 4/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 4/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.713, test=0.682) total time=   0.0s\n",
      "[CV 5/5; 61/100] START rfc__max_depth=31, rfc__n_estimators=1...................\n",
      "[CV 5/5; 61/100] END rfc__max_depth=31, rfc__n_estimators=1;, score=(train=0.514, test=0.402) total time=   0.0s\n",
      "[CV 1/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 1/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.884, test=0.753) total time=   0.4s\n",
      "[CV 2/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 2/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.871, test=0.752) total time=   0.4s\n",
      "[CV 3/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 3/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.886, test=0.764) total time=   0.4s\n",
      "[CV 4/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 4/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.888, test=0.776) total time=   0.4s\n",
      "[CV 5/5; 62/100] START rfc__max_depth=31, rfc__n_estimators=51..................\n",
      "[CV 5/5; 62/100] END rfc__max_depth=31, rfc__n_estimators=51;, score=(train=0.887, test=0.762) total time=   0.4s\n",
      "[CV 1/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 1/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.885, test=0.760) total time=   0.8s\n",
      "[CV 2/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 2/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.878, test=0.759) total time=   0.8s\n",
      "[CV 3/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 3/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.897, test=0.783) total time=   0.8s\n",
      "[CV 4/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 4/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.893, test=0.782) total time=   0.9s\n",
      "[CV 5/5; 63/100] START rfc__max_depth=31, rfc__n_estimators=101.................\n",
      "[CV 5/5; 63/100] END rfc__max_depth=31, rfc__n_estimators=101;, score=(train=0.895, test=0.757) total time=   0.8s\n",
      "[CV 1/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 1/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.888, test=0.766) total time=   1.3s\n",
      "[CV 2/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 2/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.881, test=0.758) total time=   1.3s\n",
      "[CV 3/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 3/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.897, test=0.783) total time=   1.3s\n",
      "[CV 4/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 4/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.894, test=0.785) total time=   1.3s\n",
      "[CV 5/5; 64/100] START rfc__max_depth=31, rfc__n_estimators=151.................\n",
      "[CV 5/5; 64/100] END rfc__max_depth=31, rfc__n_estimators=151;, score=(train=0.899, test=0.759) total time=   1.9s\n",
      "[CV 1/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 1/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.895, test=0.772) total time=   1.8s\n",
      "[CV 2/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 2/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.883, test=0.766) total time=   1.8s\n",
      "[CV 3/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 3/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.897, test=0.791) total time=   1.8s\n",
      "[CV 4/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 4/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.894, test=0.782) total time=   1.8s\n",
      "[CV 5/5; 65/100] START rfc__max_depth=31, rfc__n_estimators=201.................\n",
      "[CV 5/5; 65/100] END rfc__max_depth=31, rfc__n_estimators=201;, score=(train=0.899, test=0.770) total time=   1.8s\n",
      "[CV 1/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 1/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.896, test=0.770) total time=   2.3s\n",
      "[CV 2/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 2/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.882, test=0.764) total time=   2.3s\n",
      "[CV 3/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 3/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.896, test=0.788) total time=   2.3s\n",
      "[CV 4/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 4/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.895, test=0.788) total time=   2.3s\n",
      "[CV 5/5; 66/100] START rfc__max_depth=31, rfc__n_estimators=251.................\n",
      "[CV 5/5; 66/100] END rfc__max_depth=31, rfc__n_estimators=251;, score=(train=0.899, test=0.770) total time=   2.3s\n",
      "[CV 1/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 1/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.895, test=0.767) total time=   2.7s\n",
      "[CV 2/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 2/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.882, test=0.766) total time=   2.7s\n",
      "[CV 3/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 3/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.899, test=0.787) total time=   2.8s\n",
      "[CV 4/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 4/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.892, test=0.787) total time=   2.8s\n",
      "[CV 5/5; 67/100] START rfc__max_depth=31, rfc__n_estimators=301.................\n",
      "[CV 5/5; 67/100] END rfc__max_depth=31, rfc__n_estimators=301;, score=(train=0.900, test=0.769) total time=   2.7s\n",
      "[CV 1/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 1/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.895, test=0.769) total time=   3.2s\n",
      "[CV 2/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 2/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.885, test=0.766) total time=   3.2s\n",
      "[CV 3/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 3/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.901, test=0.790) total time=   3.2s\n",
      "[CV 4/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 4/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.893, test=0.790) total time=   3.3s\n",
      "[CV 5/5; 68/100] START rfc__max_depth=31, rfc__n_estimators=351.................\n",
      "[CV 5/5; 68/100] END rfc__max_depth=31, rfc__n_estimators=351;, score=(train=0.903, test=0.770) total time=   3.2s\n",
      "[CV 1/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 1/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.894, test=0.769) total time=   3.7s\n",
      "[CV 2/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 2/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.885, test=0.764) total time=   3.7s\n",
      "[CV 3/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 3/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.900, test=0.790) total time=   3.6s\n",
      "[CV 4/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 4/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.892, test=0.786) total time=   3.7s\n",
      "[CV 5/5; 69/100] START rfc__max_depth=31, rfc__n_estimators=401.................\n",
      "[CV 5/5; 69/100] END rfc__max_depth=31, rfc__n_estimators=401;, score=(train=0.902, test=0.774) total time=   3.6s\n",
      "[CV 1/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 1/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.896, test=0.767) total time=   4.1s\n",
      "[CV 2/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 2/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.884, test=0.764) total time=   4.1s\n",
      "[CV 3/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 3/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.900, test=0.785) total time=   4.0s\n",
      "[CV 4/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 4/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.892, test=0.790) total time=   4.1s\n",
      "[CV 5/5; 70/100] START rfc__max_depth=31, rfc__n_estimators=451.................\n",
      "[CV 5/5; 70/100] END rfc__max_depth=31, rfc__n_estimators=451;, score=(train=0.903, test=0.776) total time=   4.0s\n",
      "[CV 1/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 1/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.712, test=0.675) total time=   0.0s\n",
      "[CV 2/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 2/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.713, test=0.680) total time=   0.0s\n",
      "[CV 3/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 3/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.713, test=0.665) total time=   0.0s\n",
      "[CV 4/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 4/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.733, test=0.695) total time=   0.0s\n",
      "[CV 5/5; 71/100] START rfc__max_depth=36, rfc__n_estimators=1...................\n",
      "[CV 5/5; 71/100] END rfc__max_depth=36, rfc__n_estimators=1;, score=(train=0.510, test=0.392) total time=   0.0s\n",
      "[CV 1/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 1/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.896, test=0.768) total time=   0.5s\n",
      "[CV 2/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 2/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.890, test=0.753) total time=   0.5s\n",
      "[CV 3/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 3/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.896, test=0.772) total time=   0.5s\n",
      "[CV 4/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 4/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.897, test=0.774) total time=   0.5s\n",
      "[CV 5/5; 72/100] START rfc__max_depth=36, rfc__n_estimators=51..................\n",
      "[CV 5/5; 72/100] END rfc__max_depth=36, rfc__n_estimators=51;, score=(train=0.902, test=0.771) total time=   0.5s\n",
      "[CV 1/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 1/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.897, test=0.776) total time=   1.1s\n",
      "[CV 2/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 2/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.896, test=0.765) total time=   1.1s\n",
      "[CV 3/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 3/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.905, test=0.779) total time=   1.1s\n",
      "[CV 4/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 4/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.902, test=0.778) total time=   1.1s\n",
      "[CV 5/5; 73/100] START rfc__max_depth=36, rfc__n_estimators=101.................\n",
      "[CV 5/5; 73/100] END rfc__max_depth=36, rfc__n_estimators=101;, score=(train=0.908, test=0.761) total time=   1.0s\n",
      "[CV 1/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 1/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.903, test=0.769) total time=   1.6s\n",
      "[CV 2/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 2/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.896, test=0.773) total time=   1.6s\n",
      "[CV 3/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 3/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.908, test=0.787) total time=   1.6s\n",
      "[CV 4/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 4/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.904, test=0.791) total time=   1.6s\n",
      "[CV 5/5; 74/100] START rfc__max_depth=36, rfc__n_estimators=151.................\n",
      "[CV 5/5; 74/100] END rfc__max_depth=36, rfc__n_estimators=151;, score=(train=0.912, test=0.767) total time=   1.6s\n",
      "[CV 1/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 1/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.909, test=0.770) total time=   2.2s\n",
      "[CV 2/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 2/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.897, test=0.769) total time=   2.1s\n",
      "[CV 3/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 3/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.910, test=0.791) total time=   2.1s\n",
      "[CV 4/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 4/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.903, test=0.794) total time=   2.1s\n",
      "[CV 5/5; 75/100] START rfc__max_depth=36, rfc__n_estimators=201.................\n",
      "[CV 5/5; 75/100] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.915, test=0.768) total time=   2.1s\n",
      "[CV 1/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 1/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.910, test=0.772) total time=   2.7s\n",
      "[CV 2/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 2/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.897, test=0.768) total time=   2.7s\n",
      "[CV 3/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 3/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.908, test=0.790) total time=   2.7s\n",
      "[CV 4/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 4/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.902, test=0.794) total time=   2.7s\n",
      "[CV 5/5; 76/100] START rfc__max_depth=36, rfc__n_estimators=251.................\n",
      "[CV 5/5; 76/100] END rfc__max_depth=36, rfc__n_estimators=251;, score=(train=0.915, test=0.766) total time=   2.7s\n",
      "[CV 1/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 1/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.909, test=0.773) total time=   3.2s\n",
      "[CV 2/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 2/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.896, test=0.768) total time=   3.2s\n",
      "[CV 3/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 3/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.911, test=0.795) total time=   3.2s\n",
      "[CV 4/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 4/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.902, test=0.792) total time=   3.2s\n",
      "[CV 5/5; 77/100] START rfc__max_depth=36, rfc__n_estimators=301.................\n",
      "[CV 5/5; 77/100] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.916, test=0.768) total time=   3.1s\n",
      "[CV 1/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 1/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.907, test=0.775) total time=   3.7s\n",
      "[CV 2/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 2/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.896, test=0.769) total time=   3.8s\n",
      "[CV 3/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 3/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.910, test=0.796) total time=   3.7s\n",
      "[CV 4/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 4/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.903, test=0.793) total time=   4.0s\n",
      "[CV 5/5; 78/100] START rfc__max_depth=36, rfc__n_estimators=351.................\n",
      "[CV 5/5; 78/100] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.914, test=0.770) total time=   3.7s\n",
      "[CV 1/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 1/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.908, test=0.779) total time=   4.2s\n",
      "[CV 2/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 2/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.897, test=0.769) total time=   4.3s\n",
      "[CV 3/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 3/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.910, test=0.793) total time=   4.2s\n",
      "[CV 4/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 4/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.904, test=0.794) total time=   4.4s\n",
      "[CV 5/5; 79/100] START rfc__max_depth=36, rfc__n_estimators=401.................\n",
      "[CV 5/5; 79/100] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.915, test=0.770) total time=   4.4s\n",
      "[CV 1/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 1/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.908, test=0.773) total time=   4.8s\n",
      "[CV 2/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 2/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.896, test=0.772) total time=   4.8s\n",
      "[CV 3/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 3/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.911, test=0.795) total time=   4.7s\n",
      "[CV 4/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 4/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.903, test=0.791) total time=   4.8s\n",
      "[CV 5/5; 80/100] START rfc__max_depth=36, rfc__n_estimators=451.................\n",
      "[CV 5/5; 80/100] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.916, test=0.770) total time=   4.7s\n",
      "[CV 1/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 1/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.735, test=0.689) total time=   0.0s\n",
      "[CV 2/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 2/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.718, test=0.682) total time=   0.0s\n",
      "[CV 3/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 3/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.723, test=0.660) total time=   0.0s\n",
      "[CV 4/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 4/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.728, test=0.678) total time=   0.0s\n",
      "[CV 5/5; 81/100] START rfc__max_depth=41, rfc__n_estimators=1...................\n",
      "[CV 5/5; 81/100] END rfc__max_depth=41, rfc__n_estimators=1;, score=(train=0.732, test=0.664) total time=   0.0s\n",
      "[CV 1/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 1/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.903, test=0.760) total time=   0.6s\n",
      "[CV 2/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 2/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.897, test=0.761) total time=   0.6s\n",
      "[CV 3/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 3/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.908, test=0.779) total time=   0.6s\n",
      "[CV 4/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 4/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.912, test=0.782) total time=   0.6s\n",
      "[CV 5/5; 82/100] START rfc__max_depth=41, rfc__n_estimators=51..................\n",
      "[CV 5/5; 82/100] END rfc__max_depth=41, rfc__n_estimators=51;, score=(train=0.916, test=0.770) total time=   0.6s\n",
      "[CV 1/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 1/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.910, test=0.764) total time=   1.2s\n",
      "[CV 2/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 2/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.902, test=0.772) total time=   1.2s\n",
      "[CV 3/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 3/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.917, test=0.786) total time=   1.2s\n",
      "[CV 4/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 4/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.915, test=0.787) total time=   1.2s\n",
      "[CV 5/5; 83/100] START rfc__max_depth=41, rfc__n_estimators=101.................\n",
      "[CV 5/5; 83/100] END rfc__max_depth=41, rfc__n_estimators=101;, score=(train=0.918, test=0.772) total time=   1.2s\n",
      "[CV 1/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 1/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.915, test=0.762) total time=   1.8s\n",
      "[CV 2/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 2/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.906, test=0.771) total time=   1.9s\n",
      "[CV 3/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 3/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.916, test=0.796) total time=   1.8s\n",
      "[CV 4/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 4/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.916, test=0.793) total time=   1.9s\n",
      "[CV 5/5; 84/100] START rfc__max_depth=41, rfc__n_estimators=151.................\n",
      "[CV 5/5; 84/100] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.921, test=0.775) total time=   1.9s\n",
      "[CV 1/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 1/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.920, test=0.773) total time=   2.4s\n",
      "[CV 2/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 2/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.907, test=0.774) total time=   2.5s\n",
      "[CV 3/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 3/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.920, test=0.799) total time=   2.5s\n",
      "[CV 4/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 4/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.915, test=0.796) total time=   2.5s\n",
      "[CV 5/5; 85/100] START rfc__max_depth=41, rfc__n_estimators=201.................\n",
      "[CV 5/5; 85/100] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.923, test=0.777) total time=   2.5s\n",
      "[CV 1/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 1/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.920, test=0.769) total time=   3.0s\n",
      "[CV 2/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 2/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.908, test=0.771) total time=   3.1s\n",
      "[CV 3/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 3/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.921, test=0.798) total time=   3.1s\n",
      "[CV 4/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 4/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.913, test=0.797) total time=   3.1s\n",
      "[CV 5/5; 86/100] START rfc__max_depth=41, rfc__n_estimators=251.................\n",
      "[CV 5/5; 86/100] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.924, test=0.776) total time=   3.1s\n",
      "[CV 1/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 1/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.920, test=0.771) total time=   3.7s\n",
      "[CV 2/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 2/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.910, test=0.771) total time=   3.8s\n",
      "[CV 3/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 3/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.922, test=0.799) total time=   3.8s\n",
      "[CV 4/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 4/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.914, test=0.798) total time=   3.7s\n",
      "[CV 5/5; 87/100] START rfc__max_depth=41, rfc__n_estimators=301.................\n",
      "[CV 5/5; 87/100] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.923, test=0.775) total time=   3.7s\n",
      "[CV 1/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 1/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.918, test=0.772) total time=   4.3s\n",
      "[CV 2/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 2/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.909, test=0.769) total time=   4.3s\n",
      "[CV 3/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 3/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.921, test=0.798) total time=   4.3s\n",
      "[CV 4/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 4/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.913, test=0.796) total time=   4.3s\n",
      "[CV 5/5; 88/100] START rfc__max_depth=41, rfc__n_estimators=351.................\n",
      "[CV 5/5; 88/100] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.923, test=0.775) total time=   4.3s\n",
      "[CV 1/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 1/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.919, test=0.776) total time=   4.8s\n",
      "[CV 2/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 2/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.910, test=0.772) total time=   4.9s\n",
      "[CV 3/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 3/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.922, test=0.801) total time=   4.9s\n",
      "[CV 4/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 4/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.915, test=0.797) total time=   5.0s\n",
      "[CV 5/5; 89/100] START rfc__max_depth=41, rfc__n_estimators=401.................\n",
      "[CV 5/5; 89/100] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.923, test=0.774) total time=   4.9s\n",
      "[CV 1/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 1/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.920, test=0.771) total time=   5.5s\n",
      "[CV 2/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 2/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.910, test=0.775) total time=   5.6s\n",
      "[CV 3/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 3/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.920, test=0.800) total time=   5.5s\n",
      "[CV 4/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 4/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.915, test=0.798) total time=   5.6s\n",
      "[CV 5/5; 90/100] START rfc__max_depth=41, rfc__n_estimators=451.................\n",
      "[CV 5/5; 90/100] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.923, test=0.776) total time=   5.5s\n",
      "[CV 1/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 1/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.735, test=0.678) total time=   0.0s\n",
      "[CV 2/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 2/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.741, test=0.702) total time=   0.0s\n",
      "[CV 3/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 3/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.731, test=0.645) total time=   0.0s\n",
      "[CV 4/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 4/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.746, test=0.699) total time=   0.0s\n",
      "[CV 5/5; 91/100] START rfc__max_depth=46, rfc__n_estimators=1...................\n",
      "[CV 5/5; 91/100] END rfc__max_depth=46, rfc__n_estimators=1;, score=(train=0.736, test=0.665) total time=   0.0s\n",
      "[CV 1/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 1/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.918, test=0.763) total time=   0.7s\n",
      "[CV 2/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 2/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.911, test=0.781) total time=   0.7s\n",
      "[CV 3/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 3/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.919, test=0.771) total time=   0.7s\n",
      "[CV 4/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 4/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.921, test=0.781) total time=   0.7s\n",
      "[CV 5/5; 92/100] START rfc__max_depth=46, rfc__n_estimators=51..................\n",
      "[CV 5/5; 92/100] END rfc__max_depth=46, rfc__n_estimators=51;, score=(train=0.927, test=0.770) total time=   0.7s\n",
      "[CV 1/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 1/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.922, test=0.771) total time=   1.4s\n",
      "[CV 2/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 2/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.914, test=0.773) total time=   1.4s\n",
      "[CV 3/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 3/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.926, test=0.794) total time=   1.4s\n",
      "[CV 4/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 4/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.922, test=0.794) total time=   1.4s\n",
      "[CV 5/5; 93/100] START rfc__max_depth=46, rfc__n_estimators=101.................\n",
      "[CV 5/5; 93/100] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.928, test=0.772) total time=   1.4s\n",
      "[CV 1/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 1/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.926, test=0.771) total time=   2.1s\n",
      "[CV 2/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 2/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.915, test=0.768) total time=   2.1s\n",
      "[CV 3/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 3/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.927, test=0.796) total time=   2.1s\n",
      "[CV 4/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 4/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.924, test=0.797) total time=   2.1s\n",
      "[CV 5/5; 94/100] START rfc__max_depth=46, rfc__n_estimators=151.................\n",
      "[CV 5/5; 94/100] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.929, test=0.782) total time=   2.1s\n",
      "[CV 1/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 1/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.930, test=0.768) total time=   2.8s\n",
      "[CV 2/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 2/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.918, test=0.777) total time=   2.8s\n",
      "[CV 3/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 3/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.928, test=0.801) total time=   2.7s\n",
      "[CV 4/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 4/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.923, test=0.802) total time=   2.8s\n",
      "[CV 5/5; 95/100] START rfc__max_depth=46, rfc__n_estimators=201.................\n",
      "[CV 5/5; 95/100] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.933, test=0.788) total time=   2.8s\n",
      "[CV 1/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 1/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.930, test=0.776) total time=   3.7s\n",
      "[CV 2/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 2/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.918, test=0.773) total time=   3.5s\n",
      "[CV 3/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 3/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.929, test=0.801) total time=   3.4s\n",
      "[CV 4/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 4/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.922, test=0.803) total time=   3.5s\n",
      "[CV 5/5; 96/100] START rfc__max_depth=46, rfc__n_estimators=251.................\n",
      "[CV 5/5; 96/100] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.933, test=0.786) total time=   3.4s\n",
      "[CV 1/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 1/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.930, test=0.773) total time=   4.1s\n",
      "[CV 2/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 2/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.918, test=0.776) total time=   4.2s\n",
      "[CV 3/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 3/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.929, test=0.801) total time=   4.2s\n",
      "[CV 4/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 4/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.922, test=0.797) total time=   4.2s\n",
      "[CV 5/5; 97/100] START rfc__max_depth=46, rfc__n_estimators=301.................\n",
      "[CV 5/5; 97/100] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.932, test=0.782) total time=   4.1s\n",
      "[CV 1/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 1/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.929, test=0.772) total time=   4.8s\n",
      "[CV 2/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 2/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.919, test=0.774) total time=   4.9s\n",
      "[CV 3/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 3/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.929, test=0.802) total time=   4.8s\n",
      "[CV 4/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 4/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.921, test=0.798) total time=   4.9s\n",
      "[CV 5/5; 98/100] START rfc__max_depth=46, rfc__n_estimators=351.................\n",
      "[CV 5/5; 98/100] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.932, test=0.783) total time=   4.8s\n",
      "[CV 1/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 1/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.930, test=0.773) total time=   5.5s\n",
      "[CV 2/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 2/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.920, test=0.776) total time=   5.7s\n",
      "[CV 3/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 3/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.929, test=0.798) total time=   5.5s\n",
      "[CV 4/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 4/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.922, test=0.802) total time=   5.7s\n",
      "[CV 5/5; 99/100] START rfc__max_depth=46, rfc__n_estimators=401.................\n",
      "[CV 5/5; 99/100] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.932, test=0.782) total time=   5.5s\n",
      "[CV 1/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 1/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.930, test=0.770) total time=   6.2s\n",
      "[CV 2/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 2/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.919, test=0.775) total time=   6.3s\n",
      "[CV 3/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 3/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.929, test=0.798) total time=   6.3s\n",
      "[CV 4/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 4/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.923, test=0.801) total time=   6.3s\n",
      "[CV 5/5; 100/100] START rfc__max_depth=46, rfc__n_estimators=451................\n",
      "[CV 5/5; 100/100] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.932, test=0.787) total time=   6.3s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 20\n",
      "n_resources: 27660\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5; 1/20] START rfc__max_depth=36, rfc__n_estimators=201...................\n",
      "[CV 1/5; 1/20] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.887, test=0.807) total time=   8.9s\n",
      "[CV 2/5; 1/20] START rfc__max_depth=36, rfc__n_estimators=201...................\n",
      "[CV 2/5; 1/20] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.882, test=0.796) total time=   9.0s\n",
      "[CV 3/5; 1/20] START rfc__max_depth=36, rfc__n_estimators=201...................\n",
      "[CV 3/5; 1/20] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.885, test=0.805) total time=   8.9s\n",
      "[CV 4/5; 1/20] START rfc__max_depth=36, rfc__n_estimators=201...................\n",
      "[CV 4/5; 1/20] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.881, test=0.803) total time=   9.1s\n",
      "[CV 5/5; 1/20] START rfc__max_depth=36, rfc__n_estimators=201...................\n",
      "[CV 5/5; 1/20] END rfc__max_depth=36, rfc__n_estimators=201;, score=(train=0.886, test=0.809) total time=   8.9s\n",
      "[CV 1/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 1/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.887, test=0.804) total time=  13.4s\n",
      "[CV 2/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 2/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.885, test=0.798) total time=  13.4s\n",
      "[CV 3/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 3/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.885, test=0.805) total time=  13.3s\n",
      "[CV 4/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 4/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.884, test=0.807) total time=  13.7s\n",
      "[CV 5/5; 2/20] START rfc__max_depth=36, rfc__n_estimators=301...................\n",
      "[CV 5/5; 2/20] END rfc__max_depth=36, rfc__n_estimators=301;, score=(train=0.885, test=0.810) total time=  13.3s\n",
      "[CV 1/5; 3/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 1/5; 3/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.899, test=0.821) total time=   7.7s\n",
      "[CV 2/5; 3/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 2/5; 3/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.895, test=0.811) total time=   8.0s\n",
      "[CV 3/5; 3/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 3/5; 3/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.896, test=0.814) total time=   7.8s\n",
      "[CV 4/5; 3/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 4/5; 3/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.896, test=0.819) total time=   7.9s\n",
      "[CV 5/5; 3/20] START rfc__max_depth=41, rfc__n_estimators=151...................\n",
      "[CV 5/5; 3/20] END rfc__max_depth=41, rfc__n_estimators=151;, score=(train=0.892, test=0.817) total time=   7.8s\n",
      "[CV 1/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 1/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.888, test=0.805) total time=  19.6s\n",
      "[CV 2/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 2/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.884, test=0.799) total time=  20.3s\n",
      "[CV 3/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 3/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.884, test=0.803) total time=  20.1s\n",
      "[CV 4/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 4/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.886, test=0.811) total time=  20.5s\n",
      "[CV 5/5; 4/20] START rfc__max_depth=36, rfc__n_estimators=451...................\n",
      "[CV 5/5; 4/20] END rfc__max_depth=36, rfc__n_estimators=451;, score=(train=0.886, test=0.810) total time=  19.8s\n",
      "[CV 1/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 1/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.888, test=0.806) total time=  15.1s\n",
      "[CV 2/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 2/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.885, test=0.798) total time=  15.4s\n",
      "[CV 3/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 3/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.885, test=0.805) total time=  15.4s\n",
      "[CV 4/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 4/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.885, test=0.810) total time=  15.8s\n",
      "[CV 5/5; 5/20] START rfc__max_depth=36, rfc__n_estimators=351...................\n",
      "[CV 5/5; 5/20] END rfc__max_depth=36, rfc__n_estimators=351;, score=(train=0.884, test=0.809) total time=  15.4s\n",
      "[CV 1/5; 6/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 1/5; 6/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.908, test=0.827) total time=   6.1s\n",
      "[CV 2/5; 6/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 2/5; 6/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.907, test=0.819) total time=   6.2s\n",
      "[CV 3/5; 6/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 3/5; 6/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.907, test=0.825) total time=   6.1s\n",
      "[CV 4/5; 6/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 4/5; 6/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.903, test=0.823) total time=   6.2s\n",
      "[CV 5/5; 6/20] START rfc__max_depth=46, rfc__n_estimators=101...................\n",
      "[CV 5/5; 6/20] END rfc__max_depth=46, rfc__n_estimators=101;, score=(train=0.904, test=0.827) total time=   6.0s\n",
      "[CV 1/5; 7/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 1/5; 7/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.888, test=0.806) total time=  17.3s\n",
      "[CV 2/5; 7/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 2/5; 7/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.885, test=0.799) total time=  17.8s\n",
      "[CV 3/5; 7/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 3/5; 7/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.885, test=0.804) total time=  17.5s\n",
      "[CV 4/5; 7/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 4/5; 7/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.885, test=0.809) total time=  18.3s\n",
      "[CV 5/5; 7/20] START rfc__max_depth=36, rfc__n_estimators=401...................\n",
      "[CV 5/5; 7/20] END rfc__max_depth=36, rfc__n_estimators=401;, score=(train=0.885, test=0.811) total time=  17.5s\n",
      "[CV 1/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=351...................\n",
      "[CV 1/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.900, test=0.816) total time=  17.8s\n",
      "[CV 2/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=351...................\n",
      "[CV 2/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.898, test=0.812) total time=  18.2s\n",
      "[CV 3/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=351...................\n",
      "[CV 3/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.898, test=0.814) total time=  18.2s\n",
      "[CV 4/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=351...................\n",
      "[CV 4/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.896, test=0.821) total time=  18.4s\n",
      "[CV 5/5; 8/20] START rfc__max_depth=41, rfc__n_estimators=351...................\n",
      "[CV 5/5; 8/20] END rfc__max_depth=41, rfc__n_estimators=351;, score=(train=0.895, test=0.821) total time=  18.1s\n",
      "[CV 1/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 1/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.900, test=0.817) total time=  13.0s\n",
      "[CV 2/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 2/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.898, test=0.810) total time=  13.0s\n",
      "[CV 3/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 3/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.899, test=0.815) total time=  13.0s\n",
      "[CV 4/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 4/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.897, test=0.822) total time=  13.1s\n",
      "[CV 5/5; 9/20] START rfc__max_depth=41, rfc__n_estimators=251...................\n",
      "[CV 5/5; 9/20] END rfc__max_depth=41, rfc__n_estimators=251;, score=(train=0.896, test=0.820) total time=  13.2s\n",
      "[CV 1/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 1/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.901, test=0.817) total time=  15.5s\n",
      "[CV 2/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 2/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.898, test=0.810) total time=  15.8s\n",
      "[CV 3/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 3/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.899, test=0.815) total time=  15.4s\n",
      "[CV 4/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 4/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.896, test=0.820) total time=  15.6s\n",
      "[CV 5/5; 10/20] START rfc__max_depth=41, rfc__n_estimators=301..................\n",
      "[CV 5/5; 10/20] END rfc__max_depth=41, rfc__n_estimators=301;, score=(train=0.895, test=0.819) total time=  15.6s\n",
      "[CV 1/5; 11/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 1/5; 11/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.908, test=0.825) total time=   9.0s\n",
      "[CV 2/5; 11/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 2/5; 11/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.906, test=0.818) total time=   9.1s\n",
      "[CV 3/5; 11/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 3/5; 11/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.908, test=0.828) total time=   9.0s\n",
      "[CV 4/5; 11/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 4/5; 11/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.903, test=0.822) total time=   9.2s\n",
      "[CV 5/5; 11/20] START rfc__max_depth=46, rfc__n_estimators=151..................\n",
      "[CV 5/5; 11/20] END rfc__max_depth=46, rfc__n_estimators=151;, score=(train=0.903, test=0.824) total time=   8.9s\n",
      "[CV 1/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=201..................\n",
      "[CV 1/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.901, test=0.819) total time=  10.5s\n",
      "[CV 2/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=201..................\n",
      "[CV 2/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.897, test=0.810) total time=  10.4s\n",
      "[CV 3/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=201..................\n",
      "[CV 3/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.898, test=0.815) total time=  10.4s\n",
      "[CV 4/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=201..................\n",
      "[CV 4/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.893, test=0.818) total time=  10.7s\n",
      "[CV 5/5; 12/20] START rfc__max_depth=41, rfc__n_estimators=201..................\n",
      "[CV 5/5; 12/20] END rfc__max_depth=41, rfc__n_estimators=201;, score=(train=0.897, test=0.821) total time=  10.4s\n",
      "[CV 1/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 1/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.901, test=0.818) total time=  20.3s\n",
      "[CV 2/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 2/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.898, test=0.809) total time=  21.0s\n",
      "[CV 3/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 3/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.898, test=0.814) total time=  20.4s\n",
      "[CV 4/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 4/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.896, test=0.820) total time=  21.0s\n",
      "[CV 5/5; 13/20] START rfc__max_depth=41, rfc__n_estimators=401..................\n",
      "[CV 5/5; 13/20] END rfc__max_depth=41, rfc__n_estimators=401;, score=(train=0.896, test=0.822) total time=  20.5s\n",
      "[CV 1/5; 14/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 1/5; 14/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.901, test=0.818) total time=  23.0s\n",
      "[CV 2/5; 14/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 2/5; 14/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.898, test=0.808) total time=  23.2s\n",
      "[CV 3/5; 14/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 3/5; 14/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.898, test=0.814) total time=  22.8s\n",
      "[CV 4/5; 14/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 4/5; 14/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.897, test=0.822) total time=  24.0s\n",
      "[CV 5/5; 14/20] START rfc__max_depth=41, rfc__n_estimators=451..................\n",
      "[CV 5/5; 14/20] END rfc__max_depth=41, rfc__n_estimators=451;, score=(train=0.897, test=0.822) total time=  23.2s\n",
      "[CV 1/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 1/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.910, test=0.828) total time=  20.5s\n",
      "[CV 2/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 2/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.908, test=0.820) total time=  20.8s\n",
      "[CV 3/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 3/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.908, test=0.827) total time=  20.6s\n",
      "[CV 4/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 4/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.906, test=0.828) total time=  21.5s\n",
      "[CV 5/5; 15/20] START rfc__max_depth=46, rfc__n_estimators=351..................\n",
      "[CV 5/5; 15/20] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.906, test=0.831) total time=  20.8s\n",
      "[CV 1/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 1/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.909, test=0.826) total time=  17.6s\n",
      "[CV 2/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 2/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.908, test=0.820) total time=  18.4s\n",
      "[CV 3/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 3/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.908, test=0.827) total time=  18.2s\n",
      "[CV 4/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 4/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.906, test=0.827) total time=  18.3s\n",
      "[CV 5/5; 16/20] START rfc__max_depth=46, rfc__n_estimators=301..................\n",
      "[CV 5/5; 16/20] END rfc__max_depth=46, rfc__n_estimators=301;, score=(train=0.905, test=0.829) total time=  17.9s\n",
      "[CV 1/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 1/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.911, test=0.829) total time=  26.3s\n",
      "[CV 2/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 2/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.908, test=0.822) total time=  26.8s\n",
      "[CV 3/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 3/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.907, test=0.825) total time=  26.6s\n",
      "[CV 4/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 4/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.907, test=0.831) total time=  26.8s\n",
      "[CV 5/5; 17/20] START rfc__max_depth=46, rfc__n_estimators=451..................\n",
      "[CV 5/5; 17/20] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.908, test=0.830) total time=  26.5s\n",
      "[CV 1/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 1/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.910, test=0.829) total time=  23.4s\n",
      "[CV 2/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 2/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.907, test=0.821) total time=  23.9s\n",
      "[CV 3/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 3/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.907, test=0.825) total time=  23.7s\n",
      "[CV 4/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 4/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.906, test=0.830) total time=  24.1s\n",
      "[CV 5/5; 18/20] START rfc__max_depth=46, rfc__n_estimators=401..................\n",
      "[CV 5/5; 18/20] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.907, test=0.829) total time=  23.5s\n",
      "[CV 1/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 1/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.911, test=0.827) total time=  11.7s\n",
      "[CV 2/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 2/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.908, test=0.816) total time=  12.2s\n",
      "[CV 3/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 3/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.907, test=0.827) total time=  11.9s\n",
      "[CV 4/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 4/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.902, test=0.824) total time=  12.2s\n",
      "[CV 5/5; 19/20] START rfc__max_depth=46, rfc__n_estimators=201..................\n",
      "[CV 5/5; 19/20] END rfc__max_depth=46, rfc__n_estimators=201;, score=(train=0.905, test=0.829) total time=  12.0s\n",
      "[CV 1/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 1/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.910, test=0.828) total time=  14.7s\n",
      "[CV 2/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 2/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.909, test=0.820) total time=  15.1s\n",
      "[CV 3/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 3/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.908, test=0.828) total time=  14.8s\n",
      "[CV 4/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 4/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.904, test=0.826) total time=  15.2s\n",
      "[CV 5/5; 20/20] START rfc__max_depth=46, rfc__n_estimators=251..................\n",
      "[CV 5/5; 20/20] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.905, test=0.830) total time=  14.8s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 138300\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=251....................\n",
      "[CV 1/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.897, test=0.879) total time= 1.6min\n",
      "[CV 2/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=251....................\n",
      "[CV 2/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.897, test=0.877) total time= 1.6min\n",
      "[CV 3/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=251....................\n",
      "[CV 3/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.897, test=0.881) total time= 1.6min\n",
      "[CV 4/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=251....................\n",
      "[CV 4/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.895, test=0.881) total time= 1.6min\n",
      "[CV 5/5; 1/4] START rfc__max_depth=46, rfc__n_estimators=251....................\n",
      "[CV 5/5; 1/4] END rfc__max_depth=46, rfc__n_estimators=251;, score=(train=0.898, test=0.880) total time= 1.6min\n",
      "[CV 1/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 1/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.897, test=0.881) total time= 2.2min\n",
      "[CV 2/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 2/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.896, test=0.877) total time= 2.2min\n",
      "[CV 3/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 3/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.897, test=0.882) total time= 2.3min\n",
      "[CV 4/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 4/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.896, test=0.882) total time= 2.2min\n",
      "[CV 5/5; 2/4] START rfc__max_depth=46, rfc__n_estimators=351....................\n",
      "[CV 5/5; 2/4] END rfc__max_depth=46, rfc__n_estimators=351;, score=(train=0.897, test=0.880) total time= 2.2min\n",
      "[CV 1/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 1/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.898, test=0.881) total time= 2.6min\n",
      "[CV 2/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 2/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.897, test=0.877) total time= 2.5min\n",
      "[CV 3/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 3/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.897, test=0.882) total time= 2.6min\n",
      "[CV 4/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 4/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.896, test=0.882) total time= 2.5min\n",
      "[CV 5/5; 3/4] START rfc__max_depth=46, rfc__n_estimators=401....................\n",
      "[CV 5/5; 3/4] END rfc__max_depth=46, rfc__n_estimators=401;, score=(train=0.897, test=0.880) total time= 2.6min\n",
      "[CV 1/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 1/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.898, test=0.881) total time= 2.9min\n",
      "[CV 2/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 2/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.898, test=0.878) total time= 2.8min\n",
      "[CV 3/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 3/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.897, test=0.881) total time= 2.9min\n",
      "[CV 4/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 4/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.896, test=0.882) total time= 2.8min\n",
      "[CV 5/5; 4/4] START rfc__max_depth=46, rfc__n_estimators=451....................\n",
      "[CV 5/5; 4/4] END rfc__max_depth=46, rfc__n_estimators=451;, score=(train=0.898, test=0.881) total time= 2.9min\n",
      "0.8806800134410903\n",
      "{'rfc__max_depth': 46, 'rfc__n_estimators': 451}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0, n_jobs=3)\n",
    "\n",
    "rfcgrid = {\n",
    "    'rfc__max_depth' : list(range(1,50,5)),\n",
    "    'rfc__n_estimators' : list(range(1,500,50)),\n",
    "}\n",
    "\n",
    "f1 = make_scorer(f1_score, average='binary', pos_label = 1) \n",
    "\n",
    "imba_pipe_rfc = Pipeline([\n",
    "    ('sampling', RandomOverSampler(random_state=0)), \n",
    "    ('rfc', rfc)\n",
    "    ])\n",
    "\n",
    "\n",
    "rfcrs = HalvingGridSearchCV(estimator=imba_pipe_rfc, param_grid=rfcgrid, factor=5, cv=5, scoring=f1, verbose=10)\n",
    "\n",
    "rfcrs.fit(x_trainvec, y_train.to_numpy().ravel())\n",
    "\n",
    "print(rfcrs.best_score_)\n",
    "print(rfcrs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Train Accuracy Score : 0.8865328725726928\n",
      "RFC Test Accuracy Score : 0.9232613908872902\n",
      "RFC Train F1 Score : 0.896847252436692\n",
      "RFC Test F1 Score : 0.9587652482675677\n",
      "RFC Confusion matrix:\n",
      "[[  584   588]\n",
      " [  852 16741]]\n",
      "RFC Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.41      0.45      1436\n",
      "           1       0.95      0.97      0.96     17329\n",
      "\n",
      "    accuracy                           0.92     18765\n",
      "   macro avg       0.72      0.69      0.70     18765\n",
      "weighted avg       0.92      0.92      0.92     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rfc_train_predictions = rfcrs.best_estimator_.predict(x_trainvec)\n",
    "rfc_test_predictions = rfcrs.best_estimator_.predict(x_testvec)\n",
    "\n",
    "print(\"RFC Train Accuracy Score :\",accuracy_score(y_pred=rfc_train_predictions, y_true=y_train.to_numpy().ravel()))\n",
    "print(\"RFC Test Accuracy Score :\",accuracy_score(y_pred=rfc_test_predictions, y_true= y_test.to_numpy().ravel()))\n",
    "\n",
    "print(\"RFC Train F1 Score :\",f1_score(y_pred=rfc_train_predictions, y_true=y_train.to_numpy().ravel(), average = 'binary'))\n",
    "print(\"RFC Test F1 Score :\",f1_score(y_pred=rfc_test_predictions, y_true=y_test.to_numpy().ravel(), average = 'binary'))\n",
    "\n",
    "print(\"RFC Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= rfc_test_predictions)))\n",
    "print(\"RFC Classification report:\\n\",classification_report(y_pred=rfc_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.857 total time=   0.0s\n",
      "[CV 2/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.857 total time=   0.0s\n",
      "[CV 3/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.859 total time=   0.0s\n",
      "[CV 4/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.862 total time=   0.0s\n",
      "[CV 5/5; 1/20] START mnbc__alpha=0.1, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 1/20] END mnbc__alpha=0.1, mnbc__fit_prior=True;, score=0.857 total time=   0.0s\n",
      "[CV 1/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 1/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.857 total time=   0.0s\n",
      "[CV 2/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 2/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.857 total time=   0.0s\n",
      "[CV 3/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 3/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.859 total time=   0.0s\n",
      "[CV 4/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 4/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.862 total time=   0.0s\n",
      "[CV 5/5; 2/20] START mnbc__alpha=0.1, mnbc__fit_prior=False.....................\n",
      "[CV 5/5; 2/20] END mnbc__alpha=0.1, mnbc__fit_prior=False;, score=0.857 total time=   0.0s\n",
      "[CV 1/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.854 total time=   0.0s\n",
      "[CV 2/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.855 total time=   0.0s\n",
      "[CV 3/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.856 total time=   0.0s\n",
      "[CV 4/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.859 total time=   0.0s\n",
      "[CV 5/5; 3/20] START mnbc__alpha=0.2, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 3/20] END mnbc__alpha=0.2, mnbc__fit_prior=True;, score=0.854 total time=   0.0s\n",
      "[CV 1/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 1/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.854 total time=   0.0s\n",
      "[CV 2/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 2/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.855 total time=   0.0s\n",
      "[CV 3/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 3/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.856 total time=   0.0s\n",
      "[CV 4/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 4/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.859 total time=   0.0s\n",
      "[CV 5/5; 4/20] START mnbc__alpha=0.2, mnbc__fit_prior=False.....................\n",
      "[CV 5/5; 4/20] END mnbc__alpha=0.2, mnbc__fit_prior=False;, score=0.854 total time=   0.0s\n",
      "[CV 1/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.852 total time=   0.0s\n",
      "[CV 2/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.852 total time=   0.0s\n",
      "[CV 3/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.854 total time=   0.0s\n",
      "[CV 4/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.858 total time=   0.0s\n",
      "[CV 5/5; 5/20] START mnbc__alpha=0.3, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 5/20] END mnbc__alpha=0.3, mnbc__fit_prior=True;, score=0.851 total time=   0.0s\n",
      "[CV 1/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 1/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.852 total time=   0.0s\n",
      "[CV 2/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 2/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.852 total time=   0.0s\n",
      "[CV 3/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 3/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.854 total time=   0.0s\n",
      "[CV 4/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 4/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.858 total time=   0.0s\n",
      "[CV 5/5; 6/20] START mnbc__alpha=0.3, mnbc__fit_prior=False.....................\n",
      "[CV 5/5; 6/20] END mnbc__alpha=0.3, mnbc__fit_prior=False;, score=0.851 total time=   0.0s\n",
      "[CV 1/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.850 total time=   0.0s\n",
      "[CV 2/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.850 total time=   0.0s\n",
      "[CV 3/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.852 total time=   0.0s\n",
      "[CV 4/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.856 total time=   0.0s\n",
      "[CV 5/5; 7/20] START mnbc__alpha=0.4, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 7/20] END mnbc__alpha=0.4, mnbc__fit_prior=True;, score=0.849 total time=   0.0s\n",
      "[CV 1/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 1/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.850 total time=   0.0s\n",
      "[CV 2/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 2/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.850 total time=   0.0s\n",
      "[CV 3/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 3/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.852 total time=   0.0s\n",
      "[CV 4/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 4/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.856 total time=   0.0s\n",
      "[CV 5/5; 8/20] START mnbc__alpha=0.4, mnbc__fit_prior=False.....................\n",
      "[CV 5/5; 8/20] END mnbc__alpha=0.4, mnbc__fit_prior=False;, score=0.849 total time=   0.0s\n",
      "[CV 1/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 1/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.848 total time=   0.0s\n",
      "[CV 2/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 2/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.849 total time=   0.0s\n",
      "[CV 3/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 3/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.850 total time=   0.0s\n",
      "[CV 4/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 4/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.854 total time=   0.0s\n",
      "[CV 5/5; 9/20] START mnbc__alpha=0.5, mnbc__fit_prior=True......................\n",
      "[CV 5/5; 9/20] END mnbc__alpha=0.5, mnbc__fit_prior=True;, score=0.847 total time=   0.0s\n",
      "[CV 1/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.848 total time=   0.0s\n",
      "[CV 2/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.849 total time=   0.0s\n",
      "[CV 3/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.850 total time=   0.0s\n",
      "[CV 4/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.854 total time=   0.0s\n",
      "[CV 5/5; 10/20] START mnbc__alpha=0.5, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 10/20] END mnbc__alpha=0.5, mnbc__fit_prior=False;, score=0.847 total time=   0.0s\n",
      "[CV 1/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 1/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.846 total time=   0.0s\n",
      "[CV 2/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 2/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.847 total time=   0.0s\n",
      "[CV 3/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 3/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.849 total time=   0.0s\n",
      "[CV 4/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 4/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.852 total time=   0.0s\n",
      "[CV 5/5; 11/20] START mnbc__alpha=0.6, mnbc__fit_prior=True.....................\n",
      "[CV 5/5; 11/20] END mnbc__alpha=0.6, mnbc__fit_prior=True;, score=0.846 total time=   0.0s\n",
      "[CV 1/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.846 total time=   0.0s\n",
      "[CV 2/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.847 total time=   0.0s\n",
      "[CV 3/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.849 total time=   0.0s\n",
      "[CV 4/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.852 total time=   0.0s\n",
      "[CV 5/5; 12/20] START mnbc__alpha=0.6, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 12/20] END mnbc__alpha=0.6, mnbc__fit_prior=False;, score=0.846 total time=   0.0s\n",
      "[CV 1/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 1/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.845 total time=   0.0s\n",
      "[CV 2/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 2/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.845 total time=   0.0s\n",
      "[CV 3/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 3/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.847 total time=   0.0s\n",
      "[CV 4/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 4/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.850 total time=   0.0s\n",
      "[CV 5/5; 13/20] START mnbc__alpha=0.7, mnbc__fit_prior=True.....................\n",
      "[CV 5/5; 13/20] END mnbc__alpha=0.7, mnbc__fit_prior=True;, score=0.844 total time=   0.0s\n",
      "[CV 1/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.845 total time=   0.0s\n",
      "[CV 2/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.845 total time=   0.0s\n",
      "[CV 3/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.847 total time=   0.0s\n",
      "[CV 4/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.850 total time=   0.0s\n",
      "[CV 5/5; 14/20] START mnbc__alpha=0.7, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 14/20] END mnbc__alpha=0.7, mnbc__fit_prior=False;, score=0.844 total time=   0.0s\n",
      "[CV 1/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 1/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.842 total time=   0.0s\n",
      "[CV 2/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 2/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.844 total time=   0.0s\n",
      "[CV 3/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 3/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.846 total time=   0.0s\n",
      "[CV 4/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 4/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.848 total time=   0.0s\n",
      "[CV 5/5; 15/20] START mnbc__alpha=0.8, mnbc__fit_prior=True.....................\n",
      "[CV 5/5; 15/20] END mnbc__alpha=0.8, mnbc__fit_prior=True;, score=0.841 total time=   0.0s\n",
      "[CV 1/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.842 total time=   0.0s\n",
      "[CV 2/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.844 total time=   0.0s\n",
      "[CV 3/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.846 total time=   0.0s\n",
      "[CV 4/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.848 total time=   0.0s\n",
      "[CV 5/5; 16/20] START mnbc__alpha=0.8, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 16/20] END mnbc__alpha=0.8, mnbc__fit_prior=False;, score=0.841 total time=   0.0s\n",
      "[CV 1/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 1/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.840 total time=   0.0s\n",
      "[CV 2/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 2/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.843 total time=   0.0s\n",
      "[CV 3/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 3/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.844 total time=   0.0s\n",
      "[CV 4/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 4/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.847 total time=   0.0s\n",
      "[CV 5/5; 17/20] START mnbc__alpha=0.9, mnbc__fit_prior=True.....................\n",
      "[CV 5/5; 17/20] END mnbc__alpha=0.9, mnbc__fit_prior=True;, score=0.839 total time=   0.0s\n",
      "[CV 1/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 1/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.840 total time=   0.0s\n",
      "[CV 2/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 2/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.843 total time=   0.0s\n",
      "[CV 3/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 3/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.844 total time=   0.0s\n",
      "[CV 4/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 4/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.847 total time=   0.0s\n",
      "[CV 5/5; 18/20] START mnbc__alpha=0.9, mnbc__fit_prior=False....................\n",
      "[CV 5/5; 18/20] END mnbc__alpha=0.9, mnbc__fit_prior=False;, score=0.839 total time=   0.0s\n",
      "[CV 1/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 1/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.839 total time=   0.0s\n",
      "[CV 2/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 2/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.841 total time=   0.0s\n",
      "[CV 3/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 3/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.843 total time=   0.0s\n",
      "[CV 4/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 4/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.845 total time=   0.0s\n",
      "[CV 5/5; 19/20] START mnbc__alpha=1, mnbc__fit_prior=True.......................\n",
      "[CV 5/5; 19/20] END mnbc__alpha=1, mnbc__fit_prior=True;, score=0.837 total time=   0.0s\n",
      "[CV 1/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 1/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.839 total time=   0.0s\n",
      "[CV 2/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 2/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.841 total time=   0.0s\n",
      "[CV 3/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 3/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.843 total time=   0.0s\n",
      "[CV 4/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 4/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.845 total time=   0.0s\n",
      "[CV 5/5; 20/20] START mnbc__alpha=1, mnbc__fit_prior=False......................\n",
      "[CV 5/5; 20/20] END mnbc__alpha=1, mnbc__fit_prior=False;, score=0.837 total time=   0.0s\n",
      "0.8585377631601363\n",
      "{'mnbc__alpha': 0.1, 'mnbc__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "mnbc = MultinomialNB()\n",
    "\n",
    "mnbc.get_params()\n",
    "\n",
    "mnbc_grid = {\n",
    "    'mnbc__alpha' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "    'mnbc__fit_prior' : [True, False]\n",
    "}\n",
    "\n",
    "imba_pipe_mnbc = Pipeline([\n",
    "    ('sampling', RandomOverSampler(random_state=0)), \n",
    "    ('mnbc', mnbc)\n",
    "    ])\n",
    "\n",
    "f1 = make_scorer(f1_score, average='binary', pos_label = 1)\n",
    "\n",
    "mnbcgs = GridSearchCV(estimator=imba_pipe_mnbc, param_grid=mnbc_grid, cv=5, scoring=f1, verbose=10)\n",
    "\n",
    "mnbcgs.fit(x_trainvec, y_train.to_numpy().ravel())\n",
    "\n",
    "print(mnbcgs.best_score_)\n",
    "print(mnbcgs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNBC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNBC Model Train Accuracy Score : 0.8769682335420251\n",
      "MNBC Model Test Accuracy Score : 0.8349054090061284\n",
      "MNBC Model Train F1 Score : 0.8774449085409766\n",
      "MNBC Model Test F1 Score : 0.9046240995012622\n",
      "MNBC Confusion matrix:\n",
      "[[  975  2637]\n",
      " [  461 14692]]\n",
      "MNBC Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.68      0.39      1436\n",
      "           1       0.97      0.85      0.90     17329\n",
      "\n",
      "    accuracy                           0.83     18765\n",
      "   macro avg       0.62      0.76      0.65     18765\n",
      "weighted avg       0.92      0.83      0.86     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "mnb_train_predictions = mnbcgs.best_estimator_.predict(x_trainvec)\n",
    "mnb_test_predictions = mnbcgs.best_estimator_.predict(x_testvec)\n",
    "\n",
    "print(\"MNBC Model Train Accuracy Score :\",accuracy_score(mnb_train_predictions, y_train.to_numpy().ravel()))\n",
    "print(\"MNBC Model Test Accuracy Score :\",accuracy_score(mnb_test_predictions, y_test.to_numpy().ravel()))\n",
    "\n",
    "print(\"MNBC Model Train F1 Score :\",f1_score(mnb_train_predictions, y_train.to_numpy().ravel(), average = 'binary'))\n",
    "print(\"MNBC Model Test F1 Score :\",f1_score(mnb_test_predictions, y_test.to_numpy().ravel(), average = 'binary'))\n",
    "\n",
    "print(\"MNBC Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= mnb_test_predictions)))\n",
    "print(\"MNBC Classification report:\\n\",classification_report(y_pred=mnb_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45430597 0.54569403]\n",
      " [0.35307651 0.64692349]\n",
      " [0.4106744  0.5893256 ]\n",
      " ...\n",
      " [0.6098439  0.3901561 ]\n",
      " [0.58683237 0.41316763]\n",
      " [0.96207004 0.03792996]]\n"
     ]
    }
   ],
   "source": [
    "print(rfcrs.best_estimator_.predict_proba(x_trainvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mlp       rfc      mnbc\n",
      "0  0.499469  0.545694  0.466269\n",
      "1  0.999986  0.646923  0.811235\n",
      "2  0.999627  0.589326  0.762265\n",
      "3  0.999293  0.612861  0.700163\n",
      "4  0.998928  0.579946  0.792787\n"
     ]
    }
   ],
   "source": [
    "def get_predict_probas(data):\n",
    "    mlp_proba = best_model.predict(data)\n",
    "    rfc_proba = np.delete(rfcrs.best_estimator_.predict_proba(data),0,1)\n",
    "    mnbc_proba = np.delete(mnbcgs.best_estimator_.predict_proba(data),0,1)\n",
    "    mlp_proba_df = pd.DataFrame(mlp_proba,columns=['mlp'])\n",
    "    rfc_proba_df = pd.DataFrame(rfc_proba,columns=['rfc'])\n",
    "    mnbc_proba_df = pd.DataFrame(mnbc_proba,columns=['mnbc'])\n",
    "    return pd.concat([mlp_proba_df,rfc_proba_df,mnbc_proba_df],axis=1)\n",
    "\n",
    "x_trainvec_stack = get_predict_probas(x_trainvec)\n",
    "x_testvec_stack = get_predict_probas(x_testvec)\n",
    "\n",
    "print(x_trainvec_stack.head())\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Classifier(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 27664\n",
      "max_resources_: 138322\n",
      "aggressive_elimination: False\n",
      "factor: 5\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 10\n",
      "n_resources: 27664\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 138320\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(estimator=Pipeline(steps=[(&#x27;sampling&#x27;,\n",
       "                                               RandomOverSampler(random_state=0)),\n",
       "                                              (&#x27;sclf&#x27;,\n",
       "                                               LogisticRegression(random_state=0))]),\n",
       "                    factor=5,\n",
       "                    param_grid={&#x27;sclf__C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                                &#x27;sclf__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;]},\n",
       "                    scoring=make_scorer(f1_score, average=binary, pos_label=1),\n",
       "                    verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(estimator=Pipeline(steps=[(&#x27;sampling&#x27;,\n",
       "                                               RandomOverSampler(random_state=0)),\n",
       "                                              (&#x27;sclf&#x27;,\n",
       "                                               LogisticRegression(random_state=0))]),\n",
       "                    factor=5,\n",
       "                    param_grid={&#x27;sclf__C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                                &#x27;sclf__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;]},\n",
       "                    scoring=make_scorer(f1_score, average=binary, pos_label=1),\n",
       "                    verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;sampling&#x27;, RandomOverSampler(random_state=0)),\n",
       "                (&#x27;sclf&#x27;, LogisticRegression(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=0)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(estimator=Pipeline(steps=[('sampling',\n",
       "                                               RandomOverSampler(random_state=0)),\n",
       "                                              ('sclf',\n",
       "                                               LogisticRegression(random_state=0))]),\n",
       "                    factor=5,\n",
       "                    param_grid={'sclf__C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                                'sclf__solver': ['newton-cg', 'lbfgs']},\n",
       "                    scoring=make_scorer(f1_score, average=binary, pos_label=1),\n",
       "                    verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sclf = LogisticRegression(random_state=0)\n",
    "\n",
    "sclf_param_grid = {\n",
    "    'sclf__solver' : ['newton-cg', 'lbfgs'],\n",
    "    'sclf__C': [100, 10, 1.0, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "imba_pipe_stack = Pipeline([\n",
    "    ('sampling', RandomOverSampler(random_state=0)), \n",
    "    ('sclf', sclf)\n",
    "    ])\n",
    "\n",
    "\n",
    "sclfrs = HalvingGridSearchCV(estimator=imba_pipe_stack , param_grid=sclf_param_grid, factor=5, cv=5, scoring=f1, verbose=1)\n",
    "\n",
    "sclfrs.fit(x_trainvec_stack, y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# I probably shldv written a function for this...\n",
    "sclfrs_train_predictions = sclfrs.predict(x_trainvec_stack)\n",
    "sclfrs_test_predictions = sclfrs.predict(x_testvec_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Test Accuracy Score : 0.9096722621902478\n",
      "RFC Test Accuracy Score : 0.9232613908872902\n",
      "MNBC Model Test Accuracy Score : 0.8349054090061284\n",
      "Stacked Model Test Accuracy Score : 0.9140953903543831\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP Test Accuracy Score :\",accuracy_score(y_pred=mlp_test_predictions, y_true= y_test.to_numpy().ravel()))\n",
    "print(\"RFC Test Accuracy Score :\",accuracy_score(y_pred=rfc_test_predictions, y_true= y_test.to_numpy().ravel()))\n",
    "print(\"MNBC Model Test Accuracy Score :\",accuracy_score(mnb_test_predictions, y_test.to_numpy().ravel()))\n",
    "print(\"Stacked Model Test Accuracy Score :\",accuracy_score(sclfrs_test_predictions, y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Test F1 Score : 0.9510158078779297\n",
      "RFC Test F1 Score : 0.9587652482675677\n",
      "MNBC Model Test F1 Score : 0.9046240995012622\n",
      "Stacked Model Test F1 Score : 0.9534937395418613\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP Test F1 Score :\",f1_score(y_pred=mlp_test_predictions, y_true=y_test.to_numpy().ravel(), average = 'binary'))\n",
    "print(\"RFC Test F1 Score :\",f1_score(y_pred=rfc_test_predictions, y_true=y_test.to_numpy().ravel(), average = 'binary'))\n",
    "print(\"MNBC Model Test F1 Score :\",f1_score(mnb_test_predictions, y_test.to_numpy().ravel(), average = 'binary'))\n",
    "print(\"Stacked Model Test F1 Score :\",f1_score(sclfrs_test_predictions, y_test.to_numpy().ravel(),average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Confusion matrix:\n",
      "[[  616   875]\n",
      " [  820 16454]]\n",
      "RFC Confusion matrix:\n",
      "[[  584   588]\n",
      " [  852 16741]]\n",
      "MNBC Confusion matrix:\n",
      "[[  975  2637]\n",
      " [  461 14692]]\n",
      "Stacked Confusion matrix:\n",
      "[[  628   804]\n",
      " [  808 16525]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MLP Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= mlp_test_predictions)))\n",
    "print(\"RFC Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= rfc_test_predictions)))\n",
    "print(\"MNBC Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= mnb_test_predictions)))\n",
    "print(\"Stacked Confusion matrix:\\n{}\".format(confusion_matrix(y_pred=y_test.to_numpy().ravel(),y_true= sclfrs_test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.43      0.42      1436\n",
      "           1       0.95      0.95      0.95     17329\n",
      "\n",
      "    accuracy                           0.91     18765\n",
      "   macro avg       0.68      0.69      0.69     18765\n",
      "weighted avg       0.91      0.91      0.91     18765\n",
      "\n",
      "RFC Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.41      0.45      1436\n",
      "           1       0.95      0.97      0.96     17329\n",
      "\n",
      "    accuracy                           0.92     18765\n",
      "   macro avg       0.72      0.69      0.70     18765\n",
      "weighted avg       0.92      0.92      0.92     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MLP Classification report:\\n\",classification_report(y_pred=mlp_test_predictions,  y_true= y_test.to_numpy().ravel()))\n",
    "print(\"RFC Classification report:\\n\",classification_report(y_pred=rfc_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNBC Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.68      0.39      1436\n",
      "           1       0.97      0.85      0.90     17329\n",
      "\n",
      "    accuracy                           0.83     18765\n",
      "   macro avg       0.62      0.76      0.65     18765\n",
      "weighted avg       0.92      0.83      0.86     18765\n",
      "\n",
      "Stacked Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44      1436\n",
      "           1       0.95      0.95      0.95     17329\n",
      "\n",
      "    accuracy                           0.91     18765\n",
      "   macro avg       0.70      0.70      0.70     18765\n",
      "weighted avg       0.91      0.91      0.91     18765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MNBC Classification report:\\n\",classification_report(y_pred=mnb_test_predictions,  y_true= y_test.to_numpy().ravel()))\n",
    "print(\"Stacked Classification report:\\n\",classification_report(y_pred=sclfrs_test_predictions,  y_true= y_test.to_numpy().ravel()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11a3d9b85d5ef9eb303a3e0d0718105e342595a43d68d297ee0965f43b786655"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
